{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing data...\n",
      "Dataset shapes:\n",
      "X without product type: (180, 202)\n",
      "X with product type: (180, 203)\n",
      "Number of storage conditions: 3\n",
      "Storage conditions: {'Humid': 0, 'Open': 1, 'Wrapped': 2}\n",
      "\n",
      "Running hyperparameter tuning...\n",
      "\n",
      "######################################################################\n",
      "Running comparison for SVM\n",
      "######################################################################\n",
      "\n",
      "Tuning SVM with product type features...\n",
      "Fitting 10 folds for each of 32 candidates, totalling 320 fits\n",
      "\n",
      "Tuning SVM without product type features...\n",
      "Fitting 10 folds for each of 32 candidates, totalling 320 fits\n",
      "\n",
      "==================================================\n",
      "Comparison Results for SVM\n",
      "==================================================\n",
      "\n",
      "Results with product type:\n",
      "Best score: 0.9556\n",
      "Best parameters: {'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "\n",
      "Results without product type:\n",
      "Best score: 0.9500\n",
      "Best parameters: {'C': 100, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "\n",
      "Performance difference (with - without): 0.0056\n",
      "\n",
      "Recommendation: Consider using the model without product type for better generalization,\n",
      "as the performance difference is minimal (<2%).\n",
      "\n",
      "######################################################################\n",
      "Running comparison for Random Forest\n",
      "######################################################################\n",
      "\n",
      "Tuning Random Forest with product type features...\n",
      "Fitting 10 folds for each of 108 candidates, totalling 1080 fits\n",
      "\n",
      "Tuning Random Forest without product type features...\n",
      "Fitting 10 folds for each of 108 candidates, totalling 1080 fits\n",
      "\n",
      "==================================================\n",
      "Comparison Results for Random Forest\n",
      "==================================================\n",
      "\n",
      "Results with product type:\n",
      "Best score: 0.9944\n",
      "Best parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "\n",
      "Results without product type:\n",
      "Best score: 0.9944\n",
      "Best parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "\n",
      "Performance difference (with - without): 0.0000\n",
      "\n",
      "Recommendation: Consider using the model without product type for better generalization,\n",
      "as the performance difference is minimal (<2%).\n",
      "\n",
      "######################################################################\n",
      "Running comparison for KNN\n",
      "######################################################################\n",
      "\n",
      "Tuning KNN with product type features...\n",
      "Fitting 10 folds for each of 16 candidates, totalling 160 fits\n",
      "\n",
      "Tuning KNN without product type features...\n",
      "Fitting 10 folds for each of 16 candidates, totalling 160 fits\n",
      "\n",
      "==================================================\n",
      "Comparison Results for KNN\n",
      "==================================================\n",
      "\n",
      "Results with product type:\n",
      "Best score: 0.9389\n",
      "Best parameters: {'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "\n",
      "Results without product type:\n",
      "Best score: 0.9389\n",
      "Best parameters: {'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "\n",
      "Performance difference (with - without): 0.0000\n",
      "\n",
      "Recommendation: Consider using the model without product type for better generalization,\n",
      "as the performance difference is minimal (<2%).\n",
      "\n",
      "######################################################################\n",
      "Running comparison for Neural Network\n",
      "######################################################################\n",
      "\n",
      "Tuning Neural Network with product type features...\n",
      "Fitting 10 folds for each of 48 candidates, totalling 480 fits\n",
      "\n",
      "Tuning Neural Network without product type features...\n",
      "Fitting 10 folds for each of 48 candidates, totalling 480 fits\n",
      "\n",
      "==================================================\n",
      "Comparison Results for Neural Network\n",
      "==================================================\n",
      "\n",
      "Results with product type:\n",
      "Best score: 0.9222\n",
      "Best parameters: {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50,), 'learning_rate': 'constant'}\n",
      "\n",
      "Results without product type:\n",
      "Best score: 0.9278\n",
      "Best parameters: {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant'}\n",
      "\n",
      "Performance difference (with - without): -0.0056\n",
      "\n",
      "Recommendation: Consider using the model without product type for better generalization,\n",
      "as the performance difference is minimal (<2%).\n",
      "\n",
      "######################################################################\n",
      "Running comparison for Logistic Regression\n",
      "######################################################################\n",
      "\n",
      "Tuning Logistic Regression with product type features...\n",
      "Fitting 10 folds for each of 36 candidates, totalling 360 fits\n",
      "\n",
      "Tuning Logistic Regression without product type features...\n",
      "Fitting 10 folds for each of 36 candidates, totalling 360 fits\n",
      "\n",
      "==================================================\n",
      "Comparison Results for Logistic Regression\n",
      "==================================================\n",
      "\n",
      "Results with product type:\n",
      "Best score: 0.9056\n",
      "Best parameters: {'C': 10, 'multi_class': 'auto', 'solver': 'lbfgs'}\n",
      "\n",
      "Results without product type:\n",
      "Best score: 0.8833\n",
      "Best parameters: {'C': 100, 'multi_class': 'auto', 'solver': 'lbfgs'}\n",
      "\n",
      "Performance difference (with - without): 0.0222\n",
      "\n",
      "Recommendation: Consider using the model with product type,\n",
      "as it shows significantly better performance.\n",
      "\n",
      "Model Performance Summary:\n",
      "================================================================================\n",
      "\n",
      "With Product Type Features:\n",
      "----------------------------------------\n",
      "\n",
      "SVM:\n",
      "Best Score: 0.9556\n",
      "Best Parameters: {'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "\n",
      "Random Forest:\n",
      "Best Score: 0.9944\n",
      "Best Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "\n",
      "KNN:\n",
      "Best Score: 0.9389\n",
      "Best Parameters: {'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "\n",
      "Neural Network:\n",
      "Best Score: 0.9222\n",
      "Best Parameters: {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50,), 'learning_rate': 'constant'}\n",
      "\n",
      "Logistic Regression:\n",
      "Best Score: 0.9056\n",
      "Best Parameters: {'C': 10, 'multi_class': 'auto', 'solver': 'lbfgs'}\n",
      "\n",
      "Without Product Type Features:\n",
      "----------------------------------------\n",
      "\n",
      "SVM:\n",
      "Best Score: 0.9500\n",
      "Best Parameters: {'C': 100, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "\n",
      "Random Forest:\n",
      "Best Score: 0.9944\n",
      "Best Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "\n",
      "KNN:\n",
      "Best Score: 0.9389\n",
      "Best Parameters: {'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "\n",
      "Neural Network:\n",
      "Best Score: 0.9278\n",
      "Best Parameters: {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant'}\n",
      "\n",
      "Logistic Regression:\n",
      "Best Score: 0.8833\n",
      "Best Parameters: {'C': 100, 'multi_class': 'auto', 'solver': 'lbfgs'}\n",
      "\n",
      "Results have been saved to 'storage_condition_results.json'\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Imports and Setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import json\n",
    "from hyperparameter_tuning import get_param_grids, run_all_models_comparison\n",
    "\n",
    "# Constants\n",
    "RANDOM_STATE = 42\n",
    "CV_SPLITS = 10\n",
    "\n",
    "# Cell 2: Load and Prepare Data\n",
    "print(\"Loading and preparing data...\")\n",
    "data = pd.read_csv('augmented_bakery_data.csv')\n",
    "\n",
    "# Encode labels\n",
    "le_product = LabelEncoder()\n",
    "le_storage = LabelEncoder()\n",
    "data['Product_Type_encoded'] = le_product.fit_transform(data['Product_Type'])\n",
    "data['Storage_Condition_encoded'] = le_storage.fit_transform(data['Storage_Condition'])\n",
    "\n",
    "# Prepare features\n",
    "spectral_cols = [col for col in data.columns if col.startswith(('gain_', 'phase_'))]\n",
    "X_spectral = data[spectral_cols]\n",
    "product_type = data['Product_Type_encoded'].values.reshape(-1, 1)\n",
    "\n",
    "# Scale spectral features\n",
    "scaler = StandardScaler()\n",
    "X_spectral_scaled = scaler.fit_transform(X_spectral)\n",
    "\n",
    "# Prepare datasets\n",
    "X_with_product = np.column_stack([X_spectral_scaled, product_type])\n",
    "X_without_product = X_spectral_scaled\n",
    "\n",
    "# Target variable\n",
    "y_storage = data['Storage_Condition_encoded'].values\n",
    "\n",
    "print(f\"Dataset shapes:\")\n",
    "print(f\"X without product type: {X_without_product.shape}\")\n",
    "print(f\"X with product type: {X_with_product.shape}\")\n",
    "print(f\"Number of storage conditions: {len(np.unique(y_storage))}\")\n",
    "print(f\"Storage conditions: {dict(zip(le_storage.classes_, le_storage.transform(le_storage.classes_)))}\")\n",
    "\n",
    "# Cell 3: Run Tuning\n",
    "print(\"\\nRunning hyperparameter tuning...\")\n",
    "all_results = run_all_models_comparison(X_with_product, X_without_product, y_storage)\n",
    "\n",
    "# Cell 4: Save Results and Display Summary\n",
    "results_summary = {\n",
    "    'with_product_type': {},\n",
    "    'without_product_type': {}\n",
    "}\n",
    "\n",
    "print(\"\\nModel Performance Summary:\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nWith Product Type Features:\")\n",
    "print(\"-\" * 40)\n",
    "for model_name, results in all_results.items():\n",
    "    score = results['with_product_type']['best_score']\n",
    "    params = results['with_product_type']['best_params']\n",
    "    results_summary['with_product_type'][model_name] = {\n",
    "        'best_params': params,\n",
    "        'best_score': score\n",
    "    }\n",
    "    print(f\"\\n{model_name}:\")\n",
    "    print(f\"Best Score: {score:.4f}\")\n",
    "    print(f\"Best Parameters: {params}\")\n",
    "\n",
    "print(\"\\nWithout Product Type Features:\")\n",
    "print(\"-\" * 40)\n",
    "for model_name, results in all_results.items():\n",
    "    score = results['without_product_type']['best_score']\n",
    "    params = results['without_product_type']['best_params']\n",
    "    results_summary['without_product_type'][model_name] = {\n",
    "        'best_params': params,\n",
    "        'best_score': score\n",
    "    }\n",
    "    print(f\"\\n{model_name}:\")\n",
    "    print(f\"Best Score: {score:.4f}\")\n",
    "    print(f\"Best Parameters: {params}\")\n",
    "\n",
    "# Save the results\n",
    "with open('storage_condition_results.json', 'w') as f:\n",
    "    json.dump(results_summary, f, indent=4)\n",
    "\n",
    "print(\"\\nResults have been saved to 'storage_condition_results.json'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Product type tunning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing data...\n",
      "Dataset shapes:\n",
      "X without storage condition: (180, 202)\n",
      "X with storage condition: (180, 203)\n",
      "Number of product types: 2\n",
      "Product types: {'Bread': 0, 'Cookies': 1}\n",
      "\n",
      "Running hyperparameter tuning for product type classification...\n",
      "\n",
      "######################################################################\n",
      "Running comparison for SVM\n",
      "######################################################################\n",
      "\n",
      "Tuning SVM with product type features...\n",
      "Fitting 10 folds for each of 32 candidates, totalling 320 fits\n",
      "\n",
      "Tuning SVM without product type features...\n",
      "Fitting 10 folds for each of 32 candidates, totalling 320 fits\n",
      "\n",
      "==================================================\n",
      "Comparison Results for SVM\n",
      "==================================================\n",
      "\n",
      "Results with product type:\n",
      "Best score: 1.0000\n",
      "Best parameters: {'C': 100, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "\n",
      "Results without product type:\n",
      "Best score: 0.9833\n",
      "Best parameters: {'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "\n",
      "Performance difference (with - without): 0.0167\n",
      "\n",
      "Recommendation: Consider using the model without product type for better generalization,\n",
      "as the performance difference is minimal (<2%).\n",
      "\n",
      "######################################################################\n",
      "Running comparison for Random Forest\n",
      "######################################################################\n",
      "\n",
      "Tuning Random Forest with product type features...\n",
      "Fitting 10 folds for each of 108 candidates, totalling 1080 fits\n",
      "\n",
      "Tuning Random Forest without product type features...\n",
      "Fitting 10 folds for each of 108 candidates, totalling 1080 fits\n",
      "\n",
      "==================================================\n",
      "Comparison Results for Random Forest\n",
      "==================================================\n",
      "\n",
      "Results with product type:\n",
      "Best score: 0.9889\n",
      "Best parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "\n",
      "Results without product type:\n",
      "Best score: 0.9889\n",
      "Best parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "\n",
      "Performance difference (with - without): 0.0000\n",
      "\n",
      "Recommendation: Consider using the model without product type for better generalization,\n",
      "as the performance difference is minimal (<2%).\n",
      "\n",
      "######################################################################\n",
      "Running comparison for KNN\n",
      "######################################################################\n",
      "\n",
      "Tuning KNN with product type features...\n",
      "Fitting 10 folds for each of 16 candidates, totalling 160 fits\n",
      "\n",
      "Tuning KNN without product type features...\n",
      "Fitting 10 folds for each of 16 candidates, totalling 160 fits\n",
      "\n",
      "==================================================\n",
      "Comparison Results for KNN\n",
      "==================================================\n",
      "\n",
      "Results with product type:\n",
      "Best score: 0.9944\n",
      "Best parameters: {'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "\n",
      "Results without product type:\n",
      "Best score: 0.9889\n",
      "Best parameters: {'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'uniform'}\n",
      "\n",
      "Performance difference (with - without): 0.0056\n",
      "\n",
      "Recommendation: Consider using the model without product type for better generalization,\n",
      "as the performance difference is minimal (<2%).\n",
      "\n",
      "######################################################################\n",
      "Running comparison for Neural Network\n",
      "######################################################################\n",
      "\n",
      "Tuning Neural Network with product type features...\n",
      "Fitting 10 folds for each of 48 candidates, totalling 480 fits\n",
      "\n",
      "Tuning Neural Network without product type features...\n",
      "Fitting 10 folds for each of 48 candidates, totalling 480 fits\n",
      "\n",
      "==================================================\n",
      "Comparison Results for Neural Network\n",
      "==================================================\n",
      "\n",
      "Results with product type:\n",
      "Best score: 0.9889\n",
      "Best parameters: {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100, 50), 'learning_rate': 'constant'}\n",
      "\n",
      "Results without product type:\n",
      "Best score: 0.9889\n",
      "Best parameters: {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100, 50), 'learning_rate': 'constant'}\n",
      "\n",
      "Performance difference (with - without): 0.0000\n",
      "\n",
      "Recommendation: Consider using the model without product type for better generalization,\n",
      "as the performance difference is minimal (<2%).\n",
      "\n",
      "######################################################################\n",
      "Running comparison for Logistic Regression\n",
      "######################################################################\n",
      "\n",
      "Tuning Logistic Regression with product type features...\n",
      "Fitting 10 folds for each of 36 candidates, totalling 360 fits\n",
      "\n",
      "Tuning Logistic Regression without product type features...\n",
      "Fitting 10 folds for each of 36 candidates, totalling 360 fits\n",
      "\n",
      "==================================================\n",
      "Comparison Results for Logistic Regression\n",
      "==================================================\n",
      "\n",
      "Results with product type:\n",
      "Best score: 0.9944\n",
      "Best parameters: {'C': 10, 'multi_class': 'multinomial', 'solver': 'lbfgs'}\n",
      "\n",
      "Results without product type:\n",
      "Best score: 0.9889\n",
      "Best parameters: {'C': 100, 'multi_class': 'auto', 'solver': 'lbfgs'}\n",
      "\n",
      "Performance difference (with - without): 0.0056\n",
      "\n",
      "Recommendation: Consider using the model without product type for better generalization,\n",
      "as the performance difference is minimal (<2%).\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Imports and Setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import json\n",
    "from hyperparameter_tuning import get_param_grids, run_all_models_comparison\n",
    "\n",
    "# Constants\n",
    "RANDOM_STATE = 42\n",
    "CV_SPLITS = 10\n",
    "\n",
    "# Cell 2: Load and Prepare Data\n",
    "print(\"Loading and preparing data...\")\n",
    "data = pd.read_csv('augmented_bakery_data.csv')\n",
    "\n",
    "# Encode labels\n",
    "le_product = LabelEncoder()\n",
    "le_storage = LabelEncoder()\n",
    "data['Product_Type_encoded'] = le_product.fit_transform(data['Product_Type'])\n",
    "data['Storage_Condition_encoded'] = le_storage.fit_transform(data['Storage_Condition'])\n",
    "\n",
    "# Separate spectral features and storage condition\n",
    "spectral_cols = [col for col in data.columns if col.startswith(('gain_', 'phase_'))]\n",
    "X_spectral = data[spectral_cols]\n",
    "storage_condition = data['Storage_Condition_encoded'].values.reshape(-1, 1)\n",
    "\n",
    "# Scale spectral features\n",
    "scaler = StandardScaler()\n",
    "X_spectral_scaled = scaler.fit_transform(X_spectral)\n",
    "\n",
    "# Prepare two versions of the dataset\n",
    "X_without_storage = X_spectral_scaled\n",
    "X_with_storage = np.column_stack([X_spectral_scaled, storage_condition])  # Storage condition remains unscaled\n",
    "\n",
    "# Target variable (now product type)\n",
    "y_product = data['Product_Type_encoded'].values\n",
    "\n",
    "print(f\"Dataset shapes:\")\n",
    "print(f\"X without storage condition: {X_without_storage.shape}\")\n",
    "print(f\"X with storage condition: {X_with_storage.shape}\")\n",
    "print(f\"Number of product types: {len(np.unique(y_product))}\")\n",
    "print(f\"Product types: {dict(zip(le_product.classes_, le_product.transform(le_product.classes_)))}\")\n",
    "\n",
    "# Cell 3: Run Tuning\n",
    "print(\"\\nRunning hyperparameter tuning for product type classification...\")\n",
    "all_results = run_all_models_comparison(X_with_storage, X_without_storage, y_product)\n",
    "\n",
    "# Cell 4: Save Results\n",
    "Product_type_parameters_summary = {\n",
    "    'with_storage_condition': {},\n",
    "    'without_storage_condition': {}\n",
    "}\n",
    "\n",
    "# Extract best parameters and scores for each model\n",
    "for model_name, results in all_results.items():\n",
    "    Product_type_parameters_summary['with_storage_condition'][model_name] = results['with_product_type']['best_params'],  # Note: keys remain the same from the function\n",
    "    Product_type_parameters_summary['without_storage_condition'][model_name] =results['without_product_type']['best_params'],\n",
    "\n",
    "# Save the results\n",
    "with open('product_type_tuning_results.json', 'w') as f:\n",
    "    json.dump(Product_type_parameters_summary, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary of Best Results:\n",
      "==================================================\n",
      "\n",
      "With Storage Condition:\n",
      "\n",
      "SVM:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "tuple indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model, results \u001b[38;5;129;01min\u001b[39;00m Product_type_parameters_summary[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwith_storage_condition\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest Score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_score\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest Parameters: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_params\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mWithout Storage Condition:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: tuple indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "\n",
    "# Cell 5: Print Summary\n",
    "print(\"\\nSummary of Best Results:\")\n",
    "print(\"=\" * 50)\n",
    "print(\"\\nWith Storage Condition:\")\n",
    "for model, results in Product_type_parameters_summary['with_storage_condition'].items():\n",
    "    print(f\"\\n{model}:\")\n",
    "    print(f\"Best Score: {results['best_score']:.4f}\")\n",
    "    print(f\"Best Parameters: {results['best_params']}\")\n",
    "\n",
    "print(\"\\nWithout Storage Condition:\")\n",
    "for model, results in Product_type_parameters_summary['without_storage_condition'].items():\n",
    "    print(f\"\\n{model}:\")\n",
    "    print(f\"Best Score: {results['best_score']:.4f}\")\n",
    "    print(f\"Best Parameters: {results['best_params']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cell 5: Print Summary\n",
    "print(\"\\nSummary of Best Results:\")\n",
    "print(\"=\" * 50)\n",
    "print(\"\\nWith Storage Condition:\")\n",
    "for model, results in Product_type_parameters_summary['with_storage_condition'].items():\n",
    "    print(f\"\\n{model}:\")\n",
    "    print(f\"Best Score: {results['best_score']:.4f}\")\n",
    "    print(f\"Best Parameters: {results['best_params']}\")\n",
    "\n",
    "print(\"\\nWithout Storage Condition:\")\n",
    "for model, results in Product_type_parameters_summary['without_storage_condition'].items():\n",
    "    print(f\"\\n{model}:\")\n",
    "    print(f\"Best Score: {results['best_score']:.4f}\")\n",
    "    print(f\"Best Parameters: {results['best_params']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cell 2: Load and Prepare Data\n",
    "print(\"Loading and preparing data...\")\n",
    "data = pd.read_csv('augmented_bakery_data.csv')\n",
    "\n",
    "# Encode Product Type\n",
    "le_product = LabelEncoder()\n",
    "data['Product_Type_encoded'] = le_product.fit_transform(data['Product_Type'])\n",
    "\n",
    "# Encode Storage Conditions\n",
    "le_storage = LabelEncoder()\n",
    "data['Storage_Condition_encoded'] = le_storage.fit_transform(data['Storage_Condition'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cell 3: Prepare Features\n",
    "# Get features (gains and phases only)\n",
    "feature_cols = [col for col in data.columns if col.startswith(('gain_', 'phase_'))]\n",
    "X_base = data[feature_cols]\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_base)\n",
    "\n",
    "# Prepare datasets for both classifications\n",
    "X_with_product = np.column_stack([X_scaled, data['Product_Type_encoded'].values.reshape(-1, 1)])\n",
    "X_without_product = X_scaled\n",
    "y_storage = data['Storage_Condition_encoded']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cell 4: Run Comprehensive Model Comparison\n",
    "print(\"Running comprehensive model comparison...\")\n",
    "all_results = run_all_models_comparison(X_with_product, X_without_product, y_storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cell 5: Save Results\n",
    "# Create a more detailed results summary\n",
    "def create_results_summary(all_results):\n",
    "    summary = {\n",
    "        'model_comparisons': {}\n",
    "    }\n",
    "    \n",
    "    for model_name, results in all_results.items():\n",
    "        summary['model_comparisons'][model_name] = {\n",
    "            'with_product_type': {\n",
    "                'best_score': float(results['with_product_type']['best_score']),\n",
    "                'best_params': results['with_product_type']['best_params']\n",
    "            },\n",
    "            'without_product_type': {\n",
    "                'best_score': float(results['without_product_type']['best_score']),\n",
    "                'best_params': results['without_product_type']['best_params']\n",
    "            },\n",
    "            'performance_difference': float(\n",
    "                results['with_product_type']['best_score'] - \n",
    "                results['without_product_type']['best_score']\n",
    "            )\n",
    "        }\n",
    "    \n",
    "    return summary\n",
    "\n",
    "# Save results to JSON file\n",
    "results_summary = create_results_summary(all_results)\n",
    "with open('hyperparameter_tuning_results.json', 'w') as f:\n",
    "    json.dump(results_summary, f, indent=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cell 6: Find Best Overall Model\n",
    "def find_best_model(all_results):\n",
    "    best_score = -1\n",
    "    best_model = None\n",
    "    best_config = None\n",
    "    \n",
    "    for model_name, results in all_results.items():\n",
    "        with_score = results['with_product_type']['best_score']\n",
    "        without_score = results['without_product_type']['best_score']\n",
    "        \n",
    "        if with_score > best_score:\n",
    "            best_score = with_score\n",
    "            best_model = model_name\n",
    "            best_config = 'with_product_type'\n",
    "        \n",
    "        if without_score > best_score:\n",
    "            best_score = without_score\n",
    "            best_model = model_name\n",
    "            best_config = 'without_product_type'\n",
    "    \n",
    "    return best_model, best_config, best_score\n",
    "\n",
    "best_model, best_config, best_score = find_best_model(all_results)\n",
    "print(\"\\nBest Overall Model:\")\n",
    "print(f\"Model: {best_model}\")\n",
    "print(f\"Configuration: {best_config}\")\n",
    "print(f\"Score: {best_score:.4f}\")\n",
    "print(f\"Parameters: {all_results[best_model][best_config]['best_params']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Add this new cell\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_cv_score_distribution(X_with, X_without, y, model_name):\n",
    "    \"\"\"Plot distribution of cross-validation scores\"\"\"\n",
    "    # Get the best models\n",
    "    model_with = all_results[model_name]['with_product_type']['best_model']\n",
    "    model_without = all_results[model_name]['without_product_type']['best_model']\n",
    "    \n",
    "    # Get cross-validation scores\n",
    "    scores_with = cross_val_score(model_with, X_with, y, cv=10)\n",
    "    scores_without = cross_val_score(model_without, X_without, y, cv=10)\n",
    "    \n",
    "    # Plot distributions\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.boxplot([scores_with, scores_without], labels=['With Product Type', 'Without Product Type'])\n",
    "    plt.title(f'{model_name} Cross-validation Score Distribution')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    # Print statistical summary\n",
    "    print(f\"\\nCross-validation scores summary for {model_name}:\")\n",
    "    print(\"\\nWith Product Type:\")\n",
    "    print(f\"Mean: {scores_with.mean():.4f}\")\n",
    "    print(f\"Std: {scores_with.std():.4f}\")\n",
    "    print(\"\\nWithout Product Type:\")\n",
    "    print(f\"Mean: {scores_without.mean():.4f}\")\n",
    "    print(f\"Std: {scores_without.std():.4f}\")\n",
    "\n",
    "# Plot CV score distribution for Random Forest\n",
    "plot_cv_score_distribution(X_with_product, X_without_product, y_storage, 'Random Forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
