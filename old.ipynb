{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Constants\n",
    "RANDOM_STATE = 42\n",
    "CV_SPLITS = 10\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, title=\"Confusion Matrix\"):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "def load_best_parameters():\n",
    "    \"\"\"Load best parameters from JSON file\"\"\"\n",
    "    with open('best_parameters.json', 'r') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def prepare_data():\n",
    "    \"\"\"Load and prepare data consistently\"\"\"\n",
    "    print(\"Loading data and preparing features...\")\n",
    "    data = pd.read_csv('augmented_bakery_data.csv')\n",
    "    \n",
    "    # Encode labels\n",
    "    le_product = LabelEncoder()\n",
    "    le_storage = LabelEncoder()\n",
    "    data['Product_Type_encoded'] = le_product.fit_transform(data['Product_Type'])\n",
    "    data['Storage_Condition_encoded'] = le_storage.fit_transform(data['Storage_Condition'])\n",
    "    \n",
    "    # Prepare features\n",
    "    feature_cols = [col for col in data.columns if col.startswith(('gain_', 'phase_'))]\n",
    "    X_base = data[feature_cols]\n",
    "    \n",
    "    # Scale features on entire dataset\n",
    "    scaler = StandardScaler()\n",
    "    X_base_scaled = scaler.fit_transform(X_base)\n",
    "    \n",
    "    # Prepare datasets\n",
    "    X_without_product = X_base_scaled\n",
    "    X_with_product = np.column_stack([X_base_scaled, data['Product_Type_encoded'].values.reshape(-1, 1)])\n",
    "    y_storage = data['Storage_Condition_encoded'].values\n",
    "    \n",
    "    return X_with_product, X_without_product, y_storage, le_storage.classes_\n",
    "\n",
    "def classify_model(model, features, target, model_name, return_accuracy=False):\n",
    "    \"\"\"Performs classification with the given model\"\"\"\n",
    "    # Use the same CV strategy as in hyperparameter tuning\n",
    "    cv = StratifiedKFold(n_splits=CV_SPLITS, shuffle=True, random_state=RANDOM_STATE)\n",
    "    \n",
    "    # Expected accuracies from hyperparameter tuning\n",
    "    expected_accuracies = {\n",
    "        'svm': 0.950 if features.shape[1] > X_without_product.shape[1] else 0.917,\n",
    "        'rf': 0.967,\n",
    "        'knn': 0.906,\n",
    "        'mlp': 0.867 if features.shape[1] > X_without_product.shape[1] else 0.922,\n",
    "        'lr': 0.889\n",
    "    }\n",
    "    \n",
    "    # Perform cross-validation\n",
    "    cv_scores = cross_val_score(model, features, target, cv=cv, scoring='accuracy', n_jobs=-1)\n",
    "    mean_accuracy = cv_scores.mean()\n",
    "    std_accuracy = cv_scores.std()\n",
    "    \n",
    "    print(f\"\\n{model_name.upper()} Classification Results:\")\n",
    "    print(f\"Cross-Validation Scores: {cv_scores}\")\n",
    "    print(f\"Mean CV Accuracy: {mean_accuracy:.4f} Â± {std_accuracy:.4f}\")\n",
    "    print(f\"Expected Accuracy: {expected_accuracies.get(model_name.lower(), 'N/A')}\")\n",
    "    \n",
    "    # Predict using cross-validation\n",
    "    y_pred = cross_val_predict(model, features, target, cv=cv, n_jobs=-1)\n",
    "    plot_confusion_matrix(target, y_pred, title=f\"{model_name.upper()} Confusion Matrix\")\n",
    "    print(classification_report(target, y_pred))\n",
    "    \n",
    "    if return_accuracy:\n",
    "        return mean_accuracy\n",
    "\n",
    "def run_classification(features, target, params, scenario='with_product_type'):\n",
    "    \"\"\"Run classification for all models\"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    # Create and run models\n",
    "    models = {\n",
    "        'SVM': SVC(**params[scenario]['SVM'], random_state=RANDOM_STATE),\n",
    "        'Random Forest': RandomForestClassifier(**params[scenario]['Random Forest'], random_state=RANDOM_STATE),\n",
    "        'KNN': KNeighborsClassifier(**params[scenario]['KNN']),\n",
    "        'Neural Network': MLPClassifier(**params[scenario]['Neural Network'], random_state=RANDOM_STATE),\n",
    "        'Logistic Regression': LogisticRegression(**params[scenario]['Logistic Regression'], random_state=RANDOM_STATE)\n",
    "    }\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        print(f\"\\nRunning {name}...\")\n",
    "        acc = classify_model(model, features, target, name.lower().replace(' ', '_'), return_accuracy=True)\n",
    "        results[name] = acc\n",
    "    \n",
    "    return results\n",
    "\n",
    "def plot_accuracy_comparisons(results_without, results_with):\n",
    "    models = list(results_without.keys())\n",
    "    accuracies_without = list(results_without.values())\n",
    "    accuracies_with = list(results_with.values())\n",
    "    \n",
    "    x = np.arange(len(models))\n",
    "    width = 0.35\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    bars1 = ax.bar(x - width/2, accuracies_without, width, label='Without')\n",
    "    bars2 = ax.bar(x + width/2, accuracies_with, width, label='With')\n",
    "\n",
    "    ax.set_ylabel('Mean Accuracy')\n",
    "    ax.set_title('Model Comparison for Storage Condition Classification')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(models, rotation=45, ha='right')\n",
    "    ax.legend()\n",
    "\n",
    "    def autolabel(bars):\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            ax.annotate(f'{height:.3f}',\n",
    "                       xy=(bar.get_x() + bar.get_width()/2, height),\n",
    "                       xytext=(0, 3),\n",
    "                       textcoords=\"offset points\",\n",
    "                       ha='center', va='bottom')\n",
    "\n",
    "    autolabel(bars1)\n",
    "    autolabel(bars2)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Load data and best parameters\n",
    "    X_with_product, X_without_product, y_storage, class_labels = prepare_data()\n",
    "    best_params = load_best_parameters()\n",
    "    \n",
    "    # Run classifications\n",
    "    print(\"\\nRunning classification without Product Type...\")\n",
    "    results_without_product = run_classification(X_without_product, y_storage, best_params, 'without_product_type')\n",
    "    \n",
    "    print(\"\\nRunning classification with Product Type...\")\n",
    "    results_with_product = run_classification(X_with_product, y_storage, best_params, 'with_product_type')\n",
    "    \n",
    "    # Plot results\n",
    "    plot_accuracy_comparisons(results_without_product, results_with_product)\n",
    "    \n",
    "    # Save results\n",
    "    results = {\n",
    "        'without_product_type': results_without_product,\n",
    "        'with_product_type': results_with_product\n",
    "    }\n",
    "    \n",
    "    with open('classification_results.json', 'w') as f:\n",
    "        json.dump(results, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, title=\"Confusion Matrix\"):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title(title)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_best_parameters():\n",
    "    \"\"\"Load best parameters from JSON file\"\"\"\n",
    "    with open('best_parameters.json', 'r') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def prepare_data():\n",
    "    \"\"\"Load and prepare data consistently\"\"\"\n",
    "    print(\"Loading data and preparing features...\")\n",
    "    data = pd.read_csv('augmented_bakery_data.csv')\n",
    "    \n",
    "    # Encode labels\n",
    "    le_product = LabelEncoder()\n",
    "    le_storage = LabelEncoder()\n",
    "    data['Product_Type_encoded'] = le_product.fit_transform(data['Product_Type'])\n",
    "    data['Storage_Condition_encoded'] = le_storage.fit_transform(data['Storage_Condition'])\n",
    "    \n",
    "    # Prepare features\n",
    "    feature_cols = [col for col in data.columns if col.startswith(('gain_', 'phase_'))]\n",
    "    X_base = data[feature_cols]\n",
    "    \n",
    "    # Scale features on entire dataset\n",
    "    scaler = StandardScaler()\n",
    "    X_base_scaled = scaler.fit_transform(X_base)\n",
    "    \n",
    "    # Prepare datasets\n",
    "    X_without_product = X_base_scaled\n",
    "    X_with_product = np.column_stack([X_base_scaled, data['Product_Type_encoded'].values.reshape(-1, 1)])\n",
    "    y_storage = data['Storage_Condition_encoded'].values\n",
    "    \n",
    "    return X_with_product, X_without_product, y_storage, le_storage.classes_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def classify_model(model, features, target, model_name, return_accuracy=False):\n",
    "    \"\"\"Performs classification with the given model\"\"\"\n",
    "    # Use the same CV strategy as in hyperparameter tuning\n",
    "    cv = StratifiedKFold(n_splits=CV_SPLITS, shuffle=True, random_state=RANDOM_STATE)\n",
    "    \n",
    "    # Expected accuracies from hyperparameter tuning\n",
    "    expected_accuracies = {\n",
    "        'svm': 0.950 if features.shape[1] > X_without_product.shape[1] else 0.917,\n",
    "        'rf': 0.967,\n",
    "        'knn': 0.906,\n",
    "        'mlp': 0.867 if features.shape[1] > X_without_product.shape[1] else 0.922,\n",
    "        'lr': 0.889\n",
    "    }\n",
    "    \n",
    "    # Perform cross-validation\n",
    "    cv_scores = cross_val_score(model, features, target, cv=cv, scoring='accuracy', n_jobs=-1)\n",
    "    mean_accuracy = cv_scores.mean()\n",
    "    std_accuracy = cv_scores.std()\n",
    "    \n",
    "    print(f\"\\n{model_name.upper()} Classification Results:\")\n",
    "    print(f\"Cross-Validation Scores: {cv_scores}\")\n",
    "    print(f\"Mean CV Accuracy: {mean_accuracy:.4f} Â± {std_accuracy:.4f}\")\n",
    "    print(f\"Expected Accuracy: {expected_accuracies.get(model_name.lower(), 'N/A')}\")\n",
    "    \n",
    "    # Predict using cross-validation\n",
    "    y_pred = cross_val_predict(model, features, target, cv=cv, n_jobs=-1)\n",
    "    plot_confusion_matrix(target, y_pred, title=f\"{model_name.upper()} Confusion Matrix\")\n",
    "    print(classification_report(target, y_pred))\n",
    "    \n",
    "    if return_accuracy:\n",
    "        return mean_accuracy\n",
    "\n",
    "def run_classification(features, target, params, scenario='with_product_type'):\n",
    "    \"\"\"Run classification for all models\"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    # Create and run models\n",
    "    models = {\n",
    "        'SVM': SVC(**params[scenario]['SVM'], random_state=RANDOM_STATE),\n",
    "        'Random Forest': RandomForestClassifier(**params[scenario]['Random Forest'], random_state=RANDOM_STATE),\n",
    "        'KNN': KNeighborsClassifier(**params[scenario]['KNN']),\n",
    "        'Neural Network': MLPClassifier(**params[scenario]['Neural Network'], random_state=RANDOM_STATE),\n",
    "        'Logistic Regression': LogisticRegression(**params[scenario]['Logistic Regression'], random_state=RANDOM_STATE)\n",
    "    }\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        print(f\"\\nRunning {name}...\")\n",
    "        acc = classify_model(model, features, target, name.lower().replace(' ', '_'), return_accuracy=True)\n",
    "        results[name] = acc\n",
    "    \n",
    "    return results\n",
    "\n",
    "def plot_accuracy_comparisons(results_without, results_with):\n",
    "    models = list(results_without.keys())\n",
    "    accuracies_without = list(results_without.values())\n",
    "    accuracies_with = list(results_with.values())\n",
    "    \n",
    "    x = np.arange(len(models))\n",
    "    width = 0.35\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    bars1 = ax.bar(x - width/2, accuracies_without, width, label='Without')\n",
    "    bars2 = ax.bar(x + width/2, accuracies_with, width, label='With')\n",
    "\n",
    "    ax.set_ylabel('Mean Accuracy')\n",
    "    ax.set_title('Model Comparison for Storage Condition Classification')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(models, rotation=45, ha='right')\n",
    "    ax.legend()\n",
    "\n",
    "    def autolabel(bars):\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            ax.annotate(f'{height:.3f}',\n",
    "                       xy=(bar.get_x() + bar.get_width()/2, height),\n",
    "                       xytext=(0, 3),\n",
    "                       textcoords=\"offset points\",\n",
    "                       ha='center', va='bottom')\n",
    "\n",
    "    autolabel(bars1)\n",
    "    autolabel(bars2)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Load data and best parameters\n",
    "    X_with_product, X_without_product, y_storage, class_labels = prepare_data()\n",
    "    best_params = load_best_parameters()\n",
    "    \n",
    "    # Run classifications\n",
    "    print(\"\\nRunning classification without Product Type...\")\n",
    "    results_without_product = run_classification(X_without_product, y_storage, best_params, 'without_product_type')\n",
    "    \n",
    "    print(\"\\nRunning classification with Product Type...\")\n",
    "    results_with_product = run_classification(X_with_product, y_storage, best_params, 'with_product_type')\n",
    "    \n",
    "    # Plot results\n",
    "    plot_accuracy_comparisons(results_without_product, results_with_product)\n",
    "    \n",
    "    # Save results\n",
    "    results = {\n",
    "        'without_product_type': results_without_product,\n",
    "        'with_product_type': results_with_product\n",
    "    }\n",
    "    \n",
    "    with open('classification_results.json', 'w') as f:\n",
    "        json.dump(results, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_classification(features, target, params, scenario='with_product_type'):\n",
    "    \"\"\"Run classification for all models\"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    # Create and run models\n",
    "    models = {\n",
    "        'SVM': SVC(**params[scenario]['SVM'], random_state=RANDOM_STATE),\n",
    "        'Random Forest': RandomForestClassifier(**params[scenario]['Random Forest'], random_state=RANDOM_STATE),\n",
    "        'KNN': KNeighborsClassifier(**params[scenario]['KNN']),\n",
    "        'Neural Network': MLPClassifier(**params[scenario]['Neural Network'], random_state=RANDOM_STATE),\n",
    "        'Logistic Regression': LogisticRegression(**params[scenario]['Logistic Regression'], random_state=RANDOM_STATE)\n",
    "    }\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        print(f\"\\nRunning {name}...\")\n",
    "        acc = classify_model(model, features, target, name.lower().replace(' ', '_'), return_accuracy=True)\n",
    "        results[name] = acc\n",
    "    \n",
    "    return results\n",
    "\n",
    "def plot_accuracy_comparisons(results_without, results_with):\n",
    "    models = list(results_without.keys())\n",
    "    accuracies_without = list(results_without.values())\n",
    "    accuracies_with = list(results_with.values())\n",
    "    \n",
    "    x = np.arange(len(models))\n",
    "    width = 0.35\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    bars1 = ax.bar(x - width/2, accuracies_without, width, label='Without')\n",
    "    bars2 = ax.bar(x + width/2, accuracies_with, width, label='With')\n",
    "\n",
    "    ax.set_ylabel('Mean Accuracy')\n",
    "    ax.set_title('Model Comparison for Storage Condition Classification')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(models, rotation=45, ha='right')\n",
    "    ax.legend()\n",
    "\n",
    "    def autolabel(bars):\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            ax.annotate(f'{height:.3f}',\n",
    "                       xy=(bar.get_x() + bar.get_width()/2, height),\n",
    "                       xytext=(0, 3),\n",
    "                       textcoords=\"offset points\",\n",
    "                       ha='center', va='bottom')\n",
    "\n",
    "    autolabel(bars1)\n",
    "    autolabel(bars2)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Load data and best parameters\n",
    "    X_with_product, X_without_product, y_storage, class_labels = prepare_data()\n",
    "    best_params = load_best_parameters()\n",
    "    \n",
    "    # Run classifications\n",
    "    print(\"\\nRunning classification without Product Type...\")\n",
    "    results_without_product = run_classification(X_without_product, y_storage, best_params, 'without_product_type')\n",
    "    \n",
    "    print(\"\\nRunning classification with Product Type...\")\n",
    "    results_with_product = run_classification(X_with_product, y_storage, best_params, 'with_product_type')\n",
    "    \n",
    "    # Plot results\n",
    "    plot_accuracy_comparisons(results_without_product, results_with_product)\n",
    "    \n",
    "    # Save results\n",
    "    results = {\n",
    "        'without_product_type': results_without_product,\n",
    "        'with_product_type': results_with_product\n",
    "    }\n",
    "    \n",
    "    with open('classification_results.json', 'w') as f:\n",
    "        json.dump(results, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_accuracy_comparisons(results_without, results_with):\n",
    "    models = list(results_without.keys())\n",
    "    accuracies_without = list(results_without.values())\n",
    "    accuracies_with = list(results_with.values())\n",
    "    \n",
    "    x = np.arange(len(models))\n",
    "    width = 0.35\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    bars1 = ax.bar(x - width/2, accuracies_without, width, label='Without')\n",
    "    bars2 = ax.bar(x + width/2, accuracies_with, width, label='With')\n",
    "\n",
    "    ax.set_ylabel('Mean Accuracy')\n",
    "    ax.set_title('Model Comparison for Storage Condition Classification')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(models, rotation=45, ha='right')\n",
    "    ax.legend()\n",
    "\n",
    "    def autolabel(bars):\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            ax.annotate(f'{height:.3f}',\n",
    "                       xy=(bar.get_x() + bar.get_width()/2, height),\n",
    "                       xytext=(0, 3),\n",
    "                       textcoords=\"offset points\",\n",
    "                       ha='center', va='bottom')\n",
    "\n",
    "    autolabel(bars1)\n",
    "    autolabel(bars2)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Load data and best parameters\n",
    "    X_with_product, X_without_product, y_storage, class_labels = prepare_data()\n",
    "    best_params = load_best_parameters()\n",
    "    \n",
    "    # Run classifications\n",
    "    print(\"\\nRunning classification without Product Type...\")\n",
    "    results_without_product = run_classification(X_without_product, y_storage, best_params, 'without_product_type')\n",
    "    \n",
    "    print(\"\\nRunning classification with Product Type...\")\n",
    "    results_with_product = run_classification(X_with_product, y_storage, best_params, 'with_product_type')\n",
    "    \n",
    "    # Plot results\n",
    "    plot_accuracy_comparisons(results_without_product, results_with_product)\n",
    "    \n",
    "    # Save results\n",
    "    results = {\n",
    "        'without_product_type': results_without_product,\n",
    "        'with_product_type': results_with_product\n",
    "    }\n",
    "    \n",
    "    with open('classification_results.json', 'w') as f:\n",
    "        json.dump(results, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, learning_curve\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import json\n",
    "from itertools import cycle\n",
    "\n",
    "# Import models\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def plot_learning_curves(model, X, y, title=\"Learning Curves\"):\n",
    "    \"\"\"Plot learning curves for a given model\"\"\"\n",
    "    train_sizes = np.linspace(0.1, 1.0, 10)\n",
    "    cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    train_sizes, train_scores, val_scores = learning_curve(\n",
    "        model, X, y, train_sizes=train_sizes, cv=cv, n_jobs=-1,\n",
    "        scoring='accuracy'\n",
    "    )\n",
    "    \n",
    "    train_mean = np.mean(train_scores, axis=1)\n",
    "    train_std = np.std(train_scores, axis=1)\n",
    "    val_mean = np.mean(val_scores, axis=1)\n",
    "    val_std = np.std(val_scores, axis=1)\n",
    "    \n",
    "    plt.plot(train_sizes, train_mean, label='Training Score', color='blue', marker='o')\n",
    "    plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.15, color='blue')\n",
    "    \n",
    "    plt.plot(train_sizes, val_mean, label='Cross-validation Score', color='red', marker='o')\n",
    "    plt.fill_between(train_sizes, val_mean - val_std, val_mean + val_std, alpha=0.15, color='red')\n",
    "    \n",
    "    plt.xlabel('Training Examples')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title(title)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Add final scores to plot\n",
    "    plt.text(0.02, 0.02, f'Final training score: {train_mean[-1]:.4f} Â± {train_std[-1]:.4f}',\n",
    "             transform=plt.gca().transAxes)\n",
    "    plt.text(0.02, 0.06, f'Final validation score: {val_mean[-1]:.4f} Â± {val_std[-1]:.4f}',\n",
    "             transform=plt.gca().transAxes)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def analyze_model_performance(model, X_with, X_without, y, model_name, class_labels):\n",
    "    \"\"\"Detailed analysis of a single model's performance\"\"\"\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Detailed Analysis for {model_name}\")\n",
    "    print('='*50)\n",
    "    \n",
    "    # 1. Cross-validation scores\n",
    "    cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Without product type\n",
    "    scores_without = cross_val_score(model, X_without, y, cv=cv)\n",
    "    y_pred_without = cross_val_predict(model, X_without, y, cv=cv)\n",
    "    \n",
    "    # With product type\n",
    "    scores_with = cross_val_score(model, X_with, y, cv=cv)\n",
    "    y_pred_with = cross_val_predict(model, X_with, y, cv=cv)\n",
    "    \n",
    "    # Statistical comparison\n",
    "    t_stat, p_value = stats.ttest_ind(scores_with, scores_without)\n",
    "    \n",
    "    print(\"\\nPerformance Metrics:\")\n",
    "    print(f\"Without Product Type: {scores_without.mean():.4f} Â± {scores_without.std():.4f}\")\n",
    "    print(f\"With Product Type: {scores_with.mean():.4f} Â± {scores_with.std():.4f}\")\n",
    "    print(f\"P-value: {p_value:.4f}\")\n",
    "    print(f\"Significant difference: {p_value < 0.05}\")\n",
    "    \n",
    "    # 2. Confusion Matrices\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    plt.subplot(121)\n",
    "    cm_without = confusion_matrix(y, y_pred_without)\n",
    "    sns.heatmap(cm_without, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(f'{model_name} - Without Product Type')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    \n",
    "    plt.subplot(122)\n",
    "    cm_with = confusion_matrix(y, y_pred_with)\n",
    "    sns.heatmap(cm_with, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(f'{model_name} - With Product Type')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 3. Classification Reports\n",
    "\n",
    "    # 4. Model-specific analysis\n",
    "    if model_name == \"Random Forest\":\n",
    "        model.fit(X_with, y)\n",
    "        # Create feature names\n",
    "        feature_names = [f'Feature_{i+1}' for i in range(X_with.shape[1])]\n",
    "        feature_importance = pd.DataFrame({\n",
    "            'feature': feature_names,\n",
    "            'importance': model.feature_importances_\n",
    "        }).sort_values('importance', ascending=False)\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.barplot(data=feature_importance.head(10), x='importance', y='feature')\n",
    "        plt.title('Top 10 Most Important Features')\n",
    "        plt.show()\n",
    "    \n",
    "    elif model_name == \"Neural Network\":\n",
    "        plot_learning_curves(model, X_with, y, f\"Learning Curves - {model_name}\")\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Load your data and prepare features\n",
    "    X_with_product, X_without_product, y_storage, class_labels = prepare_data()\n",
    "    \n",
    "    # Load best parameters and create models\n",
    "    best_params = load_best_parameters()\n",
    "    models = {\n",
    "        'SVM': SVC(**best_params['with_product_type']['SVM']),\n",
    "        'Random Forest': RandomForestClassifier(**best_params['with_product_type']['Random Forest']),\n",
    "        'KNN': KNeighborsClassifier(**best_params['with_product_type']['KNN']),\n",
    "        'Neural Network': MLPClassifier(**best_params['with_product_type']['Neural Network']),\n",
    "        'Logistic Regression': LogisticRegression(**best_params['with_product_type']['Logistic Regression'])\n",
    "    }\n",
    "    \n",
    "    # Perform detailed analysis for each model\n",
    "    for model_name, model in models.items():\n",
    "        analyze_model_performance(\n",
    "            model,\n",
    "            X_with_product,\n",
    "            X_without_product,\n",
    "            y_storage,\n",
    "            model_name,\n",
    "            class_labels\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, learning_curve\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Classification models\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "class BakerySpectraClassifier:\n",
    "    def __init__(self):\n",
    "        self.models = {\n",
    "            'SVM': Pipeline([\n",
    "                ('scaler', StandardScaler()),\n",
    "                ('classifier', SVC(kernel='rbf', probability=True))\n",
    "            ]),\n",
    "            'Random Forest': Pipeline([\n",
    "                ('scaler', StandardScaler()),\n",
    "                ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "            ]),\n",
    "            'KNN': Pipeline([\n",
    "                ('scaler', StandardScaler()),\n",
    "                ('classifier', KNeighborsClassifier(n_neighbors=5))\n",
    "            ]),\n",
    "            'Neural Network': Pipeline([\n",
    "                ('scaler', StandardScaler()),\n",
    "                ('classifier', MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=1000, random_state=42))\n",
    "            ]),\n",
    "            'LDA': Pipeline([\n",
    "                ('scaler', StandardScaler()),\n",
    "                ('classifier', LinearDiscriminantAnalysis())\n",
    "            ])\n",
    "        }\n",
    "        \n",
    "    def load_s1p_file(self, file_path):\n",
    "        \"\"\"Load data from s1p file\"\"\"\n",
    "        data = np.loadtxt(file_path, skiprows=9)\n",
    "        freq = data[:, 0]  # 300-900 MHz range\n",
    "        gain = data[:, 1]\n",
    "        return freq, gain\n",
    "\n",
    "    def extract_features(self, gain):\n",
    "        \"\"\"Extract features from the gain data\"\"\"\n",
    "        features = []\n",
    "        # Statistical features\n",
    "        features.extend([\n",
    "            np.mean(gain),\n",
    "            np.std(gain),\n",
    "            np.max(gain),\n",
    "            np.min(gain),\n",
    "            np.median(gain),\n",
    "            np.percentile(gain, 25),\n",
    "            np.percentile(gain, 75)\n",
    "        ])\n",
    "        # Frequency domain features\n",
    "        fft_features = np.abs(np.fft.fft(gain))[:10]  # First 10 FFT coefficients\n",
    "        features.extend(fft_features)\n",
    "        \n",
    "        return features\n",
    "\n",
    "    def load_dataset(self):\n",
    "        \"\"\"Load and prepare the dataset\"\"\"\n",
    "        X_data = []\n",
    "        y_product = []  # Product type labels (A=bread, B=cookies)\n",
    "        y_storage = []  # Storage condition labels (1=Open, 2=Wrapped, 3=Humid)\n",
    "        \n",
    "        files = glob.glob('./RawData/Bakery/[A-B]_*_*.s1p')\n",
    "        frequencies = None\n",
    "        \n",
    "        for file_path in files:\n",
    "            # Extract metadata from filename\n",
    "            filename = os.path.basename(file_path)\n",
    "            product_type = filename[0]  # A or B\n",
    "            storage_condition = int(filename.split('_')[1])  # 1, 2, or 3\n",
    "            \n",
    "            # Load and process data\n",
    "            freq, gain = self.load_s1p_file(file_path)\n",
    "            if frequencies is None:\n",
    "                frequencies = freq\n",
    "            \n",
    "            # Extract features\n",
    "            features = self.extract_features(gain)\n",
    "            \n",
    "            X_data.append(features)\n",
    "            y_product.append(product_type)\n",
    "            y_storage.append(storage_condition)\n",
    "        \n",
    "        return np.array(X_data), np.array(y_product), np.array(y_storage), frequencies\n",
    "\n",
    "    def train_and_evaluate(self, X, y, task_name):\n",
    "        \"\"\"Train and evaluate all models\"\"\"\n",
    "        results = {}\n",
    "        \n",
    "        # Split data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42, stratify=y\n",
    "        )\n",
    "        \n",
    "        for name, model in self.models.items():\n",
    "            # Train model\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            # Evaluate\n",
    "            train_score = model.score(X_train, y_train)\n",
    "            test_score = model.score(X_test, y_test)\n",
    "            cv_scores = cross_val_score(model, X, y, cv=5)\n",
    "            \n",
    "            y_pred = model.predict(X_test)\n",
    "            \n",
    "            results[name] = {\n",
    "                'train_score': train_score,\n",
    "                'test_score': test_score,\n",
    "                'cv_scores': cv_scores,\n",
    "                'confusion_matrix': confusion_matrix(y_test, y_pred),\n",
    "                'classification_report': classification_report(y_test, y_pred)\n",
    "            }\n",
    "            \n",
    "            # Plot confusion matrix\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            sns.heatmap(results[name]['confusion_matrix'], annot=True, fmt='d', cmap='Blues')\n",
    "            plt.title(f'Confusion Matrix - {name} ({task_name})')\n",
    "            plt.ylabel('True Label')\n",
    "            plt.xlabel('Predicted Label')\n",
    "            plt.savefig(f'confusion_matrix_{task_name}_{name.replace(\" \", \"_\")}.png')\n",
    "            plt.close()\n",
    "            \n",
    "        return results\n",
    "\n",
    "    def plot_learning_curves(self, X, y, task_name):\n",
    "        \"\"\"Plot learning curves for all models\"\"\"\n",
    "        train_sizes = np.linspace(0.1, 1.0, 5)\n",
    "        \n",
    "        plt.figure(figsize=(15, 10))\n",
    "        for idx, (name, model) in enumerate(self.models.items(), 1):\n",
    "            train_sizes_abs, train_scores, test_scores = learning_curve(\n",
    "                model, X, y, train_sizes=train_sizes, cv=5, n_jobs=-1\n",
    "            )\n",
    "            \n",
    "            train_mean = np.mean(train_scores, axis=1)\n",
    "            train_std = np.std(train_scores, axis=1)\n",
    "            test_mean = np.mean(test_scores, axis=1)\n",
    "            test_std = np.std(test_scores, axis=1)\n",
    "            \n",
    "            plt.subplot(2, 3, idx)\n",
    "            plt.plot(train_sizes_abs, train_mean, label='Training score')\n",
    "            plt.plot(train_sizes_abs, test_mean, label='Cross-validation score')\n",
    "            plt.fill_between(train_sizes_abs, train_mean - train_std, train_mean + train_std, alpha=0.1)\n",
    "            plt.fill_between(train_sizes_abs, test_mean - test_std, test_mean + test_std, alpha=0.1)\n",
    "            plt.title(f'Learning Curve - {name}')\n",
    "            plt.xlabel('Training Examples')\n",
    "            plt.ylabel('Score')\n",
    "            plt.legend(loc='best')\n",
    "            plt.grid(True)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'learning_curves_{task_name}.png')\n",
    "        plt.close()\n",
    "\n",
    "def main():\n",
    "    # Initialize classifier\n",
    "    classifier = BakerySpectraClassifier()\n",
    "    \n",
    "    # Load dataset\n",
    "    print(\"Loading dataset...\")\n",
    "    X, y_product, y_storage, frequencies = classifier.load_dataset()\n",
    "    \n",
    "    # Product type classification\n",
    "    print(\"\\nTraining models for product type classification...\")\n",
    "    product_results = classifier.train_and_evaluate(X, y_product, \"Product_Type\")\n",
    "    classifier.plot_learning_curves(X, y_product, \"Product_Type\")\n",
    "    \n",
    "    # Storage condition classification\n",
    "    print(\"\\nTraining models for storage condition classification...\")\n",
    "    storage_results = classifier.train_and_evaluate(X, y_storage, \"Storage_Condition\")\n",
    "    classifier.plot_learning_curves(X, y_storage, \"Storage_Condition\")\n",
    "    \n",
    "    # Print results\n",
    "    print(\"\\nResults for Product Type Classification:\")\n",
    "    for name, result in product_results.items():\n",
    "        print(f\"\\n{name}:\")\n",
    "        print(f\"Train Score: {result['train_score']:.3f}\")\n",
    "        print(f\"Test Score: {result['test_score']:.3f}\")\n",
    "        print(f\"CV Scores Mean Â± Std: {np.mean(result['cv_scores']):.3f} Â± {np.std(result['cv_scores']):.3f}\")\n",
    "        print(\"\\nClassification Report:\")\n",
    "        print(result['classification_report'])\n",
    "    \n",
    "    print(\"\\nResults for Storage Condition Classification:\")\n",
    "    for name, result in storage_results.items():\n",
    "        print(f\"\\n{name}:\")\n",
    "        print(f\"Train Score: {result['train_score']:.3f}\")\n",
    "        print(f\"Test Score: {result['test_score']:.3f}\")\n",
    "        print(f\"CV Scores Mean Â± Std: {np.mean(result['cv_scores']):.3f} Â± {np.std(result['cv_scores']):.3f}\")\n",
    "        print(\"\\nClassification Report:\")\n",
    "        print(result['classification_report'])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data and preparing features...\n",
      "\n",
      "Analyzing feature importance...\n",
      "\n",
      "Top 10 most important features for Storage Classification:\n",
      "phase_28: 0.0232\n",
      "phase_0: 0.0216\n",
      "phase_64: 0.0165\n",
      "phase_61: 0.0158\n",
      "phase_2: 0.0153\n",
      "phase_91: 0.0152\n",
      "phase_63: 0.0151\n",
      "phase_36: 0.0141\n",
      "phase_32: 0.0130\n",
      "phase_62: 0.0128\n",
      "\n",
      "Top 10 most important features for Product Classification:\n",
      "phase_100: 0.0809\n",
      "gain_99: 0.0565\n",
      "gain_100: 0.0501\n",
      "phase_99: 0.0483\n",
      "phase_98: 0.0334\n",
      "phase_30: 0.0307\n",
      "gain_24: 0.0259\n",
      "phase_95: 0.0252\n",
      "gain_17: 0.0246\n",
      "gain_96: 0.0231\n",
      "\n",
      "Performing Storage Condition Classification (without Product Type)...\n",
      "\n",
      "SVM (without Product Type) - Storage Classification Results:\n",
      "CV Accuracy: 0.5611 Â± 0.1124\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.30      0.43        60\n",
      "           1       0.52      0.70      0.60        60\n",
      "           2       0.56      0.70      0.62        60\n",
      "\n",
      "    accuracy                           0.57       180\n",
      "   macro avg       0.61      0.57      0.55       180\n",
      "weighted avg       0.61      0.57      0.55       180\n",
      "\n",
      "\n",
      "Random Forest (without Product Type) - Storage Classification Results:\n",
      "CV Accuracy: 1.0000 Â± 0.0000\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        60\n",
      "           1       1.00      1.00      1.00        60\n",
      "           2       1.00      1.00      1.00        60\n",
      "\n",
      "    accuracy                           1.00       180\n",
      "   macro avg       1.00      1.00      1.00       180\n",
      "weighted avg       1.00      1.00      1.00       180\n",
      "\n",
      "\n",
      "KNN (without Product Type) - Storage Classification Results:\n",
      "CV Accuracy: 0.6278 Â± 0.1167\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        60\n",
      "           1       1.00      1.00      1.00        60\n",
      "           2       1.00      1.00      1.00        60\n",
      "\n",
      "    accuracy                           1.00       180\n",
      "   macro avg       1.00      1.00      1.00       180\n",
      "weighted avg       1.00      1.00      1.00       180\n",
      "\n",
      "\n",
      "Neural Network (without Product Type) - Storage Classification Results:\n",
      "CV Accuracy: 1.0000 Â± 0.0000\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        60\n",
      "           1       1.00      1.00      1.00        60\n",
      "           2       1.00      1.00      1.00        60\n",
      "\n",
      "    accuracy                           1.00       180\n",
      "   macro avg       1.00      1.00      1.00       180\n",
      "weighted avg       1.00      1.00      1.00       180\n",
      "\n",
      "\n",
      "Logistic Regression (without Product Type) - Storage Classification Results:\n",
      "CV Accuracy: 0.6833 Â± 0.1193\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.85      0.77        60\n",
      "           1       0.86      0.60      0.71        60\n",
      "           2       0.59      0.65      0.62        60\n",
      "\n",
      "    accuracy                           0.70       180\n",
      "   macro avg       0.72      0.70      0.70       180\n",
      "weighted avg       0.72      0.70      0.70       180\n",
      "\n",
      "\n",
      "Performing Storage Condition Classification (with Product Type)...\n",
      "\n",
      "SVM (with Product Type) - Storage Classification Results:\n",
      "CV Accuracy: 0.5611 Â± 0.1124\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.30      0.43        60\n",
      "           1       0.52      0.70      0.60        60\n",
      "           2       0.56      0.70      0.62        60\n",
      "\n",
      "    accuracy                           0.57       180\n",
      "   macro avg       0.61      0.57      0.55       180\n",
      "weighted avg       0.61      0.57      0.55       180\n",
      "\n",
      "\n",
      "Random Forest (with Product Type) - Storage Classification Results:\n",
      "CV Accuracy: 1.0000 Â± 0.0000\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        60\n",
      "           1       1.00      1.00      1.00        60\n",
      "           2       1.00      1.00      1.00        60\n",
      "\n",
      "    accuracy                           1.00       180\n",
      "   macro avg       1.00      1.00      1.00       180\n",
      "weighted avg       1.00      1.00      1.00       180\n",
      "\n",
      "\n",
      "KNN (with Product Type) - Storage Classification Results:\n",
      "CV Accuracy: 0.6278 Â± 0.1167\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        60\n",
      "           1       1.00      1.00      1.00        60\n",
      "           2       1.00      1.00      1.00        60\n",
      "\n",
      "    accuracy                           1.00       180\n",
      "   macro avg       1.00      1.00      1.00       180\n",
      "weighted avg       1.00      1.00      1.00       180\n",
      "\n",
      "\n",
      "Neural Network (with Product Type) - Storage Classification Results:\n",
      "CV Accuracy: 1.0000 Â± 0.0000\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        60\n",
      "           1       1.00      1.00      1.00        60\n",
      "           2       1.00      1.00      1.00        60\n",
      "\n",
      "    accuracy                           1.00       180\n",
      "   macro avg       1.00      1.00      1.00       180\n",
      "weighted avg       1.00      1.00      1.00       180\n",
      "\n",
      "\n",
      "Logistic Regression (with Product Type) - Storage Classification Results:\n",
      "CV Accuracy: 0.6833 Â± 0.1193\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.85      0.77        60\n",
      "           1       0.86      0.60      0.71        60\n",
      "           2       0.59      0.65      0.62        60\n",
      "\n",
      "    accuracy                           0.70       180\n",
      "   macro avg       0.72      0.70      0.70       180\n",
      "weighted avg       0.72      0.70      0.70       180\n",
      "\n",
      "\n",
      "Performing Product Type Classification...\n",
      "\n",
      "SVM - Product Type Classification Results:\n",
      "CV Accuracy: 0.9167 Â± 0.0569\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.84      0.92        90\n",
      "           1       0.87      1.00      0.93        90\n",
      "\n",
      "    accuracy                           0.92       180\n",
      "   macro avg       0.93      0.92      0.92       180\n",
      "weighted avg       0.93      0.92      0.92       180\n",
      "\n",
      "\n",
      "Random Forest - Product Type Classification Results:\n",
      "CV Accuracy: 0.9611 Â± 0.0356\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        90\n",
      "           1       1.00      1.00      1.00        90\n",
      "\n",
      "    accuracy                           1.00       180\n",
      "   macro avg       1.00      1.00      1.00       180\n",
      "weighted avg       1.00      1.00      1.00       180\n",
      "\n",
      "\n",
      "KNN - Product Type Classification Results:\n",
      "CV Accuracy: 0.9278 Â± 0.0500\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.91      0.95        90\n",
      "           1       0.92      0.99      0.95        90\n",
      "\n",
      "    accuracy                           0.95       180\n",
      "   macro avg       0.95      0.95      0.95       180\n",
      "weighted avg       0.95      0.95      0.95       180\n",
      "\n",
      "\n",
      "Neural Network - Product Type Classification Results:\n",
      "CV Accuracy: 0.9278 Â± 0.0558\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        90\n",
      "           1       1.00      1.00      1.00        90\n",
      "\n",
      "    accuracy                           1.00       180\n",
      "   macro avg       1.00      1.00      1.00       180\n",
      "weighted avg       1.00      1.00      1.00       180\n",
      "\n",
      "\n",
      "Logistic Regression - Product Type Classification Results:\n",
      "CV Accuracy: 0.9333 Â± 0.0416\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.92      0.95        90\n",
      "           1       0.93      0.99      0.96        90\n",
      "\n",
      "    accuracy                           0.96       180\n",
      "   macro avg       0.96      0.96      0.96       180\n",
      "weighted avg       0.96      0.96      0.96       180\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, learning_curve, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from scipy import stats, signal\n",
    "import glob\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Classification models\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Constants\n",
    "RANDOM_STATE = 42\n",
    "CV_SPLITS = 10\n",
    "\n",
    "class BakerySpectraClassifier:\n",
    "    def __init__(self):\n",
    "        self.models = {\n",
    "            'SVM': Pipeline([\n",
    "                ('scaler', StandardScaler()),\n",
    "                ('feature_selection', SelectKBest(score_func=f_classif, k=20)),\n",
    "                ('classifier', SVC(probability=True, random_state=RANDOM_STATE))\n",
    "            ]),\n",
    "            'Random Forest': Pipeline([\n",
    "                ('scaler', StandardScaler()),\n",
    "                ('feature_selection', SelectKBest(score_func=f_classif, k=20)),\n",
    "                ('classifier', RandomForestClassifier(n_estimators=100, random_state=RANDOM_STATE))\n",
    "            ]),\n",
    "            'KNN': Pipeline([\n",
    "                ('scaler', StandardScaler()),\n",
    "                ('feature_selection', SelectKBest(score_func=f_classif, k=20)),\n",
    "                ('classifier', KNeighborsClassifier(n_neighbors=5))\n",
    "            ]),\n",
    "            'Neural Network': Pipeline([\n",
    "                ('scaler', StandardScaler()),\n",
    "                ('feature_selection', SelectKBest(score_func=f_classif, k=20)),\n",
    "                ('classifier', MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=1000, random_state=RANDOM_STATE))\n",
    "            ]),\n",
    "            'Logistic Regression': Pipeline([\n",
    "                ('scaler', StandardScaler()),\n",
    "                ('feature_selection', SelectKBest(score_func=f_classif, k=20)),\n",
    "                ('classifier', LogisticRegression(random_state=RANDOM_STATE))\n",
    "            ])\n",
    "        }\n",
    "\n",
    "    def prepare_data(self):\n",
    "        \"\"\"Load and prepare data from augmented dataset\"\"\"\n",
    "        print(\"Loading data and preparing features...\")\n",
    "        data = pd.read_csv('augmented_bakery_data.csv')\n",
    "        \n",
    "        # Encode labels\n",
    "        le_product = LabelEncoder()\n",
    "        le_storage = LabelEncoder()\n",
    "        data['Product_Type_encoded'] = le_product.fit_transform(data['Product_Type'])\n",
    "        data['Storage_Condition_encoded'] = le_storage.fit_transform(data['Storage_Condition'])\n",
    "        \n",
    "        # Prepare features\n",
    "        feature_cols = [col for col in data.columns if col.startswith(('gain_', 'phase_'))]\n",
    "        X_base = data[feature_cols]\n",
    "        \n",
    "        # Scale features on entire dataset\n",
    "        scaler = StandardScaler()\n",
    "        X_base_scaled = scaler.fit_transform(X_base)\n",
    "        \n",
    "        # Prepare datasets\n",
    "        X_without_product = X_base_scaled\n",
    "        X_with_product = np.column_stack([X_base_scaled, data['Product_Type_encoded'].values.reshape(-1, 1)])\n",
    "        y_storage = data['Storage_Condition_encoded'].values\n",
    "        y_product = data['Product_Type_encoded'].values\n",
    "        \n",
    "        return X_with_product, X_without_product, y_product, y_storage, le_storage.classes_, feature_cols\n",
    "\n",
    "    def analyze_feature_importance(self, X, y, feature_names, task_name):\n",
    "        \"\"\"Analyze and visualize feature importance\"\"\"\n",
    "        rf = RandomForestClassifier(n_estimators=100, random_state=RANDOM_STATE)\n",
    "        rf.fit(X, y)\n",
    "        \n",
    "        importance = rf.feature_importances_\n",
    "        indices = np.argsort(importance)[::-1]\n",
    "        \n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.title(f\"Feature Importances for {task_name}\")\n",
    "        plt.bar(range(X.shape[1]), importance[indices])\n",
    "        plt.xticks(range(X.shape[1]), [feature_names[i] for i in indices], rotation=45, ha='right')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'feature_importance_{task_name.lower().replace(\" \", \"_\")}.png')\n",
    "        plt.close()\n",
    "        \n",
    "        print(f\"\\nTop 10 most important features for {task_name}:\")\n",
    "        for i in range(min(10, len(feature_names))):\n",
    "            print(f\"{feature_names[indices[i]]}: {importance[indices[i]]:.4f}\")\n",
    "\n",
    "    def plot_confusion_matrix(self, y_true, y_pred, title):\n",
    "        \"\"\"Plot confusion matrix\"\"\"\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "        plt.title(title)\n",
    "        plt.ylabel('True Label')\n",
    "        plt.xlabel('Predicted Label')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{title.lower().replace(\" \", \"_\")}.png')\n",
    "        plt.close()\n",
    "\n",
    "    def evaluate_model(self, model, X, y, model_name, task):\n",
    "        \"\"\"Evaluate a single model\"\"\"\n",
    "        cv = StratifiedKFold(n_splits=CV_SPLITS, shuffle=True, random_state=RANDOM_STATE)\n",
    "        \n",
    "        # Cross-validation scores\n",
    "        cv_scores = cross_val_score(model, X, y, cv=cv, n_jobs=-1)\n",
    "        y_pred = model.fit(X, y).predict(X)\n",
    "        \n",
    "        print(f\"\\n{model_name} - {task} Classification Results:\")\n",
    "        print(f\"CV Accuracy: {cv_scores.mean():.4f} Â± {cv_scores.std():.4f}\")\n",
    "        print(\"\\nClassification Report:\")\n",
    "        print(classification_report(y, y_pred))\n",
    "        \n",
    "        # Plot confusion matrix\n",
    "        self.plot_confusion_matrix(y, y_pred, f\"{model_name} - {task}\")\n",
    "        \n",
    "        return {\n",
    "            'cv_scores': cv_scores,\n",
    "            'confusion_matrix': confusion_matrix(y, y_pred),\n",
    "            'classification_report': classification_report(y, y_pred)\n",
    "        }\n",
    "\n",
    "    def plot_learning_curves(self, model, X, y, title):\n",
    "        \"\"\"Plot learning curves for a model\"\"\"\n",
    "        train_sizes = np.linspace(0.1, 1.0, 10)\n",
    "        cv = StratifiedKFold(n_splits=CV_SPLITS, shuffle=True, random_state=RANDOM_STATE)\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        train_sizes, train_scores, val_scores = learning_curve(\n",
    "            model, X, y, train_sizes=train_sizes, cv=cv, n_jobs=-1,\n",
    "            scoring='accuracy'\n",
    "        )\n",
    "        \n",
    "        train_mean = np.mean(train_scores, axis=1)\n",
    "        train_std = np.std(train_scores, axis=1)\n",
    "        val_mean = np.mean(val_scores, axis=1)\n",
    "        val_std = np.std(val_scores, axis=1)\n",
    "        \n",
    "        plt.plot(train_sizes, train_mean, label='Training Score', color='blue', marker='o')\n",
    "        plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.15, color='blue')\n",
    "        \n",
    "        plt.plot(train_sizes, val_mean, label='Cross-validation Score', color='red', marker='o')\n",
    "        plt.fill_between(train_sizes, val_mean - val_std, val_mean + val_std, alpha=0.15, color='red')\n",
    "        \n",
    "        plt.xlabel('Training Examples')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.title(title)\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.grid(True)\n",
    "        \n",
    "        # Add final scores to plot\n",
    "        plt.text(0.02, 0.02, f'Final training score: {train_mean[-1]:.4f} Â± {train_std[-1]:.4f}',\n",
    "                transform=plt.gca().transAxes)\n",
    "        plt.text(0.02, 0.06, f'Final validation score: {val_mean[-1]:.4f} Â± {val_std[-1]:.4f}',\n",
    "                transform=plt.gca().transAxes)\n",
    "        \n",
    "        plt.savefig(f'{title.lower().replace(\" \", \"_\")}.png')\n",
    "        plt.close()\n",
    "\n",
    "def main():\n",
    "    # Initialize classifier\n",
    "    classifier = BakerySpectraClassifier()\n",
    "    \n",
    "    # Load and prepare data\n",
    "    X_with_product, X_without_product, y_product, y_storage, class_labels, feature_names = classifier.prepare_data()\n",
    "    \n",
    "    # Analyze feature importance for both tasks\n",
    "    print(\"\\nAnalyzing feature importance...\")\n",
    "    classifier.analyze_feature_importance(X_without_product, y_storage, feature_names, \"Storage Classification\")\n",
    "    classifier.analyze_feature_importance(X_without_product, y_product, feature_names, \"Product Classification\")\n",
    "    \n",
    "    # Storage condition classification without product type\n",
    "    print(\"\\nPerforming Storage Condition Classification (without Product Type)...\")\n",
    "    storage_results_without = {}\n",
    "    for name, model in classifier.models.items():\n",
    "        storage_results_without[name] = classifier.evaluate_model(\n",
    "            model, X_without_product, y_storage, f\"{name} (without Product Type)\", \"Storage\"\n",
    "        )\n",
    "        classifier.plot_learning_curves(\n",
    "            model, X_without_product, y_storage,\n",
    "            f\"Learning Curves - {name} (Storage, without Product Type)\"\n",
    "        )\n",
    "    \n",
    "    # Storage condition classification with product type\n",
    "    print(\"\\nPerforming Storage Condition Classification (with Product Type)...\")\n",
    "    storage_results_with = {}\n",
    "    for name, model in classifier.models.items():\n",
    "        storage_results_with[name] = classifier.evaluate_model(\n",
    "            model, X_with_product, y_storage, f\"{name} (with Product Type)\", \"Storage\"\n",
    "        )\n",
    "        classifier.plot_learning_curves(\n",
    "            model, X_with_product, y_storage,\n",
    "            f\"Learning Curves - {name} (Storage, with Product Type)\"\n",
    "        )\n",
    "    \n",
    "    # Product type classification\n",
    "    print(\"\\nPerforming Product Type Classification...\")\n",
    "    product_results = {}\n",
    "    for name, model in classifier.models.items():\n",
    "        product_results[name] = classifier.evaluate_model(\n",
    "            model, X_without_product, y_product, name, \"Product Type\"\n",
    "        )\n",
    "        classifier.plot_learning_curves(\n",
    "            model, X_without_product, y_product,\n",
    "            f\"Learning Curves - {name} (Product Type)\"\n",
    "        )\n",
    "    \n",
    "    # Save results\n",
    "    results = {\n",
    "        'storage_without_product': {name: {\n",
    "            'cv_scores': list(res['cv_scores']),\n",
    "            'confusion_matrix': res['confusion_matrix'].tolist(),\n",
    "            'classification_report': res['classification_report']\n",
    "        } for name, res in storage_results_without.items()},\n",
    "        'storage_with_product': {name: {\n",
    "            'cv_scores': list(res['cv_scores']),\n",
    "            'confusion_matrix': res['confusion_matrix'].tolist(),\n",
    "            'classification_report': res['classification_report']\n",
    "        } for name, res in storage_results_with.items()},\n",
    "        'product_type': {name: {\n",
    "            'cv_scores': list(res['cv_scores']),\n",
    "            'confusion_matrix': res['confusion_matrix'].tolist(),\n",
    "            'classification_report': res['classification_report']\n",
    "        } for name, res in product_results.items()}\n",
    "    }\n",
    "    \n",
    "    with open('classification_results.json', 'w') as f:\n",
    "        json.dump(results, f, indent=4)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
