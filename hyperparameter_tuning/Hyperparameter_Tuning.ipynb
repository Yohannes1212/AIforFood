{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Common Imports and Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Common Imports and Constants\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "import json\n",
    "from hyperparameter_tuning import get_param_grids, run_all_models_comparison\n",
    "\n",
    "# Constants\n",
    "RANDOM_STATE = 42\n",
    "CV_SPLITS = 10\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking class balance...\n",
      "Class Distribution for Storage_Condition:\n",
      "Open: 60 samples (33.33%)\n",
      "Wrapped: 60 samples (33.33%)\n",
      "Humid: 60 samples (33.33%)\n",
      "\n",
      "Imbalance ratio: 1.0000\n",
      "Status: Well balanced (ratio > 0.8)\n",
      "Class Distribution for Product_Type:\n",
      "Bread: 90 samples (50.00%)\n",
      "Cookies: 90 samples (50.00%)\n",
      "\n",
      "Imbalance ratio: 1.0000\n",
      "Status: Well balanced (ratio > 0.8)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def check_class_balance(data, target_column):\n",
    "    \"\"\"Check class balance in the dataset\"\"\"\n",
    "    counts = data[target_column].value_counts()\n",
    "    percentages = data[target_column].value_counts(normalize=True) * 100\n",
    "    \n",
    "    print(f\"Class Distribution for {target_column}:\")\n",
    "    for label, count, percentage in zip(counts.index, counts, percentages):\n",
    "        print(f\"{label}: {count} samples ({percentage:.2f}%)\")\n",
    "    \n",
    "    # Calculate imbalance ratio\n",
    "    min_count = counts.min()\n",
    "    max_count = counts.max()\n",
    "    imbalance_ratio = min_count / max_count\n",
    "    \n",
    "    print(f\"\\nImbalance ratio: {imbalance_ratio:.4f}\")\n",
    "    if imbalance_ratio > 0.8:\n",
    "        print(\"Status: Well balanced (ratio > 0.8)\")\n",
    "    elif imbalance_ratio > 0.5:\n",
    "        print(\"Status: Moderately imbalanced (0.5 < ratio < 0.8)\")\n",
    "    else:\n",
    "        print(\"Status: Highly imbalanced (ratio < 0.5)\")\n",
    "    \n",
    "    return imbalance_ratio\n",
    "\n",
    "# Add this at the beginning of your notebook\n",
    "data = pd.read_csv('../augmented_bakery_data.csv')\n",
    "print(\"Checking class balance...\")\n",
    "check_class_balance(data, 'Storage_Condition')\n",
    "check_class_balance(data, 'Product_Type')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data preparation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_base_data():\n",
    "    \"\"\"Load and prepare initial data\"\"\"\n",
    "    print(\"Loading and preparing data...\")\n",
    "    data = pd.read_csv('../augmented_bakery_data.csv')\n",
    "    \n",
    "    # Encode labels\n",
    "    le_product = LabelEncoder()\n",
    "    le_storage = LabelEncoder()\n",
    "    data['Product_Type_encoded'] = le_product.fit_transform(data['Product_Type'])\n",
    "    data['Storage_Condition_encoded'] = le_storage.fit_transform(data['Storage_Condition'])\n",
    "    \n",
    "    # Prepare spectral features\n",
    "    spectral_cols = [col for col in data.columns if col.startswith(('gain_', 'phase_'))]\n",
    "    X_spectral = data[spectral_cols]\n",
    "    \n",
    "    # Scale spectral features\n",
    "    scaler = StandardScaler()\n",
    "    X_spectral_scaled = scaler.fit_transform(X_spectral)\n",
    "    \n",
    "    return data, X_spectral_scaled, le_product, le_storage\n",
    "\n",
    "def save_results(results, filename, with_label, without_label):\n",
    "    \"\"\"Save and display results\"\"\"\n",
    "    results_summary = {\n",
    "        with_label: {},\n",
    "        without_label: {}\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nModel Performance Summary:\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    for dataset_type in [with_label, without_label]:\n",
    "        print(f\"\\n{dataset_type.replace('_', ' ').title()}:\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        for model_name, model_results in results.items():\n",
    "            key = 'with_product_type' if 'with' in dataset_type else 'without_product_type'\n",
    "            # Get the parameters directly without the 'best_params' wrapper\n",
    "            params = model_results[key]['best_params']\n",
    "            \n",
    "            # Store parameters directly in the results summary\n",
    "            results_summary[dataset_type][model_name] = params\n",
    "            \n",
    "            print(f\"\\n{model_name}:\")\n",
    "            print(f\"Best Parameters: {params}\")\n",
    "    \n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(results_summary, f, indent=4)\n",
    "    print(f\"\\nResults have been saved to '{filename}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "def compare_models_statistically(all_results):\n",
    "    \"\"\"Perform statistical comparison between models with and without additional features\"\"\"\n",
    "    print(\"\\nStatistical Comparison of Models:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    for model_name, results in all_results.items():\n",
    "        # Get CV results\n",
    "        with_scores = results['with_product_type']['cv_results']['mean_test_score']\n",
    "        without_scores = results['without_product_type']['cv_results']['mean_test_score']\n",
    "        \n",
    "        # Perform paired t-test\n",
    "        t_stat, p_value = stats.ttest_rel(with_scores, without_scores)\n",
    "        \n",
    "        print(f\"\\n{model_name}:\")\n",
    "        print(f\"Mean with product type: {results['with_product_type']['best_score']:.4f}\")\n",
    "        print(f\"Mean without product type: {results['without_product_type']['best_score']:.4f}\")\n",
    "        print(f\"Difference: {results['with_product_type']['best_score'] - results['without_product_type']['best_score']:.4f}\")\n",
    "        print(f\"p-value: {p_value:.4f}\")\n",
    "        print(f\"Statistically significant difference: {'Yes' if p_value < 0.05 else 'No'}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Storage Condition Hyperparameter Tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Storage Condition Classification...\n",
      "Loading and preparing data...\n",
      "Dataset shapes:\n",
      "X without product type: (180, 202)\n",
      "X with product type: (180, 203)\n",
      "Storage conditions: {'Humid': 0, 'Open': 1, 'Wrapped': 2}\n",
      "\n",
      "######################################################################\n",
      "Running comparison for SVM\n",
      "######################################################################\n",
      "\n",
      "Tuning SVM with product_type...\n",
      "Using RandomizedSearchCV with 30 iterations for SVM\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "\n",
      "Best parameters for SVM:\n",
      "Mean CV accuracy: 0.9167\n",
      "Parameters: {'C': 89.06204386161681, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Train-Test gap: 0.0792\n",
      "\n",
      "Tuning SVM without product_type...\n",
      "Using RandomizedSearchCV with 30 iterations for SVM\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "\n",
      "Best parameters for SVM:\n",
      "Mean CV accuracy: 0.9000\n",
      "Parameters: {'C': 89.06204386161681, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Train-Test gap: 0.0944\n",
      "\n",
      "==================================================\n",
      "Comparison Results for SVM\n",
      "==================================================\n",
      "\n",
      "Results with product type:\n",
      "Best parameters: {'C': 89.06204386161681, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Mean CV accuracy: 0.9167\n",
      "\n",
      "Results without product type:\n",
      "Best parameters: {'C': 89.06204386161681, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Mean CV accuracy: 0.9000\n",
      "\n",
      "Performance difference (with - without): 0.0167\n",
      "\n",
      "Recommendation: Consider using the model without product type for better generalization,\n",
      "as the performance difference is minimal (<2%).\n",
      "\n",
      "######################################################################\n",
      "Running comparison for Random Forest\n",
      "######################################################################\n",
      "\n",
      "Tuning Random Forest with product_type...\n",
      "Using RandomizedSearchCV with 30 iterations for Random Forest\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "\n",
      "Best parameters for Random Forest:\n",
      "Mean CV accuracy: 0.9389\n",
      "Parameters: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 246}\n",
      "Train-Test gap: 0.0611\n",
      "\n",
      "Tuning Random Forest without product_type...\n",
      "Using RandomizedSearchCV with 30 iterations for Random Forest\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "\n",
      "Best parameters for Random Forest:\n",
      "Mean CV accuracy: 0.9556\n",
      "Parameters: {'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 51}\n",
      "Train-Test gap: 0.0444\n",
      "\n",
      "==================================================\n",
      "Comparison Results for Random Forest\n",
      "==================================================\n",
      "\n",
      "Results with product type:\n",
      "Best parameters: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 246}\n",
      "Mean CV accuracy: 0.9389\n",
      "\n",
      "Results without product type:\n",
      "Best parameters: {'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 51}\n",
      "Mean CV accuracy: 0.9556\n",
      "\n",
      "Performance difference (with - without): -0.0167\n",
      "\n",
      "Recommendation: Consider using the model without product type for better generalization,\n",
      "as the performance difference is minimal (<2%).\n",
      "\n",
      "######################################################################\n",
      "Running comparison for KNN\n",
      "######################################################################\n",
      "\n",
      "Tuning KNN with product_type...\n",
      "Using GridSearchCV for KNN\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "\n",
      "Best parameters for KNN:\n",
      "Mean CV accuracy: 0.8833\n",
      "Parameters: {'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "Train-Test gap: 0.1167\n",
      "\n",
      "Tuning KNN without product_type...\n",
      "Using GridSearchCV for KNN\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "\n",
      "Best parameters for KNN:\n",
      "Mean CV accuracy: 0.8833\n",
      "Parameters: {'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "Train-Test gap: 0.1167\n",
      "\n",
      "==================================================\n",
      "Comparison Results for KNN\n",
      "==================================================\n",
      "\n",
      "Results with product type:\n",
      "Best parameters: {'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "Mean CV accuracy: 0.8833\n",
      "\n",
      "Results without product type:\n",
      "Best parameters: {'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "Mean CV accuracy: 0.8833\n",
      "\n",
      "Performance difference (with - without): 0.0000\n",
      "\n",
      "Recommendation: Consider using the model without product type for better generalization,\n",
      "as the performance difference is minimal (<2%).\n",
      "\n",
      "######################################################################\n",
      "Running comparison for Neural Network\n",
      "######################################################################\n",
      "\n",
      "Tuning Neural Network with product_type...\n",
      "Using RandomizedSearchCV with 30 iterations for Neural Network\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "\n",
      "Best parameters for Neural Network:\n",
      "Mean CV accuracy: 0.7111\n",
      "Parameters: {'activation': 'relu', 'alpha': 0.008065429868602328, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.008319939418114052, 'solver': 'adam'}\n",
      "Train-Test gap: 0.0736\n",
      "\n",
      "Tuning Neural Network without product_type...\n",
      "Using RandomizedSearchCV with 30 iterations for Neural Network\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "\n",
      "Best parameters for Neural Network:\n",
      "Mean CV accuracy: 0.6111\n",
      "Parameters: {'activation': 'relu', 'alpha': 0.0032435598107632664, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.007955160864261276, 'solver': 'adam'}\n",
      "Train-Test gap: 0.0486\n",
      "\n",
      "==================================================\n",
      "Comparison Results for Neural Network\n",
      "==================================================\n",
      "\n",
      "Results with product type:\n",
      "Best parameters: {'activation': 'relu', 'alpha': 0.008065429868602328, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.008319939418114052, 'solver': 'adam'}\n",
      "Mean CV accuracy: 0.7111\n",
      "\n",
      "Results without product type:\n",
      "Best parameters: {'activation': 'relu', 'alpha': 0.0032435598107632664, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.007955160864261276, 'solver': 'adam'}\n",
      "Mean CV accuracy: 0.6111\n",
      "\n",
      "Performance difference (with - without): 0.1000\n",
      "\n",
      "Recommendation: Consider using the model with product type,\n",
      "as it shows significantly better performance.\n",
      "\n",
      "######################################################################\n",
      "Running comparison for Logistic Regression\n",
      "######################################################################\n",
      "\n",
      "Tuning Logistic Regression with product_type...\n",
      "Using RandomizedSearchCV with 30 iterations for Logistic Regression\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yohan\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters for Logistic Regression:\n",
      "Mean CV accuracy: 0.8556\n",
      "Parameters: {'C': 58.775116566384824, 'multi_class': 'ovr', 'penalty': None, 'solver': 'newton-cg'}\n",
      "Train-Test gap: 0.1444\n",
      "\n",
      "Tuning Logistic Regression without product_type...\n",
      "Using RandomizedSearchCV with 30 iterations for Logistic Regression\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "\n",
      "Best parameters for Logistic Regression:\n",
      "Mean CV accuracy: 0.8500\n",
      "Parameters: {'C': 58.775116566384824, 'multi_class': 'ovr', 'penalty': None, 'solver': 'newton-cg'}\n",
      "Train-Test gap: 0.1500\n",
      "\n",
      "==================================================\n",
      "Comparison Results for Logistic Regression\n",
      "==================================================\n",
      "\n",
      "Results with product type:\n",
      "Best parameters: {'C': 58.775116566384824, 'multi_class': 'ovr', 'penalty': None, 'solver': 'newton-cg'}\n",
      "Mean CV accuracy: 0.8556\n",
      "\n",
      "Results without product type:\n",
      "Best parameters: {'C': 58.775116566384824, 'multi_class': 'ovr', 'penalty': None, 'solver': 'newton-cg'}\n",
      "Mean CV accuracy: 0.8500\n",
      "\n",
      "Performance difference (with - without): 0.0056\n",
      "\n",
      "Recommendation: Consider using the model without product type for better generalization,\n",
      "as the performance difference is minimal (<2%).\n",
      "\n",
      "Model Performance Summary:\n",
      "================================================================================\n",
      "\n",
      "With Product Type:\n",
      "----------------------------------------\n",
      "\n",
      "SVM:\n",
      "Best Parameters: {'C': 89.06204386161681, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "\n",
      "Random Forest:\n",
      "Best Parameters: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 246}\n",
      "\n",
      "KNN:\n",
      "Best Parameters: {'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "\n",
      "Neural Network:\n",
      "Best Parameters: {'activation': 'relu', 'alpha': 0.008065429868602328, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.008319939418114052, 'solver': 'adam'}\n",
      "\n",
      "Logistic Regression:\n",
      "Best Parameters: {'C': 58.775116566384824, 'multi_class': 'ovr', 'penalty': None, 'solver': 'newton-cg'}\n",
      "\n",
      "Without Product Type:\n",
      "----------------------------------------\n",
      "\n",
      "SVM:\n",
      "Best Parameters: {'C': 89.06204386161681, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "\n",
      "Random Forest:\n",
      "Best Parameters: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 246}\n",
      "\n",
      "KNN:\n",
      "Best Parameters: {'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "\n",
      "Neural Network:\n",
      "Best Parameters: {'activation': 'relu', 'alpha': 0.008065429868602328, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.008319939418114052, 'solver': 'adam'}\n",
      "\n",
      "Logistic Regression:\n",
      "Best Parameters: {'C': 58.775116566384824, 'multi_class': 'ovr', 'penalty': None, 'solver': 'newton-cg'}\n",
      "\n",
      "Results have been saved to 'storage_condition_results.json'\n",
      "\n",
      "Statistical Comparison of Models:\n",
      "==================================================\n",
      "\n",
      "SVM:\n",
      "Mean with product type: 0.9167\n",
      "Mean without product type: 0.9000\n",
      "Difference: 0.0167\n",
      "p-value: 0.0000\n",
      "Statistically significant difference: Yes\n",
      "\n",
      "Random Forest:\n",
      "Mean with product type: 0.9389\n",
      "Mean without product type: 0.9556\n",
      "Difference: -0.0167\n",
      "p-value: 0.0000\n",
      "Statistically significant difference: Yes\n",
      "\n",
      "KNN:\n",
      "Mean with product type: 0.8833\n",
      "Mean without product type: 0.8833\n",
      "Difference: 0.0000\n",
      "p-value: 0.7183\n",
      "Statistically significant difference: No\n",
      "\n",
      "Neural Network:\n",
      "Mean with product type: 0.7111\n",
      "Mean without product type: 0.6111\n",
      "Difference: 0.1000\n",
      "p-value: 0.0000\n",
      "Statistically significant difference: Yes\n",
      "\n",
      "Logistic Regression:\n",
      "Mean with product type: 0.8556\n",
      "Mean without product type: 0.8500\n",
      "Difference: 0.0056\n",
      "p-value: 0.0000\n",
      "Statistically significant difference: Yes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yohan\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Cell 3: Storage Condition Classification\n",
    "print(\"Running Storage Condition Classification...\")\n",
    "data, X_spectral_scaled, le_product, le_storage = prepare_base_data()\n",
    "\n",
    "# Prepare datasets\n",
    "product_type = data['Product_Type_encoded'].values.reshape(-1, 1)\n",
    "X_with_product = np.column_stack([X_spectral_scaled, product_type])\n",
    "X_without_product = X_spectral_scaled\n",
    "y_storage = data['Storage_Condition_encoded'].values\n",
    "\n",
    "print(f\"Dataset shapes:\")\n",
    "print(f\"X without product type: {X_without_product.shape}\")\n",
    "print(f\"X with product type: {X_with_product.shape}\")\n",
    "print(f\"Storage conditions: {dict(zip(le_storage.classes_, le_storage.transform(le_storage.classes_)))}\")\n",
    "\n",
    "# Run tuning\n",
    "all_results = run_all_models_comparison(X_with_product, X_without_product, y_storage)\n",
    "save_results(all_results, 'storage_condition_results.json', 'with_product_type', 'without_product_type')\n",
    "# Add this after running the analysis\n",
    "compare_models_statistically(all_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Product Type Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Product Type Classification...\n",
      "Loading and preparing data...\n",
      "Dataset shapes:\n",
      "X without storage condition: (180, 202)\n",
      "X with storage condition: (180, 205)\n",
      "Product types: {'Bread': 0, 'Cookies': 1}\n",
      "\n",
      "######################################################################\n",
      "Running comparison for SVM\n",
      "######################################################################\n",
      "\n",
      "Tuning SVM with product_type...\n",
      "Using RandomizedSearchCV with 30 iterations for SVM\n",
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n",
      "\n",
      "Best parameters for SVM:\n",
      "Mean CV accuracy: 0.9889\n",
      "Parameters: {'C': 7.119418600172988, 'gamma': 'auto', 'kernel': 'linear'}\n",
      "Train-Test gap: 0.0111\n",
      "\n",
      "Tuning SVM without product_type...\n",
      "Using RandomizedSearchCV with 30 iterations for SVM\n",
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n",
      "\n",
      "Best parameters for SVM:\n",
      "Mean CV accuracy: 0.9833\n",
      "Parameters: {'C': 1.3292918943162162, 'gamma': 0.03576994933542223, 'kernel': 'rbf'}\n",
      "Train-Test gap: 0.0056\n",
      "\n",
      "==================================================\n",
      "Comparison Results for SVM\n",
      "==================================================\n",
      "\n",
      "Results with product type:\n",
      "Best parameters: {'C': 7.119418600172988, 'gamma': 'auto', 'kernel': 'linear'}\n",
      "Mean CV accuracy: 0.9889\n",
      "\n",
      "Results without product type:\n",
      "Best parameters: {'C': 1.3292918943162162, 'gamma': 0.03576994933542223, 'kernel': 'rbf'}\n",
      "Mean CV accuracy: 0.9833\n",
      "\n",
      "Performance difference (with - without): 0.0056\n",
      "\n",
      "Recommendation: Consider using the model without product type for better generalization,\n",
      "as the performance difference is minimal (<2%).\n",
      "\n",
      "######################################################################\n",
      "Running comparison for Random Forest\n",
      "######################################################################\n",
      "\n",
      "Tuning Random Forest with product_type...\n",
      "Using RandomizedSearchCV with 30 iterations for Random Forest\n",
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n",
      "\n",
      "Best parameters for Random Forest:\n",
      "Mean CV accuracy: 0.9889\n",
      "Parameters: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 137}\n",
      "Train-Test gap: 0.0111\n",
      "\n",
      "Tuning Random Forest without product_type...\n",
      "Using RandomizedSearchCV with 30 iterations for Random Forest\n",
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n",
      "\n",
      "Best parameters for Random Forest:\n",
      "Mean CV accuracy: 0.9889\n",
      "Parameters: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 137}\n",
      "Train-Test gap: 0.0111\n",
      "\n",
      "==================================================\n",
      "Comparison Results for Random Forest\n",
      "==================================================\n",
      "\n",
      "Results with product type:\n",
      "Best parameters: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 137}\n",
      "Mean CV accuracy: 0.9889\n",
      "\n",
      "Results without product type:\n",
      "Best parameters: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 137}\n",
      "Mean CV accuracy: 0.9889\n",
      "\n",
      "Performance difference (with - without): 0.0000\n",
      "\n",
      "Recommendation: Consider using the model without product type for better generalization,\n",
      "as the performance difference is minimal (<2%).\n",
      "\n",
      "######################################################################\n",
      "Running comparison for KNN\n",
      "######################################################################\n",
      "\n",
      "Tuning KNN with product_type...\n",
      "Using GridSearchCV for KNN\n",
      "Fitting 10 folds for each of 16 candidates, totalling 160 fits\n",
      "\n",
      "Best parameters for KNN:\n",
      "Mean CV accuracy: 0.9944\n",
      "Parameters: {'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "Train-Test gap: 0.0056\n",
      "\n",
      "Tuning KNN without product_type...\n",
      "Using GridSearchCV for KNN\n",
      "Fitting 10 folds for each of 16 candidates, totalling 160 fits\n",
      "\n",
      "Best parameters for KNN:\n",
      "Mean CV accuracy: 0.9889\n",
      "Parameters: {'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'uniform'}\n",
      "Train-Test gap: 0.0099\n",
      "\n",
      "==================================================\n",
      "Comparison Results for KNN\n",
      "==================================================\n",
      "\n",
      "Results with product type:\n",
      "Best parameters: {'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "Mean CV accuracy: 0.9944\n",
      "\n",
      "Results without product type:\n",
      "Best parameters: {'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'uniform'}\n",
      "Mean CV accuracy: 0.9889\n",
      "\n",
      "Performance difference (with - without): 0.0056\n",
      "\n",
      "Recommendation: Consider using the model without product type for better generalization,\n",
      "as the performance difference is minimal (<2%).\n",
      "\n",
      "######################################################################\n",
      "Running comparison for Neural Network\n",
      "######################################################################\n",
      "\n",
      "Tuning Neural Network with product_type...\n",
      "Using RandomizedSearchCV with 30 iterations for Neural Network\n",
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n",
      "\n",
      "Best parameters for Neural Network:\n",
      "Mean CV accuracy: 0.9333\n",
      "Parameters: {'activation': 'relu', 'alpha': 0.007168573438476171, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.008901755405312056, 'solver': 'adam'}\n",
      "Train-Test gap: 0.0167\n",
      "\n",
      "Tuning Neural Network without product_type...\n",
      "Using RandomizedSearchCV with 30 iterations for Neural Network\n",
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n",
      "\n",
      "Best parameters for Neural Network:\n",
      "Mean CV accuracy: 0.9556\n",
      "Parameters: {'activation': 'relu', 'alpha': 0.0005360377175443376, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.010404585843529143, 'solver': 'adam'}\n",
      "Train-Test gap: 0.0012\n",
      "\n",
      "==================================================\n",
      "Comparison Results for Neural Network\n",
      "==================================================\n",
      "\n",
      "Results with product type:\n",
      "Best parameters: {'activation': 'relu', 'alpha': 0.007168573438476171, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.008901755405312056, 'solver': 'adam'}\n",
      "Mean CV accuracy: 0.9333\n",
      "\n",
      "Results without product type:\n",
      "Best parameters: {'activation': 'relu', 'alpha': 0.0005360377175443376, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.010404585843529143, 'solver': 'adam'}\n",
      "Mean CV accuracy: 0.9556\n",
      "\n",
      "Performance difference (with - without): -0.0222\n",
      "\n",
      "Recommendation: Use the model without product type,\n",
      "as it shows better performance and provides better generalization.\n",
      "\n",
      "######################################################################\n",
      "Running comparison for Logistic Regression\n",
      "######################################################################\n",
      "\n",
      "Tuning Logistic Regression with product_type...\n",
      "Using RandomizedSearchCV with 30 iterations for Logistic Regression\n",
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n",
      "\n",
      "Best parameters for Logistic Regression:\n",
      "Mean CV accuracy: 0.9889\n",
      "Parameters: {'C': 15.699452033620265, 'multi_class': 'ovr', 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "Train-Test gap: 0.0111\n",
      "\n",
      "Tuning Logistic Regression without product_type...\n",
      "Using RandomizedSearchCV with 30 iterations for Logistic Regression\n",
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n",
      "\n",
      "Best parameters for Logistic Regression:\n",
      "Mean CV accuracy: 0.9833\n",
      "Parameters: {'C': 38.9677289689482, 'multi_class': 'multinomial', 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "Train-Test gap: 0.0167\n",
      "\n",
      "==================================================\n",
      "Comparison Results for Logistic Regression\n",
      "==================================================\n",
      "\n",
      "Results with product type:\n",
      "Best parameters: {'C': 15.699452033620265, 'multi_class': 'ovr', 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "Mean CV accuracy: 0.9889\n",
      "\n",
      "Results without product type:\n",
      "Best parameters: {'C': 38.9677289689482, 'multi_class': 'multinomial', 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "Mean CV accuracy: 0.9833\n",
      "\n",
      "Performance difference (with - without): 0.0056\n",
      "\n",
      "Recommendation: Consider using the model without product type for better generalization,\n",
      "as the performance difference is minimal (<2%).\n",
      "\n",
      "Model Performance Summary:\n",
      "================================================================================\n",
      "\n",
      "With Storage Condition:\n",
      "----------------------------------------\n",
      "\n",
      "SVM:\n",
      "Best Parameters: {'C': 7.119418600172988, 'gamma': 'auto', 'kernel': 'linear'}\n",
      "\n",
      "Random Forest:\n",
      "Best Parameters: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 137}\n",
      "\n",
      "KNN:\n",
      "Best Parameters: {'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "\n",
      "Neural Network:\n",
      "Best Parameters: {'activation': 'relu', 'alpha': 0.007168573438476171, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.008901755405312056, 'solver': 'adam'}\n",
      "\n",
      "Logistic Regression:\n",
      "Best Parameters: {'C': 15.699452033620265, 'multi_class': 'ovr', 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "\n",
      "Without Storage Condition:\n",
      "----------------------------------------\n",
      "\n",
      "SVM:\n",
      "Best Parameters: {'C': 7.119418600172988, 'gamma': 'auto', 'kernel': 'linear'}\n",
      "\n",
      "Random Forest:\n",
      "Best Parameters: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 137}\n",
      "\n",
      "KNN:\n",
      "Best Parameters: {'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "\n",
      "Neural Network:\n",
      "Best Parameters: {'activation': 'relu', 'alpha': 0.007168573438476171, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.008901755405312056, 'solver': 'adam'}\n",
      "\n",
      "Logistic Regression:\n",
      "Best Parameters: {'C': 15.699452033620265, 'multi_class': 'ovr', 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "\n",
      "Results have been saved to 'product_type_results.json'\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Product Type Classification\n",
    "print(\"\\nRunning Product Type Classification...\")\n",
    "data, X_spectral_scaled, le_product, le_storage = prepare_base_data()\n",
    "\n",
    "# Prepare datasets\n",
    "#storage_condition = data['Storage_Condition_encoded'].values.reshape(-1, 1)\n",
    "storage_condition = pd.get_dummies(data['Storage_Condition'], prefix='Storage')\n",
    "    \n",
    "X_with_storage = np.hstack([X_spectral_scaled, storage_condition.values])\n",
    "X_without_storage = X_spectral_scaled\n",
    "y_product = data['Product_Type_encoded'].values\n",
    "\n",
    "print(f\"Dataset shapes:\")\n",
    "print(f\"X without storage condition: {X_without_storage.shape}\")\n",
    "print(f\"X with storage condition: {X_with_storage.shape}\")\n",
    "print(f\"Product types: {dict(zip(le_product.classes_, le_product.transform(le_product.classes_)))}\")\n",
    "\n",
    "# Run tuning\n",
    "all_results = run_all_models_comparison(X_with_storage, X_without_storage, y_product)\n",
    "save_results(all_results, 'product_type_results.json', 'with_storage_condition', 'without_storage_condition')\n",
    "# Add this after running the analysis\n",
    "#compare_models_statistically(all_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Storage Condition Hyperparameter Tuning\n",
    " with LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Storage Condition Classification with LDA...\n",
      "Loading and preparing data...\n",
      "Dataset shapes (LDA):\n",
      "X without product type: (180, 2)\n",
      "X with product type: (180, 3)\n",
      "\n",
      "######################################################################\n",
      "Running comparison for SVM\n",
      "######################################################################\n",
      "\n",
      "Tuning SVM with product_type...\n",
      "Using RandomizedSearchCV with 30 iterations for SVM\n",
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n",
      "\n",
      "Best parameters for SVM:\n",
      "Mean CV accuracy: 1.0000\n",
      "Parameters: {'C': 1.3292918943162162, 'gamma': 0.02782799141372051, 'kernel': 'rbf'}\n",
      "Train-Test gap: 0.0000\n",
      "\n",
      "Tuning SVM without product_type...\n",
      "Using RandomizedSearchCV with 30 iterations for SVM\n",
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n",
      "\n",
      "Best parameters for SVM:\n",
      "Mean CV accuracy: 1.0000\n",
      "Parameters: {'C': 1.3292918943162162, 'gamma': 0.02782799141372051, 'kernel': 'rbf'}\n",
      "Train-Test gap: 0.0000\n",
      "\n",
      "==================================================\n",
      "Comparison Results for SVM\n",
      "==================================================\n",
      "\n",
      "Results with product type:\n",
      "Best parameters: {'C': 1.3292918943162162, 'gamma': 0.02782799141372051, 'kernel': 'rbf'}\n",
      "Mean CV accuracy: 1.0000\n",
      "\n",
      "Results without product type:\n",
      "Best parameters: {'C': 1.3292918943162162, 'gamma': 0.02782799141372051, 'kernel': 'rbf'}\n",
      "Mean CV accuracy: 1.0000\n",
      "\n",
      "Performance difference (with - without): 0.0000\n",
      "\n",
      "Recommendation: Consider using the model without product type for better generalization,\n",
      "as the performance difference is minimal (<2%).\n",
      "\n",
      "######################################################################\n",
      "Running comparison for Random Forest\n",
      "######################################################################\n",
      "\n",
      "Tuning Random Forest with product_type...\n",
      "Using RandomizedSearchCV with 30 iterations for Random Forest\n",
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n",
      "\n",
      "Best parameters for Random Forest:\n",
      "Mean CV accuracy: 1.0000\n",
      "Parameters: {'max_depth': 20, 'min_samples_leaf': 4, 'min_samples_split': 9, 'n_estimators': 238}\n",
      "Train-Test gap: 0.0000\n",
      "\n",
      "Tuning Random Forest without product_type...\n",
      "Using RandomizedSearchCV with 30 iterations for Random Forest\n",
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n",
      "\n",
      "Best parameters for Random Forest:\n",
      "Mean CV accuracy: 1.0000\n",
      "Parameters: {'max_depth': 20, 'min_samples_leaf': 4, 'min_samples_split': 9, 'n_estimators': 238}\n",
      "Train-Test gap: 0.0000\n",
      "\n",
      "==================================================\n",
      "Comparison Results for Random Forest\n",
      "==================================================\n",
      "\n",
      "Results with product type:\n",
      "Best parameters: {'max_depth': 20, 'min_samples_leaf': 4, 'min_samples_split': 9, 'n_estimators': 238}\n",
      "Mean CV accuracy: 1.0000\n",
      "\n",
      "Results without product type:\n",
      "Best parameters: {'max_depth': 20, 'min_samples_leaf': 4, 'min_samples_split': 9, 'n_estimators': 238}\n",
      "Mean CV accuracy: 1.0000\n",
      "\n",
      "Performance difference (with - without): 0.0000\n",
      "\n",
      "Recommendation: Consider using the model without product type for better generalization,\n",
      "as the performance difference is minimal (<2%).\n",
      "\n",
      "######################################################################\n",
      "Running comparison for KNN\n",
      "######################################################################\n",
      "\n",
      "Tuning KNN with product_type...\n",
      "Using GridSearchCV for KNN\n",
      "Fitting 10 folds for each of 16 candidates, totalling 160 fits\n",
      "\n",
      "Best parameters for KNN:\n",
      "Mean CV accuracy: 1.0000\n",
      "Parameters: {'metric': 'euclidean', 'n_neighbors': 3, 'weights': 'uniform'}\n",
      "Train-Test gap: 0.0000\n",
      "\n",
      "Tuning KNN without product_type...\n",
      "Using GridSearchCV for KNN\n",
      "Fitting 10 folds for each of 16 candidates, totalling 160 fits\n",
      "\n",
      "Best parameters for KNN:\n",
      "Mean CV accuracy: 1.0000\n",
      "Parameters: {'metric': 'euclidean', 'n_neighbors': 3, 'weights': 'uniform'}\n",
      "Train-Test gap: 0.0000\n",
      "\n",
      "==================================================\n",
      "Comparison Results for KNN\n",
      "==================================================\n",
      "\n",
      "Results with product type:\n",
      "Best parameters: {'metric': 'euclidean', 'n_neighbors': 3, 'weights': 'uniform'}\n",
      "Mean CV accuracy: 1.0000\n",
      "\n",
      "Results without product type:\n",
      "Best parameters: {'metric': 'euclidean', 'n_neighbors': 3, 'weights': 'uniform'}\n",
      "Mean CV accuracy: 1.0000\n",
      "\n",
      "Performance difference (with - without): 0.0000\n",
      "\n",
      "Recommendation: Consider using the model without product type for better generalization,\n",
      "as the performance difference is minimal (<2%).\n",
      "\n",
      "######################################################################\n",
      "Running comparison for Neural Network\n",
      "######################################################################\n",
      "\n",
      "Tuning Neural Network with product_type...\n",
      "Using RandomizedSearchCV with 30 iterations for Neural Network\n",
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n",
      "\n",
      "Best parameters for Neural Network:\n",
      "Mean CV accuracy: 1.0000\n",
      "Parameters: {'activation': 'tanh', 'alpha': 0.0034370861113902185, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.008080725777960455, 'solver': 'sgd'}\n",
      "Train-Test gap: 0.0000\n",
      "\n",
      "Tuning Neural Network without product_type...\n",
      "Using RandomizedSearchCV with 30 iterations for Neural Network\n",
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n",
      "\n",
      "Best parameters for Neural Network:\n",
      "Mean CV accuracy: 1.0000\n",
      "Parameters: {'activation': 'tanh', 'alpha': 0.0034370861113902185, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.008080725777960455, 'solver': 'sgd'}\n",
      "Train-Test gap: 0.0000\n",
      "\n",
      "==================================================\n",
      "Comparison Results for Neural Network\n",
      "==================================================\n",
      "\n",
      "Results with product type:\n",
      "Best parameters: {'activation': 'tanh', 'alpha': 0.0034370861113902185, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.008080725777960455, 'solver': 'sgd'}\n",
      "Mean CV accuracy: 1.0000\n",
      "\n",
      "Results without product type:\n",
      "Best parameters: {'activation': 'tanh', 'alpha': 0.0034370861113902185, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.008080725777960455, 'solver': 'sgd'}\n",
      "Mean CV accuracy: 1.0000\n",
      "\n",
      "Performance difference (with - without): 0.0000\n",
      "\n",
      "Recommendation: Consider using the model without product type for better generalization,\n",
      "as the performance difference is minimal (<2%).\n",
      "\n",
      "######################################################################\n",
      "Running comparison for Logistic Regression\n",
      "######################################################################\n",
      "\n",
      "Tuning Logistic Regression with product_type...\n",
      "Using RandomizedSearchCV with 30 iterations for Logistic Regression\n",
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n",
      "\n",
      "Best parameters for Logistic Regression:\n",
      "Mean CV accuracy: 1.0000\n",
      "Parameters: {'C': 37.55401188473625, 'multi_class': 'ovr', 'penalty': 'l2', 'solver': 'sag'}\n",
      "Train-Test gap: 0.0000\n",
      "\n",
      "Tuning Logistic Regression without product_type...\n",
      "Using RandomizedSearchCV with 30 iterations for Logistic Regression\n",
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n",
      "\n",
      "Best parameters for Logistic Regression:\n",
      "Mean CV accuracy: 1.0000\n",
      "Parameters: {'C': 37.55401188473625, 'multi_class': 'ovr', 'penalty': 'l2', 'solver': 'sag'}\n",
      "Train-Test gap: 0.0000\n",
      "\n",
      "==================================================\n",
      "Comparison Results for Logistic Regression\n",
      "==================================================\n",
      "\n",
      "Results with product type:\n",
      "Best parameters: {'C': 37.55401188473625, 'multi_class': 'ovr', 'penalty': 'l2', 'solver': 'sag'}\n",
      "Mean CV accuracy: 1.0000\n",
      "\n",
      "Results without product type:\n",
      "Best parameters: {'C': 37.55401188473625, 'multi_class': 'ovr', 'penalty': 'l2', 'solver': 'sag'}\n",
      "Mean CV accuracy: 1.0000\n",
      "\n",
      "Performance difference (with - without): 0.0000\n",
      "\n",
      "Recommendation: Consider using the model without product type for better generalization,\n",
      "as the performance difference is minimal (<2%).\n",
      "\n",
      "Model Performance Summary:\n",
      "================================================================================\n",
      "\n",
      "With Product Type:\n",
      "----------------------------------------\n",
      "\n",
      "SVM:\n",
      "Best Parameters: {'C': 1.3292918943162162, 'gamma': 0.02782799141372051, 'kernel': 'rbf'}\n",
      "\n",
      "Random Forest:\n",
      "Best Parameters: {'max_depth': 20, 'min_samples_leaf': 4, 'min_samples_split': 9, 'n_estimators': 238}\n",
      "\n",
      "KNN:\n",
      "Best Parameters: {'metric': 'euclidean', 'n_neighbors': 3, 'weights': 'uniform'}\n",
      "\n",
      "Neural Network:\n",
      "Best Parameters: {'activation': 'tanh', 'alpha': 0.0034370861113902185, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.008080725777960455, 'solver': 'sgd'}\n",
      "\n",
      "Logistic Regression:\n",
      "Best Parameters: {'C': 37.55401188473625, 'multi_class': 'ovr', 'penalty': 'l2', 'solver': 'sag'}\n",
      "\n",
      "Without Product Type:\n",
      "----------------------------------------\n",
      "\n",
      "SVM:\n",
      "Best Parameters: {'C': 1.3292918943162162, 'gamma': 0.02782799141372051, 'kernel': 'rbf'}\n",
      "\n",
      "Random Forest:\n",
      "Best Parameters: {'max_depth': 20, 'min_samples_leaf': 4, 'min_samples_split': 9, 'n_estimators': 238}\n",
      "\n",
      "KNN:\n",
      "Best Parameters: {'metric': 'euclidean', 'n_neighbors': 3, 'weights': 'uniform'}\n",
      "\n",
      "Neural Network:\n",
      "Best Parameters: {'activation': 'tanh', 'alpha': 0.0034370861113902185, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.008080725777960455, 'solver': 'sgd'}\n",
      "\n",
      "Logistic Regression:\n",
      "Best Parameters: {'C': 37.55401188473625, 'multi_class': 'ovr', 'penalty': 'l2', 'solver': 'sag'}\n",
      "\n",
      "Results have been saved to 'LDA_storage_condition_results.json'\n",
      "\n",
      "Statistical Comparison of Models:\n",
      "==================================================\n",
      "\n",
      "SVM:\n",
      "Mean with product type: 1.0000\n",
      "Mean without product type: 1.0000\n",
      "Difference: 0.0000\n",
      "p-value: nan\n",
      "Statistically significant difference: No\n",
      "\n",
      "Random Forest:\n",
      "Mean with product type: 1.0000\n",
      "Mean without product type: 1.0000\n",
      "Difference: 0.0000\n",
      "p-value: nan\n",
      "Statistically significant difference: No\n",
      "\n",
      "KNN:\n",
      "Mean with product type: 1.0000\n",
      "Mean without product type: 1.0000\n",
      "Difference: 0.0000\n",
      "p-value: nan\n",
      "Statistically significant difference: No\n",
      "\n",
      "Neural Network:\n",
      "Mean with product type: 1.0000\n",
      "Mean without product type: 1.0000\n",
      "Difference: 0.0000\n",
      "p-value: 0.0005\n",
      "Statistically significant difference: Yes\n",
      "\n",
      "Logistic Regression:\n",
      "Mean with product type: 1.0000\n",
      "Mean without product type: 1.0000\n",
      "Difference: 0.0000\n",
      "p-value: nan\n",
      "Statistically significant difference: No\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Storage Condition Classification with LDA\n",
    "print(\"\\nRunning Storage Condition Classification with LDA...\")\n",
    "data, X_spectral_scaled, le_product, le_storage = prepare_base_data()\n",
    "\n",
    "# Apply LDA\n",
    "y_storage = data['Storage_Condition_encoded'].values\n",
    "lda = LDA(n_components=min(len(np.unique(y_storage)) - 1, X_spectral_scaled.shape[1]))\n",
    "X_lda = lda.fit_transform(X_spectral_scaled, y_storage)\n",
    "\n",
    "# Prepare datasets\n",
    "product_type = data['Product_Type_encoded'].values.reshape(-1, 1)\n",
    "X_with_product = np.column_stack([X_lda, product_type])\n",
    "X_without_product = X_lda\n",
    "\n",
    "print(f\"Dataset shapes (LDA):\")\n",
    "print(f\"X without product type: {X_without_product.shape}\")\n",
    "print(f\"X with product type: {X_with_product.shape}\")\n",
    "\n",
    "# Run tuning\n",
    "all_results = run_all_models_comparison(X_with_product, X_without_product, y_storage)\n",
    "save_results(all_results, 'LDA_storage_condition_results.json', 'with_product_type', 'without_product_type')\n",
    "# Add this after running the analysis\n",
    "compare_models_statistically(all_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Product Type  Hyperparameter Tuning with LDA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Product Type Classification with LDA...\n",
      "Loading and preparing data...\n",
      "Dataset shapes (LDA):\n",
      "X without storage condition: (180, 1)\n",
      "X with storage condition: (180, 4)\n",
      "\n",
      "######################################################################\n",
      "Running comparison for SVM\n",
      "######################################################################\n",
      "\n",
      "Tuning SVM with product_type...\n",
      "Using RandomizedSearchCV with 30 iterations for SVM\n",
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n",
      "\n",
      "Best parameters for SVM:\n",
      "Mean CV accuracy: 1.0000\n",
      "Parameters: {'C': 1.3292918943162162, 'gamma': 0.0022294051208863884, 'kernel': 'rbf'}\n",
      "Train-Test gap: 0.0000\n",
      "\n",
      "Tuning SVM without product_type...\n",
      "Using RandomizedSearchCV with 30 iterations for SVM\n",
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n",
      "\n",
      "Best parameters for SVM:\n",
      "Mean CV accuracy: 1.0000\n",
      "Parameters: {'C': 1.3292918943162162, 'gamma': 0.0022294051208863884, 'kernel': 'rbf'}\n",
      "Train-Test gap: 0.0000\n",
      "\n",
      "==================================================\n",
      "Comparison Results for SVM\n",
      "==================================================\n",
      "\n",
      "Results with product type:\n",
      "Best parameters: {'C': 1.3292918943162162, 'gamma': 0.0022294051208863884, 'kernel': 'rbf'}\n",
      "Mean CV accuracy: 1.0000\n",
      "\n",
      "Results without product type:\n",
      "Best parameters: {'C': 1.3292918943162162, 'gamma': 0.0022294051208863884, 'kernel': 'rbf'}\n",
      "Mean CV accuracy: 1.0000\n",
      "\n",
      "Performance difference (with - without): 0.0000\n",
      "\n",
      "Recommendation: Consider using the model without product type for better generalization,\n",
      "as the performance difference is minimal (<2%).\n",
      "\n",
      "######################################################################\n",
      "Running comparison for Random Forest\n",
      "######################################################################\n",
      "\n",
      "Tuning Random Forest with product_type...\n",
      "Using RandomizedSearchCV with 30 iterations for Random Forest\n",
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n",
      "\n",
      "Best parameters for Random Forest:\n",
      "Mean CV accuracy: 1.0000\n",
      "Parameters: {'max_depth': 20, 'min_samples_leaf': 4, 'min_samples_split': 9, 'n_estimators': 238}\n",
      "Train-Test gap: 0.0000\n",
      "\n",
      "Tuning Random Forest without product_type...\n",
      "Using RandomizedSearchCV with 30 iterations for Random Forest\n",
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n",
      "\n",
      "Best parameters for Random Forest:\n",
      "Mean CV accuracy: 1.0000\n",
      "Parameters: {'max_depth': 20, 'min_samples_leaf': 4, 'min_samples_split': 9, 'n_estimators': 238}\n",
      "Train-Test gap: 0.0000\n",
      "\n",
      "==================================================\n",
      "Comparison Results for Random Forest\n",
      "==================================================\n",
      "\n",
      "Results with product type:\n",
      "Best parameters: {'max_depth': 20, 'min_samples_leaf': 4, 'min_samples_split': 9, 'n_estimators': 238}\n",
      "Mean CV accuracy: 1.0000\n",
      "\n",
      "Results without product type:\n",
      "Best parameters: {'max_depth': 20, 'min_samples_leaf': 4, 'min_samples_split': 9, 'n_estimators': 238}\n",
      "Mean CV accuracy: 1.0000\n",
      "\n",
      "Performance difference (with - without): 0.0000\n",
      "\n",
      "Recommendation: Consider using the model without product type for better generalization,\n",
      "as the performance difference is minimal (<2%).\n",
      "\n",
      "######################################################################\n",
      "Running comparison for KNN\n",
      "######################################################################\n",
      "\n",
      "Tuning KNN with product_type...\n",
      "Using GridSearchCV for KNN\n",
      "Fitting 10 folds for each of 16 candidates, totalling 160 fits\n",
      "\n",
      "Best parameters for KNN:\n",
      "Mean CV accuracy: 1.0000\n",
      "Parameters: {'metric': 'euclidean', 'n_neighbors': 3, 'weights': 'uniform'}\n",
      "Train-Test gap: 0.0000\n",
      "\n",
      "Tuning KNN without product_type...\n",
      "Using GridSearchCV for KNN\n",
      "Fitting 10 folds for each of 16 candidates, totalling 160 fits\n",
      "\n",
      "Best parameters for KNN:\n",
      "Mean CV accuracy: 1.0000\n",
      "Parameters: {'metric': 'euclidean', 'n_neighbors': 3, 'weights': 'uniform'}\n",
      "Train-Test gap: 0.0000\n",
      "\n",
      "==================================================\n",
      "Comparison Results for KNN\n",
      "==================================================\n",
      "\n",
      "Results with product type:\n",
      "Best parameters: {'metric': 'euclidean', 'n_neighbors': 3, 'weights': 'uniform'}\n",
      "Mean CV accuracy: 1.0000\n",
      "\n",
      "Results without product type:\n",
      "Best parameters: {'metric': 'euclidean', 'n_neighbors': 3, 'weights': 'uniform'}\n",
      "Mean CV accuracy: 1.0000\n",
      "\n",
      "Performance difference (with - without): 0.0000\n",
      "\n",
      "Recommendation: Consider using the model without product type for better generalization,\n",
      "as the performance difference is minimal (<2%).\n",
      "\n",
      "######################################################################\n",
      "Running comparison for Neural Network\n",
      "######################################################################\n",
      "\n",
      "Tuning Neural Network with product_type...\n",
      "Using RandomizedSearchCV with 30 iterations for Neural Network\n",
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n",
      "\n",
      "Best parameters for Neural Network:\n",
      "Mean CV accuracy: 1.0000\n",
      "Parameters: {'activation': 'relu', 'alpha': 0.008065429868602328, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.008319939418114052, 'solver': 'adam'}\n",
      "Train-Test gap: 0.0000\n",
      "\n",
      "Tuning Neural Network without product_type...\n",
      "Using RandomizedSearchCV with 30 iterations for Neural Network\n",
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n",
      "\n",
      "Best parameters for Neural Network:\n",
      "Mean CV accuracy: 1.0000\n",
      "Parameters: {'activation': 'relu', 'alpha': 0.008065429868602328, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.008319939418114052, 'solver': 'adam'}\n",
      "Train-Test gap: 0.0000\n",
      "\n",
      "==================================================\n",
      "Comparison Results for Neural Network\n",
      "==================================================\n",
      "\n",
      "Results with product type:\n",
      "Best parameters: {'activation': 'relu', 'alpha': 0.008065429868602328, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.008319939418114052, 'solver': 'adam'}\n",
      "Mean CV accuracy: 1.0000\n",
      "\n",
      "Results without product type:\n",
      "Best parameters: {'activation': 'relu', 'alpha': 0.008065429868602328, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.008319939418114052, 'solver': 'adam'}\n",
      "Mean CV accuracy: 1.0000\n",
      "\n",
      "Performance difference (with - without): 0.0000\n",
      "\n",
      "Recommendation: Consider using the model without product type for better generalization,\n",
      "as the performance difference is minimal (<2%).\n",
      "\n",
      "######################################################################\n",
      "Running comparison for Logistic Regression\n",
      "######################################################################\n",
      "\n",
      "Tuning Logistic Regression with product_type...\n",
      "Using RandomizedSearchCV with 30 iterations for Logistic Regression\n",
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n",
      "\n",
      "Best parameters for Logistic Regression:\n",
      "Mean CV accuracy: 1.0000\n",
      "Parameters: {'C': 37.55401188473625, 'multi_class': 'ovr', 'penalty': 'l2', 'solver': 'sag'}\n",
      "Train-Test gap: 0.0000\n",
      "\n",
      "Tuning Logistic Regression without product_type...\n",
      "Using RandomizedSearchCV with 30 iterations for Logistic Regression\n",
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n",
      "\n",
      "Best parameters for Logistic Regression:\n",
      "Mean CV accuracy: 1.0000\n",
      "Parameters: {'C': 37.55401188473625, 'multi_class': 'ovr', 'penalty': 'l2', 'solver': 'sag'}\n",
      "Train-Test gap: 0.0000\n",
      "\n",
      "==================================================\n",
      "Comparison Results for Logistic Regression\n",
      "==================================================\n",
      "\n",
      "Results with product type:\n",
      "Best parameters: {'C': 37.55401188473625, 'multi_class': 'ovr', 'penalty': 'l2', 'solver': 'sag'}\n",
      "Mean CV accuracy: 1.0000\n",
      "\n",
      "Results without product type:\n",
      "Best parameters: {'C': 37.55401188473625, 'multi_class': 'ovr', 'penalty': 'l2', 'solver': 'sag'}\n",
      "Mean CV accuracy: 1.0000\n",
      "\n",
      "Performance difference (with - without): 0.0000\n",
      "\n",
      "Recommendation: Consider using the model without product type for better generalization,\n",
      "as the performance difference is minimal (<2%).\n",
      "\n",
      "Model Performance Summary:\n",
      "================================================================================\n",
      "\n",
      "With Storage Condition:\n",
      "----------------------------------------\n",
      "\n",
      "SVM:\n",
      "Best Parameters: {'C': 1.3292918943162162, 'gamma': 0.0022294051208863884, 'kernel': 'rbf'}\n",
      "\n",
      "Random Forest:\n",
      "Best Parameters: {'max_depth': 20, 'min_samples_leaf': 4, 'min_samples_split': 9, 'n_estimators': 238}\n",
      "\n",
      "KNN:\n",
      "Best Parameters: {'metric': 'euclidean', 'n_neighbors': 3, 'weights': 'uniform'}\n",
      "\n",
      "Neural Network:\n",
      "Best Parameters: {'activation': 'relu', 'alpha': 0.008065429868602328, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.008319939418114052, 'solver': 'adam'}\n",
      "\n",
      "Logistic Regression:\n",
      "Best Parameters: {'C': 37.55401188473625, 'multi_class': 'ovr', 'penalty': 'l2', 'solver': 'sag'}\n",
      "\n",
      "Without Storage Condition:\n",
      "----------------------------------------\n",
      "\n",
      "SVM:\n",
      "Best Parameters: {'C': 1.3292918943162162, 'gamma': 0.0022294051208863884, 'kernel': 'rbf'}\n",
      "\n",
      "Random Forest:\n",
      "Best Parameters: {'max_depth': 20, 'min_samples_leaf': 4, 'min_samples_split': 9, 'n_estimators': 238}\n",
      "\n",
      "KNN:\n",
      "Best Parameters: {'metric': 'euclidean', 'n_neighbors': 3, 'weights': 'uniform'}\n",
      "\n",
      "Neural Network:\n",
      "Best Parameters: {'activation': 'relu', 'alpha': 0.008065429868602328, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.008319939418114052, 'solver': 'adam'}\n",
      "\n",
      "Logistic Regression:\n",
      "Best Parameters: {'C': 37.55401188473625, 'multi_class': 'ovr', 'penalty': 'l2', 'solver': 'sag'}\n",
      "\n",
      "Results have been saved to 'LDA_product_type_results.json'\n",
      "\n",
      "Statistical Comparison of Models:\n",
      "==================================================\n",
      "\n",
      "SVM:\n",
      "Mean with product type: 1.0000\n",
      "Mean without product type: 1.0000\n",
      "Difference: 0.0000\n",
      "p-value: nan\n",
      "Statistically significant difference: No\n",
      "\n",
      "Random Forest:\n",
      "Mean with product type: 1.0000\n",
      "Mean without product type: 1.0000\n",
      "Difference: 0.0000\n",
      "p-value: nan\n",
      "Statistically significant difference: No\n",
      "\n",
      "KNN:\n",
      "Mean with product type: 1.0000\n",
      "Mean without product type: 1.0000\n",
      "Difference: 0.0000\n",
      "p-value: nan\n",
      "Statistically significant difference: No\n",
      "\n",
      "Neural Network:\n",
      "Mean with product type: 1.0000\n",
      "Mean without product type: 1.0000\n",
      "Difference: 0.0000\n",
      "p-value: 0.1246\n",
      "Statistically significant difference: No\n",
      "\n",
      "Logistic Regression:\n",
      "Mean with product type: 1.0000\n",
      "Mean without product type: 1.0000\n",
      "Difference: 0.0000\n",
      "p-value: nan\n",
      "Statistically significant difference: No\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Product Type Classification with LDA\n",
    "print(\"\\nRunning Product Type Classification with LDA...\")\n",
    "data, X_spectral_scaled, le_product, le_storage = prepare_base_data()\n",
    "\n",
    "# Apply LDA\n",
    "y_product = data['Product_Type_encoded'].values\n",
    "lda = LDA(n_components=min(len(np.unique(y_product)) - 1, X_spectral_scaled.shape[1]))\n",
    "X_lda = lda.fit_transform(X_spectral_scaled, y_product)\n",
    "\n",
    "# Prepare datasets\n",
    "#storage_condition = data['Storage_Condition_encoded'].values.reshape(-1, 1)\n",
    " # One-hot encode Storage_Condition\n",
    "storage_condition = pd.get_dummies(data['Storage_Condition'], prefix='Storage')\n",
    "#X_with_storage = np.column_stack([X_lda, storage_condition])\n",
    "X_with_storage = np.hstack([X_lda, storage_condition.values])\n",
    "X_without_storage = X_lda\n",
    "\n",
    "print(f\"Dataset shapes (LDA):\")\n",
    "print(f\"X without storage condition: {X_without_storage.shape}\")\n",
    "print(f\"X with storage condition: {X_with_storage.shape}\")\n",
    "\n",
    "# Run tuning\n",
    "all_results = run_all_models_comparison(X_with_storage, X_without_storage, y_product)\n",
    "save_results(all_results, 'LDA_product_type_results.json', 'with_storage_condition', 'without_storage_condition')\n",
    "# Add this after running the analysis\n",
    "compare_models_statistically(all_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "def compare_models_statistically(all_results):\n",
    "    \"\"\"Perform statistical comparison between models with and without additional features\"\"\"\n",
    "    print(\"\\nStatistical Comparison of Models:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    for model_name, results in all_results.items():\n",
    "        # Get CV results\n",
    "        with_scores = results['with_product_type']['cv_results']['mean_test_score']\n",
    "        without_scores = results['without_product_type']['cv_results']['mean_test_score']\n",
    "        \n",
    "        # Perform paired t-test\n",
    "        t_stat, p_value = stats.ttest_rel(with_scores, without_scores)\n",
    "        \n",
    "        print(f\"\\n{model_name}:\")\n",
    "        print(f\"Mean with product type: {results['with_product_type']['best_score']:.4f}\")\n",
    "        print(f\"Mean without product type: {results['without_product_type']['best_score']:.4f}\")\n",
    "        print(f\"Difference: {results['with_product_type']['best_score'] - results['without_product_type']['best_score']:.4f}\")\n",
    "        print(f\"p-value: {p_value:.4f}\")\n",
    "        print(f\"Statistically significant difference: {'Yes' if p_value < 0.05 else 'No'}\")\n",
    "\n",
    "# Add this after running the analysis\n",
    "compare_models_statistically(all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importance(model, feature_names, top_n=20):\n",
    "    \"\"\"Plot feature importance for Random Forest model\"\"\"\n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        # Get feature importances\n",
    "        importances = model.feature_importances_\n",
    "        \n",
    "        # Create DataFrame\n",
    "        feature_importance = pd.DataFrame({\n",
    "            'Feature': feature_names,\n",
    "            'Importance': importances\n",
    "        })\n",
    "        \n",
    "        # Sort by importance\n",
    "        feature_importance = feature_importance.sort_values('Importance', ascending=False)\n",
    "        \n",
    "        # Plot top N features\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        sns.barplot(x='Importance', y='Feature', data=feature_importance.head(top_n))\n",
    "        plt.title('Top Feature Importances')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('feature_importance.png')\n",
    "        plt.show()\n",
    "        \n",
    "        return feature_importance\n",
    "    else:\n",
    "        print(\"Model doesn't have feature_importances_ attribute\")\n",
    "        return None\n",
    "\n",
    "# Add this after running Random Forest\n",
    "spectral_cols = [col for col in data.columns if col.startswith(('gain_', 'phase_'))]\n",
    "rf_model = all_results['Random Forest']['with_product_type']['best_model']\n",
    "feature_names = spectral_cols + ['Product_Type']\n",
    "plot_feature_importance(rf_model, feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell: Model Performance Analysis\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def analyze_model_performance(all_results):\n",
    "    \"\"\"Analyze and visualize model performance including overfitting detection\"\"\"\n",
    "    \n",
    "    # Prepare data for plotting\n",
    "    models = []\n",
    "    train_scores = []\n",
    "    val_scores = []\n",
    "    cv_scores = []\n",
    "    variants = []\n",
    "    \n",
    "    for model_name, results in all_results.items():\n",
    "        for variant in ['with_product_type', 'without_product_type']:\n",
    "            models.append(model_name)\n",
    "            variants.append(variant)\n",
    "            res = results[variant]\n",
    "            train_scores.append(res['train_score'])\n",
    "            val_scores.append(res['validation_score'])\n",
    "            cv_scores.append(res['best_score'])\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'Model': models,\n",
    "        'Variant': variants,\n",
    "        'Training Score': train_scores,\n",
    "        'Validation Score': val_scores,\n",
    "        'CV Score': cv_scores\n",
    "    })\n",
    "    \n",
    "    # Plot performance comparison\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    \n",
    "    x = np.arange(len(df['Model'].unique()))\n",
    "    width = 0.15\n",
    "    \n",
    "    plt.bar(x - width, df[df['Variant'] == 'with_product_type']['Training Score'], \n",
    "            width, label='With Features (Train)', alpha=0.7)\n",
    "    plt.bar(x, df[df['Variant'] == 'with_product_type']['Validation Score'], \n",
    "            width, label='With Features (Val)', alpha=0.7)\n",
    "    plt.bar(x + width, df[df['Variant'] == 'without_product_type']['Training Score'], \n",
    "            width, label='Without Features (Train)', alpha=0.7)\n",
    "    plt.bar(x + 2*width, df[df['Variant'] == 'without_product_type']['Validation Score'], \n",
    "            width, label='Without Features (Val)', alpha=0.7)\n",
    "    \n",
    "    plt.xlabel('Models')\n",
    "    plt.ylabel('Score')\n",
    "    plt.title('Model Performance Comparison')\n",
    "    plt.xticks(x, df['Model'].unique(), rotation=45)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print overfitting analysis\n",
    "    print(\"\\nOverfitting Analysis:\")\n",
    "    print(\"=\" * 50)\n",
    "    for model_name, results in all_results.items():\n",
    "        print(f\"\\n{model_name}:\")\n",
    "        for variant in ['with_product_type', 'without_product_type']:\n",
    "            res = results[variant]\n",
    "            print(f\"\\n{variant}:\")\n",
    "            print(f\"Train-Val difference: {res['overfitting_score']:.4f}\")\n",
    "            if res['overfitting_score'] > 0.05:\n",
    "                print(\"WARNING: Potential overfitting detected!\")\n",
    "            elif res['overfitting_score'] < -0.05:\n",
    "                print(\"WARNING: Potential underfitting detected!\")\n",
    "            else:\n",
    "                print(\"Good fit!\")\n",
    "\n",
    "# Run the analysis\n",
    "analyze_model_performance(all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Storage Condition Classification with GridSearch\n",
    "import grid_search as gst\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load data\n",
    "data = pd.read_csv('../augmented_bakery_data.csv')\n",
    "\n",
    "# Prepare features\n",
    "feature_cols = [col for col in data.columns if col.startswith(('gain_', 'phase_'))]\n",
    "X_base = data[feature_cols]\n",
    "\n",
    "# Encode target\n",
    "le_storage = LabelEncoder()\n",
    "y_storage = le_storage.fit_transform(data['Storage_Condition'])\n",
    "\n",
    "# Encode extra feature (Product_Type)\n",
    "le_product = LabelEncoder()\n",
    "product_encoded = le_product.fit_transform(data['Product_Type'])\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_base)\n",
    "\n",
    "# Create datasets with and without product type\n",
    "X_without_product = X_scaled\n",
    "X_with_product = np.column_stack([X_scaled, product_encoded.reshape(-1, 1)])\n",
    "\n",
    "# Run hyperparameter tuning with grid search for all models\n",
    "results = gst.run_all_models_comparison(\n",
    "    X_with_product,\n",
    "    X_without_product,\n",
    "    y_storage,\n",
    "    with_label='with_product_type',\n",
    "    without_label='without_product_type'\n",
    ")\n",
    "\n",
    "# Save the results\n",
    "gst.save_results(\n",
    "    results,\n",
    "    'hyperparameter_tuning/grid_search_storage_condition_results.json',\n",
    "    with_label='with_product_type',\n",
    "    without_label='without_product_type'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "######################################################################\n",
      "Running comparison for SVM\n",
      "######################################################################\n",
      "\n",
      "Tuning SVM with_storage_condition...\n",
      "Using GridSearchCV for SVM\n",
      "Fitting 10 folds for each of 50 candidates, totalling 500 fits\n",
      "\n",
      "Best parameters for SVM:\n",
      "Mean CV accuracy: 0.9889\n",
      "Parameters: {'C': 10, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "Train-Test gap: 0.0111\n",
      "\n",
      "Tuning SVM without_storage_condition...\n",
      "Using GridSearchCV for SVM\n",
      "Fitting 10 folds for each of 50 candidates, totalling 500 fits\n",
      "\n",
      "Best parameters for SVM:\n",
      "Mean CV accuracy: 0.9833\n",
      "Parameters: {'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "Train-Test gap: 0.0056\n",
      "\n",
      "==================================================\n",
      "Comparison Results for SVM\n",
      "==================================================\n",
      "\n",
      "Results with_storage_condition:\n",
      "Best parameters: {'C': 10, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "Mean CV accuracy: 0.9889\n",
      "\n",
      "Results without_storage_condition:\n",
      "Best parameters: {'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "Mean CV accuracy: 0.9833\n",
      "\n",
      "Performance difference (with_storage_condition - without_storage_condition): 0.0056\n",
      "\n",
      "Recommendation: Consider using the model without_storage_condition for better generalization,\n",
      "as the performance difference is minimal (<2%).\n",
      "\n",
      "######################################################################\n",
      "Running comparison for Random Forest\n",
      "######################################################################\n",
      "\n",
      "Tuning Random Forest with_storage_condition...\n",
      "Using GridSearchCV for Random Forest\n",
      "Fitting 10 folds for each of 240 candidates, totalling 2400 fits\n",
      "\n",
      "Best parameters for Random Forest:\n",
      "Mean CV accuracy: 0.9889\n",
      "Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "Train-Test gap: 0.0111\n",
      "\n",
      "Tuning Random Forest without_storage_condition...\n",
      "Using GridSearchCV for Random Forest\n",
      "Fitting 10 folds for each of 240 candidates, totalling 2400 fits\n",
      "\n",
      "Best parameters for Random Forest:\n",
      "Mean CV accuracy: 0.9889\n",
      "Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "Train-Test gap: 0.0111\n",
      "\n",
      "==================================================\n",
      "Comparison Results for Random Forest\n",
      "==================================================\n",
      "\n",
      "Results with_storage_condition:\n",
      "Best parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "Mean CV accuracy: 0.9889\n",
      "\n",
      "Results without_storage_condition:\n",
      "Best parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "Mean CV accuracy: 0.9889\n",
      "\n",
      "Performance difference (with_storage_condition - without_storage_condition): 0.0000\n",
      "\n",
      "Recommendation: Consider using the model without_storage_condition for better generalization,\n",
      "as the performance difference is minimal (<2%).\n",
      "\n",
      "######################################################################\n",
      "Running comparison for KNN\n",
      "######################################################################\n",
      "\n",
      "Tuning KNN with_storage_condition...\n",
      "Using GridSearchCV for KNN\n",
      "Fitting 10 folds for each of 16 candidates, totalling 160 fits\n",
      "\n",
      "Best parameters for KNN:\n",
      "Mean CV accuracy: 0.9944\n",
      "Parameters: {'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "Train-Test gap: 0.0056\n",
      "\n",
      "Tuning KNN without_storage_condition...\n",
      "Using GridSearchCV for KNN\n",
      "Fitting 10 folds for each of 16 candidates, totalling 160 fits\n",
      "\n",
      "Best parameters for KNN:\n",
      "Mean CV accuracy: 0.9889\n",
      "Parameters: {'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'uniform'}\n",
      "Train-Test gap: 0.0099\n",
      "\n",
      "==================================================\n",
      "Comparison Results for KNN\n",
      "==================================================\n",
      "\n",
      "Results with_storage_condition:\n",
      "Best parameters: {'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "Mean CV accuracy: 0.9944\n",
      "\n",
      "Results without_storage_condition:\n",
      "Best parameters: {'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'uniform'}\n",
      "Mean CV accuracy: 0.9889\n",
      "\n",
      "Performance difference (with_storage_condition - without_storage_condition): 0.0056\n",
      "\n",
      "Recommendation: Consider using the model without_storage_condition for better generalization,\n",
      "as the performance difference is minimal (<2%).\n",
      "\n",
      "######################################################################\n",
      "Running comparison for Neural Network\n",
      "######################################################################\n",
      "\n",
      "Tuning Neural Network with_storage_condition...\n",
      "Using GridSearchCV for Neural Network\n",
      "Fitting 10 folds for each of 72 candidates, totalling 720 fits\n",
      "\n",
      "Best parameters for Neural Network:\n",
      "Mean CV accuracy: 0.9333\n",
      "Parameters: {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.01, 'solver': 'adam'}\n",
      "Train-Test gap: 0.0136\n",
      "\n",
      "Tuning Neural Network without_storage_condition...\n",
      "Using GridSearchCV for Neural Network\n",
      "Fitting 10 folds for each of 72 candidates, totalling 720 fits\n",
      "\n",
      "Best parameters for Neural Network:\n",
      "Mean CV accuracy: 0.9500\n",
      "Parameters: {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.01, 'solver': 'adam'}\n",
      "Train-Test gap: 0.0056\n",
      "\n",
      "==================================================\n",
      "Comparison Results for Neural Network\n",
      "==================================================\n",
      "\n",
      "Results with_storage_condition:\n",
      "Best parameters: {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.01, 'solver': 'adam'}\n",
      "Mean CV accuracy: 0.9333\n",
      "\n",
      "Results without_storage_condition:\n",
      "Best parameters: {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.01, 'solver': 'adam'}\n",
      "Mean CV accuracy: 0.9500\n",
      "\n",
      "Performance difference (with_storage_condition - without_storage_condition): -0.0167\n",
      "\n",
      "Recommendation: Consider using the model without_storage_condition for better generalization,\n",
      "as the performance difference is minimal (<2%).\n",
      "\n",
      "######################################################################\n",
      "Running comparison for Logistic Regression\n",
      "######################################################################\n",
      "\n",
      "Tuning Logistic Regression with_storage_condition...\n",
      "Using GridSearchCV for Logistic Regression\n",
      "Fitting 10 folds for each of 48 candidates, totalling 480 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yohan\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters for Logistic Regression:\n",
      "Mean CV accuracy: 0.9889\n",
      "Parameters: {'C': 0.1, 'multi_class': 'ovr', 'penalty': None, 'solver': 'newton-cg'}\n",
      "Train-Test gap: 0.0111\n",
      "\n",
      "Tuning Logistic Regression without_storage_condition...\n",
      "Using GridSearchCV for Logistic Regression\n",
      "Fitting 10 folds for each of 48 candidates, totalling 480 fits\n",
      "\n",
      "Best parameters for Logistic Regression:\n",
      "Mean CV accuracy: 0.9833\n",
      "Parameters: {'C': 0.1, 'multi_class': 'ovr', 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "Train-Test gap: -0.0000\n",
      "\n",
      "==================================================\n",
      "Comparison Results for Logistic Regression\n",
      "==================================================\n",
      "\n",
      "Results with_storage_condition:\n",
      "Best parameters: {'C': 0.1, 'multi_class': 'ovr', 'penalty': None, 'solver': 'newton-cg'}\n",
      "Mean CV accuracy: 0.9889\n",
      "\n",
      "Results without_storage_condition:\n",
      "Best parameters: {'C': 0.1, 'multi_class': 'ovr', 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "Mean CV accuracy: 0.9833\n",
      "\n",
      "Performance difference (with_storage_condition - without_storage_condition): 0.0056\n",
      "\n",
      "Recommendation: Consider using the model without_storage_condition for better generalization,\n",
      "as the performance difference is minimal (<2%).\n",
      "\n",
      "Model Performance Summary:\n",
      "================================================================================\n",
      "\n",
      "With Storage Condition:\n",
      "----------------------------------------\n",
      "\n",
      "SVM:\n",
      "Best Parameters: {'C': 10, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "\n",
      "Random Forest:\n",
      "Best Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "\n",
      "KNN:\n",
      "Best Parameters: {'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "\n",
      "Neural Network:\n",
      "Best Parameters: {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.01, 'solver': 'adam'}\n",
      "\n",
      "Logistic Regression:\n",
      "Best Parameters: {'C': 0.1, 'multi_class': 'ovr', 'penalty': None, 'solver': 'newton-cg'}\n",
      "\n",
      "Without Storage Condition:\n",
      "----------------------------------------\n",
      "\n",
      "SVM:\n",
      "Best Parameters: {'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "\n",
      "Random Forest:\n",
      "Best Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "\n",
      "KNN:\n",
      "Best Parameters: {'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'uniform'}\n",
      "\n",
      "Neural Network:\n",
      "Best Parameters: {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.01, 'solver': 'adam'}\n",
      "\n",
      "Logistic Regression:\n",
      "Best Parameters: {'C': 0.1, 'multi_class': 'ovr', 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "\n",
      "Results have been saved to 'hyperparameter_tuning/grid_search_product_type_results.json'\n"
     ]
    }
   ],
   "source": [
    "# Product Type Classification with Grid Search\n",
    "import grid_search as gst\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv('../augmented_bakery_data.csv')\n",
    "\n",
    "# Prepare features\n",
    "feature_cols = [col for col in data.columns if col.startswith(('gain_', 'phase_'))]\n",
    "X_base = data[feature_cols]\n",
    "\n",
    "# Encode target\n",
    "le_product = LabelEncoder()\n",
    "y_product = le_product.fit_transform(data['Product_Type'])\n",
    "\n",
    "# Encode extra feature (Storage_Condition)\n",
    "le_storage = LabelEncoder()\n",
    "#storage_encoded = le_storage.fit_transform(data['Storage_Condition'])\n",
    "storage_encoded = pd.get_dummies(data['Storage_Condition'], prefix='Storage')\n",
    "    \n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_base)\n",
    "\n",
    "# Create datasets with and without storage condition\n",
    "X_without_storage = X_scaled\n",
    "X_with_storage = np.hstack([X_spectral_scaled, storage_condition.values])\n",
    "\n",
    "# Run hyperparameter tuning with grid search for all models\n",
    "results = gst.run_all_models_comparison(\n",
    "    X_with_storage,\n",
    "    X_without_storage,\n",
    "    y_product,\n",
    "    with_label='with_storage_condition',\n",
    "    without_label='without_storage_condition'\n",
    ")\n",
    "\n",
    "# Save the results\n",
    "gst.save_results(\n",
    "    results,\n",
    "    'hyperparameter_tuning/grid_search_product_type_results.json',\n",
    "    with_label='with_storage_condition',\n",
    "    without_label='without_storage_condition'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "######################################################################\n",
      "Running comparison for SVM\n",
      "######################################################################\n",
      "\n",
      "Tuning SVM with_product_type...\n",
      "Using GridSearchCV for SVM\n",
      "Fitting 10 folds for each of 50 candidates, totalling 500 fits\n",
      "\n",
      "Best parameters for SVM:\n",
      "Mean CV accuracy: 0.9389\n",
      "Parameters: {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Train-Test gap: 0.0562\n",
      "\n",
      "Tuning SVM without_product_type...\n",
      "Using GridSearchCV for SVM\n",
      "Fitting 10 folds for each of 50 candidates, totalling 500 fits\n",
      "\n",
      "Best parameters for SVM:\n",
      "Mean CV accuracy: 0.9278\n",
      "Parameters: {'C': 50, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "Train-Test gap: 0.0679\n",
      "\n",
      "==================================================\n",
      "Comparison Results for SVM\n",
      "==================================================\n",
      "\n",
      "Results with_product_type:\n",
      "Best parameters: {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Mean CV accuracy: 0.9389\n",
      "\n",
      "Results without_product_type:\n",
      "Best parameters: {'C': 50, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "Mean CV accuracy: 0.9278\n",
      "\n",
      "Performance difference (with_product_type - without_product_type): 0.0111\n",
      "\n",
      "Recommendation: Consider using the model without_product_type for better generalization,\n",
      "as the performance difference is minimal (<2%).\n",
      "\n",
      "######################################################################\n",
      "Running comparison for Random Forest\n",
      "######################################################################\n",
      "\n",
      "Tuning Random Forest with_product_type...\n",
      "Using GridSearchCV for Random Forest\n",
      "Fitting 10 folds for each of 240 candidates, totalling 2400 fits\n",
      "\n",
      "Best parameters for Random Forest:\n",
      "Mean CV accuracy: 0.9667\n",
      "Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "Train-Test gap: 0.0333\n",
      "\n",
      "Tuning Random Forest without_product_type...\n",
      "Using GridSearchCV for Random Forest\n",
      "Fitting 10 folds for each of 240 candidates, totalling 2400 fits\n",
      "\n",
      "Best parameters for Random Forest:\n",
      "Mean CV accuracy: 0.9611\n",
      "Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Train-Test gap: 0.0389\n",
      "\n",
      "==================================================\n",
      "Comparison Results for Random Forest\n",
      "==================================================\n",
      "\n",
      "Results with_product_type:\n",
      "Best parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "Mean CV accuracy: 0.9667\n",
      "\n",
      "Results without_product_type:\n",
      "Best parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Mean CV accuracy: 0.9611\n",
      "\n",
      "Performance difference (with_product_type - without_product_type): 0.0056\n",
      "\n",
      "Recommendation: Consider using the model without_product_type for better generalization,\n",
      "as the performance difference is minimal (<2%).\n",
      "\n",
      "######################################################################\n",
      "Running comparison for KNN\n",
      "######################################################################\n",
      "\n",
      "Tuning KNN with_product_type...\n",
      "Using GridSearchCV for KNN\n",
      "Fitting 10 folds for each of 16 candidates, totalling 160 fits\n",
      "\n",
      "Best parameters for KNN:\n",
      "Mean CV accuracy: 0.9167\n",
      "Parameters: {'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "Train-Test gap: 0.0833\n",
      "\n",
      "Tuning KNN without_product_type...\n",
      "Using GridSearchCV for KNN\n",
      "Fitting 10 folds for each of 16 candidates, totalling 160 fits\n",
      "\n",
      "Best parameters for KNN:\n",
      "Mean CV accuracy: 0.9167\n",
      "Parameters: {'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "Train-Test gap: 0.0833\n",
      "\n",
      "==================================================\n",
      "Comparison Results for KNN\n",
      "==================================================\n",
      "\n",
      "Results with_product_type:\n",
      "Best parameters: {'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "Mean CV accuracy: 0.9167\n",
      "\n",
      "Results without_product_type:\n",
      "Best parameters: {'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "Mean CV accuracy: 0.9167\n",
      "\n",
      "Performance difference (with_product_type - without_product_type): 0.0000\n",
      "\n",
      "Recommendation: Consider using the model without_product_type for better generalization,\n",
      "as the performance difference is minimal (<2%).\n",
      "\n",
      "######################################################################\n",
      "Running comparison for Neural Network\n",
      "######################################################################\n",
      "\n",
      "Tuning Neural Network with_product_type...\n",
      "Using GridSearchCV for Neural Network\n",
      "Fitting 10 folds for each of 72 candidates, totalling 720 fits\n",
      "\n",
      "Best parameters for Neural Network:\n",
      "Mean CV accuracy: 0.6444\n",
      "Parameters: {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.005, 'solver': 'adam'}\n",
      "Train-Test gap: 0.0247\n",
      "\n",
      "Tuning Neural Network without_product_type...\n",
      "Using GridSearchCV for Neural Network\n",
      "Fitting 10 folds for each of 72 candidates, totalling 720 fits\n",
      "\n",
      "Best parameters for Neural Network:\n",
      "Mean CV accuracy: 0.6444\n",
      "Parameters: {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.005, 'solver': 'adam'}\n",
      "Train-Test gap: 0.0735\n",
      "\n",
      "==================================================\n",
      "Comparison Results for Neural Network\n",
      "==================================================\n",
      "\n",
      "Results with_product_type:\n",
      "Best parameters: {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.005, 'solver': 'adam'}\n",
      "Mean CV accuracy: 0.6444\n",
      "\n",
      "Results without_product_type:\n",
      "Best parameters: {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.005, 'solver': 'adam'}\n",
      "Mean CV accuracy: 0.6444\n",
      "\n",
      "Performance difference (with_product_type - without_product_type): -0.0000\n",
      "\n",
      "Recommendation: Consider using the model without_product_type for better generalization,\n",
      "as the performance difference is minimal (<2%).\n",
      "\n",
      "######################################################################\n",
      "Running comparison for Logistic Regression\n",
      "######################################################################\n",
      "\n",
      "Tuning Logistic Regression with_product_type...\n",
      "Using GridSearchCV for Logistic Regression\n",
      "Fitting 10 folds for each of 48 candidates, totalling 480 fits\n",
      "\n",
      "Best parameters for Logistic Regression:\n",
      "Mean CV accuracy: 0.8611\n",
      "Parameters: {'C': 50.0, 'multi_class': 'ovr', 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "Train-Test gap: 0.1389\n",
      "\n",
      "Tuning Logistic Regression without_product_type...\n",
      "Using GridSearchCV for Logistic Regression\n",
      "Fitting 10 folds for each of 48 candidates, totalling 480 fits\n",
      "\n",
      "Best parameters for Logistic Regression:\n",
      "Mean CV accuracy: 0.8444\n",
      "Parameters: {'C': 0.1, 'multi_class': 'ovr', 'penalty': None, 'solver': 'newton-cg'}\n",
      "Train-Test gap: 0.1556\n",
      "\n",
      "==================================================\n",
      "Comparison Results for Logistic Regression\n",
      "==================================================\n",
      "\n",
      "Results with_product_type:\n",
      "Best parameters: {'C': 50.0, 'multi_class': 'ovr', 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "Mean CV accuracy: 0.8611\n",
      "\n",
      "Results without_product_type:\n",
      "Best parameters: {'C': 0.1, 'multi_class': 'ovr', 'penalty': None, 'solver': 'newton-cg'}\n",
      "Mean CV accuracy: 0.8444\n",
      "\n",
      "Performance difference (with_product_type - without_product_type): 0.0167\n",
      "\n",
      "Recommendation: Consider using the model without_product_type for better generalization,\n",
      "as the performance difference is minimal (<2%).\n",
      "Warning: LDA not found in parameter grids. Skipping.\n",
      "\n",
      "Model Performance Summary:\n",
      "================================================================================\n",
      "\n",
      "With Product Type:\n",
      "----------------------------------------\n",
      "\n",
      "SVM:\n",
      "Best Parameters: {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "\n",
      "Random Forest:\n",
      "Best Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "\n",
      "KNN:\n",
      "Best Parameters: {'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "\n",
      "Neural Network:\n",
      "Best Parameters: {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.005, 'solver': 'adam'}\n",
      "\n",
      "Logistic Regression:\n",
      "Best Parameters: {'C': 50.0, 'multi_class': 'ovr', 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "\n",
      "Without Product Type:\n",
      "----------------------------------------\n",
      "\n",
      "SVM:\n",
      "Best Parameters: {'C': 50, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "\n",
      "Random Forest:\n",
      "Best Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "\n",
      "KNN:\n",
      "Best Parameters: {'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "\n",
      "Neural Network:\n",
      "Best Parameters: {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.005, 'solver': 'adam'}\n",
      "\n",
      "Logistic Regression:\n",
      "Best Parameters: {'C': 0.1, 'multi_class': 'ovr', 'penalty': None, 'solver': 'newton-cg'}\n",
      "\n",
      "Results have been saved to 'hyperparameter_tuning/grid_search_lda_storage_condition_results.json'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yohan\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# LDA Storage Condition Classification with Grid Search\n",
    "import grid_search as gst\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv('../augmented_bakery_data.csv')\n",
    "\n",
    "# Prepare features\n",
    "feature_cols = [col for col in data.columns if col.startswith(('gain_', 'phase_'))]\n",
    "X_base = data[feature_cols]\n",
    "\n",
    "# Encode target\n",
    "le_storage = LabelEncoder()\n",
    "y_storage = le_storage.fit_transform(data['Storage_Condition'])\n",
    "\n",
    "# Encode extra feature (Product_Type)\n",
    "le_product = LabelEncoder()\n",
    "product_encoded = le_product.fit_transform(data['Product_Type'])\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_base)\n",
    "\n",
    "# Create datasets with and without product type\n",
    "X_without_product = X_scaled\n",
    "X_with_product = np.column_stack([X_scaled, product_encoded.reshape(-1, 1)])\n",
    "\n",
    "# For LDA, we need to modify the parameter grids to include LDA-specific params\n",
    "param_grids = gst.get_param_grids()\n",
    "\n",
    "# Add LDA-specific parameters\n",
    "param_grids['LDA'] = {\n",
    "    'model': LDA(),\n",
    "    'params': {\n",
    "        'solver': ['svd', 'lsqr', 'eigen'],\n",
    "        'shrinkage': [None, 'auto', 0.1, 0.5, 0.9]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Run hyperparameter tuning with grid search for all models including LDA\n",
    "model_types = list(param_grids.keys())  # This will include the newly added LDA\n",
    "\n",
    "results = gst.run_all_models_comparison(\n",
    "    X_with_product,\n",
    "    X_without_product,\n",
    "    y_storage,\n",
    "    model_types=model_types,\n",
    "    with_label='with_product_type',\n",
    "    without_label='without_product_type'\n",
    ")\n",
    "\n",
    "# Save the results\n",
    "gst.save_results(\n",
    "    results,\n",
    "    'hyperparameter_tuning/grid_search_lda_storage_condition_results.json',\n",
    "    with_label='with_product_type',\n",
    "    without_label='without_product_type'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "######################################################################\n",
      "Running comparison for SVM\n",
      "######################################################################\n",
      "\n",
      "Tuning SVM with_storage_condition...\n",
      "Using GridSearchCV for SVM\n",
      "Fitting 10 folds for each of 50 candidates, totalling 500 fits\n",
      "\n",
      "Best parameters for SVM:\n",
      "Mean CV accuracy: 0.9833\n",
      "Parameters: {'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "Train-Test gap: 0.0056\n",
      "\n",
      "Tuning SVM without_storage_condition...\n",
      "Using GridSearchCV for SVM\n",
      "Fitting 10 folds for each of 50 candidates, totalling 500 fits\n",
      "\n",
      "Best parameters for SVM:\n",
      "Mean CV accuracy: 0.9833\n",
      "Parameters: {'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "Train-Test gap: 0.0056\n",
      "\n",
      "==================================================\n",
      "Comparison Results for SVM\n",
      "==================================================\n",
      "\n",
      "Results with_storage_condition:\n",
      "Best parameters: {'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "Mean CV accuracy: 0.9833\n",
      "\n",
      "Results without_storage_condition:\n",
      "Best parameters: {'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "Mean CV accuracy: 0.9833\n",
      "\n",
      "Performance difference (with_storage_condition - without_storage_condition): 0.0000\n",
      "\n",
      "Recommendation: Consider using the model without_storage_condition for better generalization,\n",
      "as the performance difference is minimal (<2%).\n",
      "\n",
      "######################################################################\n",
      "Running comparison for Random Forest\n",
      "######################################################################\n",
      "\n",
      "Tuning Random Forest with_storage_condition...\n",
      "Using GridSearchCV for Random Forest\n",
      "Fitting 10 folds for each of 240 candidates, totalling 2400 fits\n",
      "\n",
      "Best parameters for Random Forest:\n",
      "Mean CV accuracy: 0.9889\n",
      "Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "Train-Test gap: 0.0111\n",
      "\n",
      "Tuning Random Forest without_storage_condition...\n",
      "Using GridSearchCV for Random Forest\n",
      "Fitting 10 folds for each of 240 candidates, totalling 2400 fits\n",
      "\n",
      "Best parameters for Random Forest:\n",
      "Mean CV accuracy: 0.9889\n",
      "Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "Train-Test gap: 0.0111\n",
      "\n",
      "==================================================\n",
      "Comparison Results for Random Forest\n",
      "==================================================\n",
      "\n",
      "Results with_storage_condition:\n",
      "Best parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "Mean CV accuracy: 0.9889\n",
      "\n",
      "Results without_storage_condition:\n",
      "Best parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "Mean CV accuracy: 0.9889\n",
      "\n",
      "Performance difference (with_storage_condition - without_storage_condition): 0.0000\n",
      "\n",
      "Recommendation: Consider using the model without_storage_condition for better generalization,\n",
      "as the performance difference is minimal (<2%).\n",
      "\n",
      "######################################################################\n",
      "Running comparison for KNN\n",
      "######################################################################\n",
      "\n",
      "Tuning KNN with_storage_condition...\n",
      "Using GridSearchCV for KNN\n",
      "Fitting 10 folds for each of 16 candidates, totalling 160 fits\n",
      "\n",
      "Best parameters for KNN:\n",
      "Mean CV accuracy: 0.9944\n",
      "Parameters: {'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "Train-Test gap: 0.0056\n",
      "\n",
      "Tuning KNN without_storage_condition...\n",
      "Using GridSearchCV for KNN\n",
      "Fitting 10 folds for each of 16 candidates, totalling 160 fits\n",
      "\n",
      "Best parameters for KNN:\n",
      "Mean CV accuracy: 0.9889\n",
      "Parameters: {'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'uniform'}\n",
      "Train-Test gap: 0.0099\n",
      "\n",
      "==================================================\n",
      "Comparison Results for KNN\n",
      "==================================================\n",
      "\n",
      "Results with_storage_condition:\n",
      "Best parameters: {'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "Mean CV accuracy: 0.9944\n",
      "\n",
      "Results without_storage_condition:\n",
      "Best parameters: {'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'uniform'}\n",
      "Mean CV accuracy: 0.9889\n",
      "\n",
      "Performance difference (with_storage_condition - without_storage_condition): 0.0056\n",
      "\n",
      "Recommendation: Consider using the model without_storage_condition for better generalization,\n",
      "as the performance difference is minimal (<2%).\n",
      "\n",
      "######################################################################\n",
      "Running comparison for Neural Network\n",
      "######################################################################\n",
      "\n",
      "Tuning Neural Network with_storage_condition...\n",
      "Using GridSearchCV for Neural Network\n",
      "Fitting 10 folds for each of 72 candidates, totalling 720 fits\n",
      "\n",
      "Best parameters for Neural Network:\n",
      "Mean CV accuracy: 0.9667\n",
      "Parameters: {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.01, 'solver': 'adam'}\n",
      "Train-Test gap: 0.0019\n",
      "\n",
      "Tuning Neural Network without_storage_condition...\n",
      "Using GridSearchCV for Neural Network\n",
      "Fitting 10 folds for each of 72 candidates, totalling 720 fits\n",
      "\n",
      "Best parameters for Neural Network:\n",
      "Mean CV accuracy: 0.9500\n",
      "Parameters: {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.01, 'solver': 'adam'}\n",
      "Train-Test gap: 0.0056\n",
      "\n",
      "==================================================\n",
      "Comparison Results for Neural Network\n",
      "==================================================\n",
      "\n",
      "Results with_storage_condition:\n",
      "Best parameters: {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.01, 'solver': 'adam'}\n",
      "Mean CV accuracy: 0.9667\n",
      "\n",
      "Results without_storage_condition:\n",
      "Best parameters: {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.01, 'solver': 'adam'}\n",
      "Mean CV accuracy: 0.9500\n",
      "\n",
      "Performance difference (with_storage_condition - without_storage_condition): 0.0167\n",
      "\n",
      "Recommendation: Consider using the model without_storage_condition for better generalization,\n",
      "as the performance difference is minimal (<2%).\n",
      "\n",
      "######################################################################\n",
      "Running comparison for Logistic Regression\n",
      "######################################################################\n",
      "\n",
      "Tuning Logistic Regression with_storage_condition...\n",
      "Using GridSearchCV for Logistic Regression\n",
      "Fitting 10 folds for each of 48 candidates, totalling 480 fits\n",
      "\n",
      "Best parameters for Logistic Regression:\n",
      "Mean CV accuracy: 0.9833\n",
      "Parameters: {'C': 0.1, 'multi_class': 'ovr', 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "Train-Test gap: -0.0000\n",
      "\n",
      "Tuning Logistic Regression without_storage_condition...\n",
      "Using GridSearchCV for Logistic Regression\n",
      "Fitting 10 folds for each of 48 candidates, totalling 480 fits\n",
      "\n",
      "Best parameters for Logistic Regression:\n",
      "Mean CV accuracy: 0.9833\n",
      "Parameters: {'C': 0.1, 'multi_class': 'ovr', 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "Train-Test gap: -0.0000\n",
      "\n",
      "==================================================\n",
      "Comparison Results for Logistic Regression\n",
      "==================================================\n",
      "\n",
      "Results with_storage_condition:\n",
      "Best parameters: {'C': 0.1, 'multi_class': 'ovr', 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "Mean CV accuracy: 0.9833\n",
      "\n",
      "Results without_storage_condition:\n",
      "Best parameters: {'C': 0.1, 'multi_class': 'ovr', 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "Mean CV accuracy: 0.9833\n",
      "\n",
      "Performance difference (with_storage_condition - without_storage_condition): 0.0000\n",
      "\n",
      "Recommendation: Consider using the model without_storage_condition for better generalization,\n",
      "as the performance difference is minimal (<2%).\n",
      "Warning: LDA not found in parameter grids. Skipping.\n",
      "\n",
      "Model Performance Summary:\n",
      "================================================================================\n",
      "\n",
      "With Storage Condition:\n",
      "----------------------------------------\n",
      "\n",
      "SVM:\n",
      "Best Parameters: {'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "\n",
      "Random Forest:\n",
      "Best Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "\n",
      "KNN:\n",
      "Best Parameters: {'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "\n",
      "Neural Network:\n",
      "Best Parameters: {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.01, 'solver': 'adam'}\n",
      "\n",
      "Logistic Regression:\n",
      "Best Parameters: {'C': 0.1, 'multi_class': 'ovr', 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "\n",
      "Without Storage Condition:\n",
      "----------------------------------------\n",
      "\n",
      "SVM:\n",
      "Best Parameters: {'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "\n",
      "Random Forest:\n",
      "Best Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "\n",
      "KNN:\n",
      "Best Parameters: {'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'uniform'}\n",
      "\n",
      "Neural Network:\n",
      "Best Parameters: {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.01, 'solver': 'adam'}\n",
      "\n",
      "Logistic Regression:\n",
      "Best Parameters: {'C': 0.1, 'multi_class': 'ovr', 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "\n",
      "Results have been saved to 'hyperparameter_tuning/grid_search_lda_product_type_results.json'\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# LDA Product Type Classification with Grid Search\n",
    "import grid_search as gst\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv('../augmented_bakery_data.csv')\n",
    "\n",
    "# Prepare features\n",
    "feature_cols = [col for col in data.columns if col.startswith(('gain_', 'phase_'))]\n",
    "X_base = data[feature_cols]\n",
    "\n",
    "# Encode target\n",
    "le_product = LabelEncoder()\n",
    "y_product = le_product.fit_transform(data['Product_Type'])\n",
    "\n",
    "# Encode extra feature (Storage_Condition)\n",
    "le_storage = LabelEncoder()\n",
    "storage_encoded = le_storage.fit_transform(data['Storage_Condition'])\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_base)\n",
    "\n",
    "# Create datasets with and without storage condition\n",
    "X_without_storage = X_scaled\n",
    "X_with_storage = np.hstack([X_spectral_scaled, storage_condition.values])\n",
    "\n",
    "# For LDA, use the modified parameter grids like in the previous example\n",
    "param_grids = gst.get_param_grids()\n",
    "param_grids['LDA'] = {\n",
    "    'model': LDA(),\n",
    "    'params': {\n",
    "        'solver': ['svd', 'lsqr', 'eigen'],\n",
    "        'shrinkage': [None, 'auto', 0.1, 0.5, 0.9]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Run hyperparameter tuning with grid search for all models including LDA\n",
    "model_types = list(param_grids.keys())\n",
    "\n",
    "results = gst.run_all_models_comparison(\n",
    "    X_with_storage,\n",
    "    X_without_storage,\n",
    "    y_product,\n",
    "    model_types=model_types,\n",
    "    with_label='with_storage_condition',\n",
    "    without_label='without_storage_condition'\n",
    ")\n",
    "\n",
    "# Save the results\n",
    "gst.save_results(\n",
    "    results,\n",
    "    'hyperparameter_tuning/grid_search_lda_product_type_results.json',\n",
    "    with_label='with_storage_condition',\n",
    "    without_label='without_storage_condition'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Add this new cell\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_cv_score_distribution(X_with, X_without, y, model_name):\n",
    "    \"\"\"Plot distribution of cross-validation scores\"\"\"\n",
    "    # Get the best models\n",
    "    model_with = all_results[model_name]['with_product_type']['best_model']\n",
    "    model_without = all_results[model_name]['without_product_type']['best_model']\n",
    "    \n",
    "    # Get cross-validation scores\n",
    "    scores_with = cross_val_score(model_with, X_with, y, cv=10)\n",
    "    scores_without = cross_val_score(model_without, X_without, y, cv=10)\n",
    "    \n",
    "    # Plot distributions\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.boxplot([scores_with, scores_without], labels=['With Product Type', 'Without Product Type'])\n",
    "    plt.title(f'{model_name} Cross-validation Score Distribution')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    # Print statistical summary\n",
    "    print(f\"\\nCross-validation scores summary for {model_name}:\")\n",
    "    print(\"\\nWith Product Type:\")\n",
    "    print(f\"Mean: {scores_with.mean():.4f}\")\n",
    "    print(f\"Std: {scores_with.std():.4f}\")\n",
    "    print(\"\\nWithout Product Type:\")\n",
    "    print(f\"Mean: {scores_without.mean():.4f}\")\n",
    "    print(f\"Std: {scores_without.std():.4f}\")\n",
    "\n",
    "# Plot CV score distribution for Random Forest\n",
    "plot_cv_score_distribution(X_with_product, X_without_product, y_storage, 'Random Forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
