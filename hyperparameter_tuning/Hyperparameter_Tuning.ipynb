{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Common Imports and Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Common Imports and Constants\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "import json\n",
    "from hyperparameter_tuning import get_param_grids, run_all_models_comparison\n",
    "\n",
    "# Constants\n",
    "RANDOM_STATE = 42\n",
    "CV_SPLITS = 10\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_class_balance(data, target_column):\n",
    "    \"\"\"Check class balance in the dataset\"\"\"\n",
    "    counts = data[target_column].value_counts()\n",
    "    percentages = data[target_column].value_counts(normalize=True) * 100\n",
    "    \n",
    "    print(f\"Class Distribution for {target_column}:\")\n",
    "    for label, count, percentage in zip(counts.index, counts, percentages):\n",
    "        print(f\"{label}: {count} samples ({percentage:.2f}%)\")\n",
    "    \n",
    "    # Calculate imbalance ratio\n",
    "    min_count = counts.min()\n",
    "    max_count = counts.max()\n",
    "    imbalance_ratio = min_count / max_count\n",
    "    \n",
    "    print(f\"\\nImbalance ratio: {imbalance_ratio:.4f}\")\n",
    "    if imbalance_ratio > 0.8:\n",
    "        print(\"Status: Well balanced (ratio > 0.8)\")\n",
    "    elif imbalance_ratio > 0.5:\n",
    "        print(\"Status: Moderately imbalanced (0.5 < ratio < 0.8)\")\n",
    "    else:\n",
    "        print(\"Status: Highly imbalanced (ratio < 0.5)\")\n",
    "    \n",
    "    return imbalance_ratio\n",
    "\n",
    "# Add this at the beginning of your notebook\n",
    "data = pd.read_csv('../augmented_bakery_data.csv')\n",
    "print(\"Checking class balance...\")\n",
    "check_class_balance(data, 'Storage_Condition')\n",
    "check_class_balance(data, 'Product_Type')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data preparation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_base_data():\n",
    "    \"\"\"Load and prepare initial data\"\"\"\n",
    "    print(\"Loading and preparing data...\")\n",
    "    data = pd.read_csv('../augmented_bakery_data.csv')\n",
    "    \n",
    "    # Encode labels\n",
    "    le_product = LabelEncoder()\n",
    "    le_storage = LabelEncoder()\n",
    "    data['Product_Type_encoded'] = le_product.fit_transform(data['Product_Type'])\n",
    "    data['Storage_Condition_encoded'] = le_storage.fit_transform(data['Storage_Condition'])\n",
    "    \n",
    "    # Prepare spectral features\n",
    "    spectral_cols = [col for col in data.columns if col.startswith(('gain_', 'phase_'))]\n",
    "    X_spectral = data[spectral_cols]\n",
    "    \n",
    "    # Scale spectral features\n",
    "    scaler = StandardScaler()\n",
    "    X_spectral_scaled = scaler.fit_transform(X_spectral)\n",
    "    \n",
    "    return data, X_spectral_scaled, le_product, le_storage\n",
    "\n",
    "def save_results(results, filename, with_label, without_label):\n",
    "    \"\"\"Save and display results\"\"\"\n",
    "    results_summary = {\n",
    "        with_label: {},\n",
    "        without_label: {}\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nModel Performance Summary:\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    for dataset_type in [with_label, without_label]:\n",
    "        print(f\"\\n{dataset_type.replace('_', ' ').title()}:\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        for model_name, model_results in results.items():\n",
    "            key = 'with_product_type' if 'with' in dataset_type else 'without_product_type'\n",
    "            # Get the parameters directly without the 'best_params' wrapper\n",
    "            params = model_results[key]['best_params']\n",
    "            \n",
    "            # Store parameters directly in the results summary\n",
    "            results_summary[dataset_type][model_name] = params\n",
    "            \n",
    "            print(f\"\\n{model_name}:\")\n",
    "            print(f\"Best Parameters: {params}\")\n",
    "    \n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(results_summary, f, indent=4)\n",
    "    print(f\"\\nResults have been saved to '{filename}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "def compare_models_statistically(all_results):\n",
    "    \"\"\"Perform statistical comparison between models with and without additional features\"\"\"\n",
    "    print(\"\\nStatistical Comparison of Models:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    for model_name, results in all_results.items():\n",
    "        # Get CV results\n",
    "        with_scores = results['with_product_type']['cv_results']['mean_test_score']\n",
    "        without_scores = results['without_product_type']['cv_results']['mean_test_score']\n",
    "        \n",
    "        # Perform paired t-test\n",
    "        t_stat, p_value = stats.ttest_rel(with_scores, without_scores)\n",
    "        \n",
    "        print(f\"\\n{model_name}:\")\n",
    "        print(f\"Mean with product type: {results['with_product_type']['best_score']:.4f}\")\n",
    "        print(f\"Mean without product type: {results['without_product_type']['best_score']:.4f}\")\n",
    "        print(f\"Difference: {results['with_product_type']['best_score'] - results['without_product_type']['best_score']:.4f}\")\n",
    "        print(f\"p-value: {p_value:.4f}\")\n",
    "        print(f\"Statistically significant difference: {'Yes' if p_value < 0.05 else 'No'}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Storage Condition Hyperparameter Tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Storage Condition Classification...\n",
      "Loading and preparing data...\n",
      "Dataset shapes:\n",
      "X without product type: (180, 202)\n",
      "X with product type: (180, 203)\n",
      "Storage conditions: {'Humid': 0, 'Open': 1, 'Wrapped': 2}\n",
      "\n",
      "######################################################################\n",
      "Running comparison for SVM\n",
      "######################################################################\n",
      "\n",
      "Tuning SVM with product_type...\n",
      "Using RandomizedSearchCV with 30 iterations for SVM\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "\n",
      "Best parameters for SVM:\n",
      "Mean CV accuracy: 0.9333\n",
      "Parameters: {'C': 89.06204386161681, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Train-Test gap: 0.0617\n",
      "\n",
      "Tuning SVM without product_type...\n",
      "Using RandomizedSearchCV with 30 iterations for SVM\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "\n",
      "Best parameters for SVM:\n",
      "Mean CV accuracy: 0.9167\n",
      "Parameters: {'C': 89.06204386161681, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Train-Test gap: 0.0796\n",
      "\n",
      "==================================================\n",
      "Comparison Results for SVM\n",
      "==================================================\n",
      "\n",
      "Results with product type:\n",
      "Best parameters: {'C': 89.06204386161681, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Mean CV accuracy: 0.9333\n",
      "\n",
      "Results without product type:\n",
      "Best parameters: {'C': 89.06204386161681, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Mean CV accuracy: 0.9167\n",
      "\n",
      "Performance difference (with - without): 0.0167\n",
      "\n",
      "Recommendation: Consider using the model without product type for better generalization,\n",
      "as the performance difference is minimal (<2%).\n",
      "\n",
      "######################################################################\n",
      "Running comparison for Random Forest\n",
      "######################################################################\n",
      "\n",
      "Tuning Random Forest with product_type...\n",
      "Using RandomizedSearchCV with 30 iterations for Random Forest\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "\n",
      "Best parameters for Random Forest:\n",
      "Mean CV accuracy: 0.9667\n",
      "Parameters: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 137}\n",
      "Train-Test gap: 0.0333\n",
      "\n",
      "Tuning Random Forest without product_type...\n",
      "Using RandomizedSearchCV with 30 iterations for Random Forest\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "\n",
      "Best parameters for Random Forest:\n",
      "Mean CV accuracy: 0.9611\n",
      "Parameters: {'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 138}\n",
      "Train-Test gap: 0.0389\n",
      "\n",
      "==================================================\n",
      "Comparison Results for Random Forest\n",
      "==================================================\n",
      "\n",
      "Results with product type:\n",
      "Best parameters: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 137}\n",
      "Mean CV accuracy: 0.9667\n",
      "\n",
      "Results without product type:\n",
      "Best parameters: {'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 138}\n",
      "Mean CV accuracy: 0.9611\n",
      "\n",
      "Performance difference (with - without): 0.0056\n",
      "\n",
      "Recommendation: Consider using the model without product type for better generalization,\n",
      "as the performance difference is minimal (<2%).\n",
      "\n",
      "######################################################################\n",
      "Running comparison for KNN\n",
      "######################################################################\n",
      "\n",
      "Tuning KNN with product_type...\n",
      "Using GridSearchCV for KNN\n",
      "Fitting 10 folds for each of 16 candidates, totalling 160 fits\n",
      "\n",
      "Best parameters for KNN:\n",
      "Mean CV accuracy: 0.9000\n",
      "Parameters: {'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "Train-Test gap: 0.1000\n",
      "\n",
      "Tuning KNN without product_type...\n",
      "Using GridSearchCV for KNN\n",
      "Fitting 10 folds for each of 16 candidates, totalling 160 fits\n",
      "\n",
      "Best parameters for KNN:\n",
      "Mean CV accuracy: 0.9000\n",
      "Parameters: {'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "Train-Test gap: 0.1000\n",
      "\n",
      "==================================================\n",
      "Comparison Results for KNN\n",
      "==================================================\n",
      "\n",
      "Results with product type:\n",
      "Best parameters: {'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "Mean CV accuracy: 0.9000\n",
      "\n",
      "Results without product type:\n",
      "Best parameters: {'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "Mean CV accuracy: 0.9000\n",
      "\n",
      "Performance difference (with - without): 0.0000\n",
      "\n",
      "Recommendation: Consider using the model without product type for better generalization,\n",
      "as the performance difference is minimal (<2%).\n",
      "\n",
      "######################################################################\n",
      "Running comparison for Neural Network\n",
      "######################################################################\n",
      "\n",
      "Tuning Neural Network with product_type...\n",
      "Using RandomizedSearchCV with 30 iterations for Neural Network\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "\n",
      "Best parameters for Neural Network:\n",
      "Mean CV accuracy: 0.6000\n",
      "Parameters: {'activation': 'relu', 'alpha': 0.009363008785133489, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.0021586905952512975, 'solver': 'adam'}\n",
      "Train-Test gap: 0.0364\n",
      "\n",
      "Tuning Neural Network without product_type...\n",
      "Using RandomizedSearchCV with 30 iterations for Neural Network\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "\n",
      "Best parameters for Neural Network:\n",
      "Mean CV accuracy: 0.6444\n",
      "Parameters: {'activation': 'relu', 'alpha': 0.0032435598107632664, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.007955160864261276, 'solver': 'adam'}\n",
      "Train-Test gap: 0.1136\n",
      "\n",
      "==================================================\n",
      "Comparison Results for Neural Network\n",
      "==================================================\n",
      "\n",
      "Results with product type:\n",
      "Best parameters: {'activation': 'relu', 'alpha': 0.009363008785133489, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.0021586905952512975, 'solver': 'adam'}\n",
      "Mean CV accuracy: 0.6000\n",
      "\n",
      "Results without product type:\n",
      "Best parameters: {'activation': 'relu', 'alpha': 0.0032435598107632664, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.007955160864261276, 'solver': 'adam'}\n",
      "Mean CV accuracy: 0.6444\n",
      "\n",
      "Performance difference (with - without): -0.0444\n",
      "\n",
      "Recommendation: Use the model without product type,\n",
      "as it shows better performance and provides better generalization.\n",
      "\n",
      "######################################################################\n",
      "Running comparison for Logistic Regression\n",
      "######################################################################\n",
      "\n",
      "Tuning Logistic Regression with product_type...\n",
      "Using RandomizedSearchCV with 30 iterations for Logistic Regression\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "\n",
      "Best parameters for Logistic Regression:\n",
      "Mean CV accuracy: 0.8833\n",
      "Parameters: {'C': 38.9677289689482, 'multi_class': 'multinomial', 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "Train-Test gap: 0.1167\n",
      "\n",
      "Tuning Logistic Regression without product_type...\n",
      "Using RandomizedSearchCV with 30 iterations for Logistic Regression\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "\n",
      "Best parameters for Logistic Regression:\n",
      "Mean CV accuracy: 0.8722\n",
      "Parameters: {'C': 38.9677289689482, 'multi_class': 'multinomial', 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "Train-Test gap: 0.1278\n",
      "\n",
      "==================================================\n",
      "Comparison Results for Logistic Regression\n",
      "==================================================\n",
      "\n",
      "Results with product type:\n",
      "Best parameters: {'C': 38.9677289689482, 'multi_class': 'multinomial', 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "Mean CV accuracy: 0.8833\n",
      "\n",
      "Results without product type:\n",
      "Best parameters: {'C': 38.9677289689482, 'multi_class': 'multinomial', 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "Mean CV accuracy: 0.8722\n",
      "\n",
      "Performance difference (with - without): 0.0111\n",
      "\n",
      "Recommendation: Consider using the model without product type for better generalization,\n",
      "as the performance difference is minimal (<2%).\n",
      "\n",
      "Model Performance Summary:\n",
      "================================================================================\n",
      "\n",
      "With Product Type:\n",
      "----------------------------------------\n",
      "\n",
      "SVM:\n",
      "Best Parameters: {'C': 89.06204386161681, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "\n",
      "Random Forest:\n",
      "Best Parameters: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 137}\n",
      "\n",
      "KNN:\n",
      "Best Parameters: {'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "\n",
      "Neural Network:\n",
      "Best Parameters: {'activation': 'relu', 'alpha': 0.009363008785133489, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.0021586905952512975, 'solver': 'adam'}\n",
      "\n",
      "Logistic Regression:\n",
      "Best Parameters: {'C': 38.9677289689482, 'multi_class': 'multinomial', 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "\n",
      "Without Product Type:\n",
      "----------------------------------------\n",
      "\n",
      "SVM:\n",
      "Best Parameters: {'C': 89.06204386161681, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "\n",
      "Random Forest:\n",
      "Best Parameters: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 137}\n",
      "\n",
      "KNN:\n",
      "Best Parameters: {'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "\n",
      "Neural Network:\n",
      "Best Parameters: {'activation': 'relu', 'alpha': 0.009363008785133489, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.0021586905952512975, 'solver': 'adam'}\n",
      "\n",
      "Logistic Regression:\n",
      "Best Parameters: {'C': 38.9677289689482, 'multi_class': 'multinomial', 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "\n",
      "Results have been saved to 'storage_condition_results.json'\n",
      "\n",
      "Statistical Comparison of Models:\n",
      "==================================================\n",
      "\n",
      "SVM:\n",
      "Mean with product type: 0.9333\n",
      "Mean without product type: 0.9167\n",
      "Difference: 0.0167\n",
      "p-value: 0.0003\n",
      "Statistically significant difference: Yes\n",
      "\n",
      "Random Forest:\n",
      "Mean with product type: 0.9667\n",
      "Mean without product type: 0.9611\n",
      "Difference: 0.0056\n",
      "p-value: 0.0723\n",
      "Statistically significant difference: No\n",
      "\n",
      "KNN:\n",
      "Mean with product type: 0.9000\n",
      "Mean without product type: 0.9000\n",
      "Difference: 0.0000\n",
      "p-value: 0.3332\n",
      "Statistically significant difference: No\n",
      "\n",
      "Neural Network:\n",
      "Mean with product type: 0.6000\n",
      "Mean without product type: 0.6444\n",
      "Difference: -0.0444\n",
      "p-value: 0.4919\n",
      "Statistically significant difference: No\n",
      "\n",
      "Logistic Regression:\n",
      "Mean with product type: 0.8833\n",
      "Mean without product type: 0.8722\n",
      "Difference: 0.0111\n",
      "p-value: 0.0000\n",
      "Statistically significant difference: Yes\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Cell 3: Storage Condition Classification\n",
    "print(\"Running Storage Condition Classification...\")\n",
    "data, X_spectral_scaled, le_product, le_storage = prepare_base_data()\n",
    "\n",
    "# Prepare datasets\n",
    "product_type = data['Product_Type_encoded'].values.reshape(-1, 1)\n",
    "X_with_product = np.column_stack([X_spectral_scaled, product_type])\n",
    "X_without_product = X_spectral_scaled\n",
    "y_storage = data['Storage_Condition_encoded'].values\n",
    "\n",
    "print(f\"Dataset shapes:\")\n",
    "print(f\"X without product type: {X_without_product.shape}\")\n",
    "print(f\"X with product type: {X_with_product.shape}\")\n",
    "print(f\"Storage conditions: {dict(zip(le_storage.classes_, le_storage.transform(le_storage.classes_)))}\")\n",
    "\n",
    "# Run tuning\n",
    "all_results = run_all_models_comparison(X_with_product, X_without_product, y_storage)\n",
    "save_results(all_results, 'storage_condition_results.json', 'with_product_type', 'without_product_type')\n",
    "# Add this after running the analysis\n",
    "compare_models_statistically(all_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Product Type Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Product Type Classification\n",
    "print(\"\\nRunning Product Type Classification...\")\n",
    "data, X_spectral_scaled, le_product, le_storage = prepare_base_data()\n",
    "\n",
    "# Prepare datasets\n",
    "storage_condition = data['Storage_Condition_encoded'].values.reshape(-1, 1)\n",
    "X_with_storage = np.column_stack([X_spectral_scaled, storage_condition])\n",
    "X_without_storage = X_spectral_scaled\n",
    "y_product = data['Product_Type_encoded'].values\n",
    "\n",
    "print(f\"Dataset shapes:\")\n",
    "print(f\"X without storage condition: {X_without_storage.shape}\")\n",
    "print(f\"X with storage condition: {X_with_storage.shape}\")\n",
    "print(f\"Product types: {dict(zip(le_product.classes_, le_product.transform(le_product.classes_)))}\")\n",
    "\n",
    "# Run tuning\n",
    "all_results = run_all_models_comparison(X_with_storage, X_without_storage, y_product)\n",
    "save_results(all_results, 'product_type_results.json', 'with_storage_condition', 'without_storage_condition')\n",
    "# Add this after running the analysis\n",
    "compare_models_statistically(all_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Storage Condition Hyperparameter Tuning\n",
    " with LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Storage Condition Classification with LDA\n",
    "print(\"\\nRunning Storage Condition Classification with LDA...\")\n",
    "data, X_spectral_scaled, le_product, le_storage = prepare_base_data()\n",
    "\n",
    "# Apply LDA\n",
    "y_storage = data['Storage_Condition_encoded'].values\n",
    "lda = LDA(n_components=min(len(np.unique(y_storage)) - 1, X_spectral_scaled.shape[1]))\n",
    "X_lda = lda.fit_transform(X_spectral_scaled, y_storage)\n",
    "\n",
    "# Prepare datasets\n",
    "product_type = data['Product_Type_encoded'].values.reshape(-1, 1)\n",
    "X_with_product = np.column_stack([X_lda, product_type])\n",
    "X_without_product = X_lda\n",
    "\n",
    "print(f\"Dataset shapes (LDA):\")\n",
    "print(f\"X without product type: {X_without_product.shape}\")\n",
    "print(f\"X with product type: {X_with_product.shape}\")\n",
    "\n",
    "# Run tuning\n",
    "all_results = run_all_models_comparison(X_with_product, X_without_product, y_storage)\n",
    "save_results(all_results, 'LDA_storage_condition_results.json', 'with_product_type', 'without_product_type')\n",
    "# Add this after running the analysis\n",
    "compare_models_statistically(all_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Product Type  Hyperparameter Tuning with LDA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Product Type Classification with LDA\n",
    "print(\"\\nRunning Product Type Classification with LDA...\")\n",
    "data, X_spectral_scaled, le_product, le_storage = prepare_base_data()\n",
    "\n",
    "# Apply LDA\n",
    "y_product = data['Product_Type_encoded'].values\n",
    "lda = LDA(n_components=min(len(np.unique(y_product)) - 1, X_spectral_scaled.shape[1]))\n",
    "X_lda = lda.fit_transform(X_spectral_scaled, y_product)\n",
    "\n",
    "# Prepare datasets\n",
    "storage_condition = data['Storage_Condition_encoded'].values.reshape(-1, 1)\n",
    "X_with_storage = np.column_stack([X_lda, storage_condition])\n",
    "X_without_storage = X_lda\n",
    "\n",
    "print(f\"Dataset shapes (LDA):\")\n",
    "print(f\"X without storage condition: {X_without_storage.shape}\")\n",
    "print(f\"X with storage condition: {X_with_storage.shape}\")\n",
    "\n",
    "# Run tuning\n",
    "all_results = run_all_models_comparison(X_with_storage, X_without_storage, y_product)\n",
    "save_results(all_results, 'LDA_product_type_results.json', 'with_storage_condition', 'without_storage_condition')\n",
    "# Add this after running the analysis\n",
    "compare_models_statistically(all_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "def compare_models_statistically(all_results):\n",
    "    \"\"\"Perform statistical comparison between models with and without additional features\"\"\"\n",
    "    print(\"\\nStatistical Comparison of Models:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    for model_name, results in all_results.items():\n",
    "        # Get CV results\n",
    "        with_scores = results['with_product_type']['cv_results']['mean_test_score']\n",
    "        without_scores = results['without_product_type']['cv_results']['mean_test_score']\n",
    "        \n",
    "        # Perform paired t-test\n",
    "        t_stat, p_value = stats.ttest_rel(with_scores, without_scores)\n",
    "        \n",
    "        print(f\"\\n{model_name}:\")\n",
    "        print(f\"Mean with product type: {results['with_product_type']['best_score']:.4f}\")\n",
    "        print(f\"Mean without product type: {results['without_product_type']['best_score']:.4f}\")\n",
    "        print(f\"Difference: {results['with_product_type']['best_score'] - results['without_product_type']['best_score']:.4f}\")\n",
    "        print(f\"p-value: {p_value:.4f}\")\n",
    "        print(f\"Statistically significant difference: {'Yes' if p_value < 0.05 else 'No'}\")\n",
    "\n",
    "# Add this after running the analysis\n",
    "compare_models_statistically(all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importance(model, feature_names, top_n=20):\n",
    "    \"\"\"Plot feature importance for Random Forest model\"\"\"\n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        # Get feature importances\n",
    "        importances = model.feature_importances_\n",
    "        \n",
    "        # Create DataFrame\n",
    "        feature_importance = pd.DataFrame({\n",
    "            'Feature': feature_names,\n",
    "            'Importance': importances\n",
    "        })\n",
    "        \n",
    "        # Sort by importance\n",
    "        feature_importance = feature_importance.sort_values('Importance', ascending=False)\n",
    "        \n",
    "        # Plot top N features\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        sns.barplot(x='Importance', y='Feature', data=feature_importance.head(top_n))\n",
    "        plt.title('Top Feature Importances')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('feature_importance.png')\n",
    "        plt.show()\n",
    "        \n",
    "        return feature_importance\n",
    "    else:\n",
    "        print(\"Model doesn't have feature_importances_ attribute\")\n",
    "        return None\n",
    "\n",
    "# Add this after running Random Forest\n",
    "spectral_cols = [col for col in data.columns if col.startswith(('gain_', 'phase_'))]\n",
    "rf_model = all_results['Random Forest']['with_product_type']['best_model']\n",
    "feature_names = spectral_cols + ['Product_Type']\n",
    "plot_feature_importance(rf_model, feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell: Model Performance Analysis\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def analyze_model_performance(all_results):\n",
    "    \"\"\"Analyze and visualize model performance including overfitting detection\"\"\"\n",
    "    \n",
    "    # Prepare data for plotting\n",
    "    models = []\n",
    "    train_scores = []\n",
    "    val_scores = []\n",
    "    cv_scores = []\n",
    "    variants = []\n",
    "    \n",
    "    for model_name, results in all_results.items():\n",
    "        for variant in ['with_product_type', 'without_product_type']:\n",
    "            models.append(model_name)\n",
    "            variants.append(variant)\n",
    "            res = results[variant]\n",
    "            train_scores.append(res['train_score'])\n",
    "            val_scores.append(res['validation_score'])\n",
    "            cv_scores.append(res['best_score'])\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'Model': models,\n",
    "        'Variant': variants,\n",
    "        'Training Score': train_scores,\n",
    "        'Validation Score': val_scores,\n",
    "        'CV Score': cv_scores\n",
    "    })\n",
    "    \n",
    "    # Plot performance comparison\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    \n",
    "    x = np.arange(len(df['Model'].unique()))\n",
    "    width = 0.15\n",
    "    \n",
    "    plt.bar(x - width, df[df['Variant'] == 'with_product_type']['Training Score'], \n",
    "            width, label='With Features (Train)', alpha=0.7)\n",
    "    plt.bar(x, df[df['Variant'] == 'with_product_type']['Validation Score'], \n",
    "            width, label='With Features (Val)', alpha=0.7)\n",
    "    plt.bar(x + width, df[df['Variant'] == 'without_product_type']['Training Score'], \n",
    "            width, label='Without Features (Train)', alpha=0.7)\n",
    "    plt.bar(x + 2*width, df[df['Variant'] == 'without_product_type']['Validation Score'], \n",
    "            width, label='Without Features (Val)', alpha=0.7)\n",
    "    \n",
    "    plt.xlabel('Models')\n",
    "    plt.ylabel('Score')\n",
    "    plt.title('Model Performance Comparison')\n",
    "    plt.xticks(x, df['Model'].unique(), rotation=45)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print overfitting analysis\n",
    "    print(\"\\nOverfitting Analysis:\")\n",
    "    print(\"=\" * 50)\n",
    "    for model_name, results in all_results.items():\n",
    "        print(f\"\\n{model_name}:\")\n",
    "        for variant in ['with_product_type', 'without_product_type']:\n",
    "            res = results[variant]\n",
    "            print(f\"\\n{variant}:\")\n",
    "            print(f\"Train-Val difference: {res['overfitting_score']:.4f}\")\n",
    "            if res['overfitting_score'] > 0.05:\n",
    "                print(\"WARNING: Potential overfitting detected!\")\n",
    "            elif res['overfitting_score'] < -0.05:\n",
    "                print(\"WARNING: Potential underfitting detected!\")\n",
    "            else:\n",
    "                print(\"Good fit!\")\n",
    "\n",
    "# Run the analysis\n",
    "analyze_model_performance(all_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Add this new cell\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_cv_score_distribution(X_with, X_without, y, model_name):\n",
    "    \"\"\"Plot distribution of cross-validation scores\"\"\"\n",
    "    # Get the best models\n",
    "    model_with = all_results[model_name]['with_product_type']['best_model']\n",
    "    model_without = all_results[model_name]['without_product_type']['best_model']\n",
    "    \n",
    "    # Get cross-validation scores\n",
    "    scores_with = cross_val_score(model_with, X_with, y, cv=10)\n",
    "    scores_without = cross_val_score(model_without, X_without, y, cv=10)\n",
    "    \n",
    "    # Plot distributions\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.boxplot([scores_with, scores_without], labels=['With Product Type', 'Without Product Type'])\n",
    "    plt.title(f'{model_name} Cross-validation Score Distribution')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    # Print statistical summary\n",
    "    print(f\"\\nCross-validation scores summary for {model_name}:\")\n",
    "    print(\"\\nWith Product Type:\")\n",
    "    print(f\"Mean: {scores_with.mean():.4f}\")\n",
    "    print(f\"Std: {scores_with.std():.4f}\")\n",
    "    print(\"\\nWithout Product Type:\")\n",
    "    print(f\"Mean: {scores_without.mean():.4f}\")\n",
    "    print(f\"Std: {scores_without.std():.4f}\")\n",
    "\n",
    "# Plot CV score distribution for Random Forest\n",
    "plot_cv_score_distribution(X_with_product, X_without_product, y_storage, 'Random Forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
