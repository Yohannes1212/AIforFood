{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running classification analysis for product_type\n",
      "==================================================\n",
      "\n",
      "Evaluating SVM...\n",
      "\n",
      "Results for SVM:\n",
      "Cross-validation scores: [0.63888889 0.61111111 0.72222222 0.75       0.61111111]\n",
      "Mean CV accuracy: 0.6667 (±0.0583)\n",
      "Test set accuracy: 0.9722\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Bread       1.00      0.95      0.97        20\n",
      "     Cookies       0.94      1.00      0.97        16\n",
      "\n",
      "    accuracy                           0.97        36\n",
      "   macro avg       0.97      0.97      0.97        36\n",
      "weighted avg       0.97      0.97      0.97        36\n",
      "\n",
      "\n",
      "Evaluating Random Forest...\n",
      "\n",
      "Results for Random Forest:\n",
      "Cross-validation scores: [0.97222222 1.         1.         1.         0.97222222]\n",
      "Mean CV accuracy: 0.9889 (±0.0136)\n",
      "Test set accuracy: 1.0000\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Bread       1.00      1.00      1.00        20\n",
      "     Cookies       1.00      1.00      1.00        16\n",
      "\n",
      "    accuracy                           1.00        36\n",
      "   macro avg       1.00      1.00      1.00        36\n",
      "weighted avg       1.00      1.00      1.00        36\n",
      "\n",
      "\n",
      "Evaluating KNN...\n",
      "\n",
      "Results for KNN:\n",
      "Cross-validation scores: [0.97222222 0.97222222 1.         1.         0.97222222]\n",
      "Mean CV accuracy: 0.9833 (±0.0136)\n",
      "Test set accuracy: 0.9722\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Bread       1.00      0.95      0.97        20\n",
      "     Cookies       0.94      1.00      0.97        16\n",
      "\n",
      "    accuracy                           0.97        36\n",
      "   macro avg       0.97      0.97      0.97        36\n",
      "weighted avg       0.97      0.97      0.97        36\n",
      "\n",
      "\n",
      "Evaluating Neural Network...\n",
      "\n",
      "Results for Neural Network:\n",
      "Cross-validation scores: [0.97222222 0.91666667 1.         1.         0.97222222]\n",
      "Mean CV accuracy: 0.9722 (±0.0304)\n",
      "Test set accuracy: 0.9722\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Bread       1.00      0.95      0.97        20\n",
      "     Cookies       0.94      1.00      0.97        16\n",
      "\n",
      "    accuracy                           0.97        36\n",
      "   macro avg       0.97      0.97      0.97        36\n",
      "weighted avg       0.97      0.97      0.97        36\n",
      "\n",
      "\n",
      "Evaluating Logistic Regression...\n",
      "\n",
      "Results for Logistic Regression:\n",
      "Cross-validation scores: [0.91666667 0.91666667 0.86111111 0.91666667 0.88888889]\n",
      "Mean CV accuracy: 0.9000 (±0.0222)\n",
      "Test set accuracy: 0.9722\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Bread       1.00      0.95      0.97        20\n",
      "     Cookies       0.94      1.00      0.97        16\n",
      "\n",
      "    accuracy                           0.97        36\n",
      "   macro avg       0.97      0.97      0.97        36\n",
      "weighted avg       0.97      0.97      0.97        36\n",
      "\n",
      "\n",
      "Running classification analysis for storage_condition\n",
      "==================================================\n",
      "\n",
      "Evaluating SVM...\n",
      "\n",
      "Results for SVM:\n",
      "Cross-validation scores: [0.44444444 0.38888889 0.55555556 0.38888889 0.33333333]\n",
      "Mean CV accuracy: 0.4222 (±0.0754)\n",
      "Test set accuracy: 0.4444\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Humid       0.43      0.21      0.29        14\n",
      "        Open       1.00      0.57      0.73        14\n",
      "     Wrapped       0.24      0.62      0.34         8\n",
      "\n",
      "    accuracy                           0.44        36\n",
      "   macro avg       0.56      0.47      0.45        36\n",
      "weighted avg       0.61      0.44      0.47        36\n",
      "\n",
      "\n",
      "Evaluating Random Forest...\n",
      "\n",
      "Results for Random Forest:\n",
      "Cross-validation scores: [0.97222222 0.88888889 0.88888889 0.83333333 0.94444444]\n",
      "Mean CV accuracy: 0.9056 (±0.0484)\n",
      "Test set accuracy: 0.9444\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Humid       0.88      1.00      0.93        14\n",
      "        Open       1.00      1.00      1.00        14\n",
      "     Wrapped       1.00      0.75      0.86         8\n",
      "\n",
      "    accuracy                           0.94        36\n",
      "   macro avg       0.96      0.92      0.93        36\n",
      "weighted avg       0.95      0.94      0.94        36\n",
      "\n",
      "\n",
      "Evaluating KNN...\n",
      "\n",
      "Results for KNN:\n",
      "Cross-validation scores: [0.83333333 0.86111111 0.83333333 0.80555556 0.77777778]\n",
      "Mean CV accuracy: 0.8222 (±0.0283)\n",
      "Test set accuracy: 0.6944\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Humid       0.67      0.57      0.62        14\n",
      "        Open       0.76      0.93      0.84        14\n",
      "     Wrapped       0.57      0.50      0.53         8\n",
      "\n",
      "    accuracy                           0.69        36\n",
      "   macro avg       0.67      0.67      0.66        36\n",
      "weighted avg       0.68      0.69      0.68        36\n",
      "\n",
      "\n",
      "Evaluating Neural Network...\n",
      "\n",
      "Results for Neural Network:\n",
      "Cross-validation scores: [0.33333333 0.41666667 0.33333333 0.36111111 0.33333333]\n",
      "Mean CV accuracy: 0.3556 (±0.0324)\n",
      "Test set accuracy: 0.9167\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Humid       0.93      0.93      0.93        14\n",
      "        Open       1.00      0.93      0.96        14\n",
      "     Wrapped       0.78      0.88      0.82         8\n",
      "\n",
      "    accuracy                           0.92        36\n",
      "   macro avg       0.90      0.91      0.91        36\n",
      "weighted avg       0.92      0.92      0.92        36\n",
      "\n",
      "\n",
      "Evaluating Logistic Regression...\n",
      "\n",
      "Results for Logistic Regression:\n",
      "Cross-validation scores: [0.41666667 0.5        0.44444444 0.33333333 0.36111111]\n",
      "Mean CV accuracy: 0.4111 (±0.0593)\n",
      "Test set accuracy: 0.7778\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Humid       0.73      0.79      0.76        14\n",
      "        Open       1.00      0.93      0.96        14\n",
      "     Wrapped       0.50      0.50      0.50         8\n",
      "\n",
      "    accuracy                           0.78        36\n",
      "   macro avg       0.74      0.74      0.74        36\n",
      "weighted avg       0.79      0.78      0.78        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Import classifiers\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "class BakeryClassification:\n",
    "    def __init__(self, data_path='augmented_bakery_data.csv'):\n",
    "        \"\"\"Initialize the classification analysis\"\"\"\n",
    "        self.data = pd.read_csv(data_path)\n",
    "        self.classifiers = {\n",
    "            'SVM': SVC(kernel='rbf', random_state=42),\n",
    "            'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "            'KNN': KNeighborsClassifier(n_neighbors=5),\n",
    "            'Neural Network': MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=1000, random_state=42),\n",
    "            'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42)\n",
    "        }\n",
    "        self.scaler = StandardScaler()\n",
    "        \n",
    "    def prepare_data(self, task='product_type'):\n",
    "        \"\"\"Prepare data for classification\"\"\"\n",
    "        # Get feature columns (gain and phase)\n",
    "        feature_cols = [col for col in self.data.columns if col.startswith(('gain_', 'phase_'))]\n",
    "        X = self.data[feature_cols]\n",
    "        \n",
    "        # Select target based on task\n",
    "        if task == 'product_type':\n",
    "            y = self.data['Product_Type']\n",
    "        else:  # storage_condition\n",
    "            y = self.data['Storage_Condition']\n",
    "            \n",
    "        return X, y\n",
    "    \n",
    "    def plot_confusion_matrix(self, y_true, y_pred, title, classifier_name):\n",
    "        \"\"\"Plot confusion matrix\"\"\"\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "        plt.title(f'{classifier_name} - {title}')\n",
    "        plt.ylabel('True Label')\n",
    "        plt.xlabel('Predicted Label')\n",
    "        plt.savefig(f'confusion_matrix_{classifier_name}_{title.lower().replace(\" \", \"_\")}.png')\n",
    "        plt.close()\n",
    "    \n",
    "    def evaluate_classifier(self, clf, X, y, task, clf_name):\n",
    "        \"\"\"Evaluate a single classifier\"\"\"\n",
    "        # Perform cross-validation\n",
    "        cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        cv_scores = cross_val_score(clf, X, y, cv=cv, scoring='accuracy')\n",
    "        \n",
    "        # Train-test split for detailed evaluation\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        \n",
    "        # Scale the features\n",
    "        X_train_scaled = self.scaler.fit_transform(X_train)\n",
    "        X_test_scaled = self.scaler.transform(X_test)\n",
    "        \n",
    "        # Train and predict\n",
    "        clf.fit(X_train_scaled, y_train)\n",
    "        y_pred = clf.predict(X_test_scaled)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        \n",
    "        # Plot confusion matrix\n",
    "        self.plot_confusion_matrix(y_test, y_pred, task, clf_name)\n",
    "        \n",
    "        # Generate classification report\n",
    "        report = classification_report(y_test, y_pred)\n",
    "        \n",
    "        return {\n",
    "            'cv_scores': cv_scores,\n",
    "            'cv_mean': cv_scores.mean(),\n",
    "            'cv_std': cv_scores.std(),\n",
    "            'test_accuracy': accuracy,\n",
    "            'classification_report': report\n",
    "        }\n",
    "    \n",
    "    def run_classification_analysis(self, task='product_type'):\n",
    "        \"\"\"Run complete classification analysis\"\"\"\n",
    "        X, y = self.prepare_data(task)\n",
    "        results = {}\n",
    "        \n",
    "        print(f\"\\nRunning classification analysis for {task}\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        for name, clf in self.classifiers.items():\n",
    "            print(f\"\\nEvaluating {name}...\")\n",
    "            results[name] = self.evaluate_classifier(clf, X, y, task, name)\n",
    "            \n",
    "            print(f\"\\nResults for {name}:\")\n",
    "            print(f\"Cross-validation scores: {results[name]['cv_scores']}\")\n",
    "            print(f\"Mean CV accuracy: {results[name]['cv_mean']:.4f} (±{results[name]['cv_std']:.4f})\")\n",
    "            print(f\"Test set accuracy: {results[name]['test_accuracy']:.4f}\")\n",
    "            print(\"\\nClassification Report:\")\n",
    "            print(results[name]['classification_report'])\n",
    "        \n",
    "        # Plot comparison of classifier performances\n",
    "        self.plot_classifier_comparison(results, task)\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def plot_classifier_comparison(self, results, task):\n",
    "        \"\"\"Plot comparison of classifier performances\"\"\"\n",
    "        clf_names = list(results.keys())\n",
    "        cv_means = [results[name]['cv_mean'] for name in clf_names]\n",
    "        cv_stds = [results[name]['cv_std'] for name in clf_names]\n",
    "        test_accuracies = [results[name]['test_accuracy'] for name in clf_names]\n",
    "        \n",
    "        x = np.arange(len(clf_names))\n",
    "        width = 0.35\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(12, 6))\n",
    "        rects1 = ax.bar(x - width/2, cv_means, width, label='CV Accuracy', yerr=cv_stds)\n",
    "        rects2 = ax.bar(x + width/2, test_accuracies, width, label='Test Accuracy')\n",
    "        \n",
    "        ax.set_ylabel('Accuracy')\n",
    "        ax.set_title(f'Classifier Performance Comparison - {task}')\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels(clf_names, rotation=45)\n",
    "        ax.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'classifier_comparison_{task}.png')\n",
    "        plt.close()\n",
    "\n",
    "def main():\n",
    "    # Initialize analysis\n",
    "    analyzer = BakeryClassification()\n",
    "    \n",
    "    # Run analysis for product type classification\n",
    "    product_results = analyzer.run_classification_analysis(task='product_type')\n",
    "    \n",
    "    # Run analysis for storage condition classification\n",
    "    storage_results = analyzer.run_classification_analysis(task='storage_condition')\n",
    "    \n",
    "    # Save results to file\n",
    "    with open('classification_results.txt', 'w') as f:\n",
    "        f.write(\"Classification Results\\n\")\n",
    "        f.write(\"=====================\\n\\n\")\n",
    "        \n",
    "        for task, results in [(\"Product Type\", product_results), \n",
    "                            (\"Storage Condition\", storage_results)]:\n",
    "            f.write(f\"\\n{task} Classification\\n\")\n",
    "            f.write(\"-\" * 50 + \"\\n\")\n",
    "            \n",
    "            for clf_name, clf_results in results.items():\n",
    "                f.write(f\"\\n{clf_name}:\\n\")\n",
    "                f.write(f\"Mean CV Accuracy: {clf_results['cv_mean']:.4f} \"\n",
    "                       f\"(±{clf_results['cv_std']:.4f})\\n\")\n",
    "                f.write(f\"Test Accuracy: {clf_results['test_accuracy']:.4f}\\n\")\n",
    "                f.write(\"\\nClassification Report:\\n\")\n",
    "                f.write(clf_results['classification_report'])\n",
    "                f.write(\"\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
